{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################       \n",
    "#Script Name    :                                                                                              \n",
    "#Description    :                                                                                 \n",
    "#Args           :                                                                                           \n",
    "#Author         : Nikhil Rao in R, converted to Python by Nor Raymond                                              \n",
    "#Email          : nraymond@appen.com                                          \n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fail Rate Reports for Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import warnings\n",
    "from functools import reduce\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "config_path = \"conf/base\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "    \n",
    "except:\n",
    "    \n",
    "    os.chdir('..')\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "    \n",
    "# import data_processing module\n",
    "import src.data.data_processing as data_processing\n",
    "# import data_processing module\n",
    "import src.data.data_cleaning as data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_selection(languages):\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            language_index = int(input(\"\\nPlease select the number of the Language you are assessing: \"))\n",
    "            if language_index < min(languages.index) or language_index > max(languages.index):\n",
    "                print(f\"\\nYou must enter numbers between {min(languages.index)} - {max(languages.index)}... Please try again\")\n",
    "                continue\n",
    "            elif language_index == \"\":\n",
    "                print(\"\\nYou must enter any numbers\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"\\nYou have selected {language_index} for {languages.iloc[language_index, 0]}\")\n",
    "                language_selected = languages.iloc[language_index, 0]\n",
    "                break\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"\\nYou must enter numerical values only... Please try again\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return language_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Language Modification - getting the overall time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Language Modification\n",
    "def get_time_taken(df, language_selected):\n",
    "\n",
    "    # Filter data based on selected language\n",
    "    dfr = df[df['Language'] == language_selected]\n",
    "\n",
    "    # Time Taken by Item\n",
    "    dfr[\"Time_Taken_Seconds\"] = (dfr['_created_at'] - dfr['_started_at']).dt.seconds\n",
    "\n",
    "    # Time Taken Overall\n",
    "    dfr_grouped = dfr.groupby('_worker_id').sum('Time_Taken_Seconds')\n",
    "    dfr_grouped[\"Time_Taken_Minutes_Overall\"] = dfr_grouped[\"Time_Taken_Seconds\"] / 60\n",
    "    dfr_grouped = dfr_grouped.reset_index()\n",
    "    dfr = pd.merge(dfr, dfr_grouped[[\"Time_Taken_Minutes_Overall\", \"_worker_id\"]], how = 'left', on = '_worker_id')\n",
    "\n",
    "    return dfr\n",
    "\n",
    "def get_time_taken_all(language_selected, rc, v1, v2):\n",
    "    \n",
    "    df_list = [rc, v1, v2]\n",
    "    keys = [\"rcR\", \"v1R\", \"v2R\"]\n",
    "    df_time = {}\n",
    "    \n",
    "    for df, key in zip(df_list, keys) :\n",
    "\n",
    "        dfr = get_time_taken(df, language_selected)\n",
    "        df_time[key] = dfr\n",
    "\n",
    "    rcR, v1R, v2R = df_time[\"rcR\"], df_time[\"v1R\"], df_time[\"v2R\"]    \n",
    "    \n",
    "    return rcR, v1R, v2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for calculating Fail Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PILOT 3A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v1_fail_rate_3A(v1R):  #Valid for 3A\n",
    "    \n",
    "    vR_temp = v1R[['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                    'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty'])['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and Fail_rate descending \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', 'Fail_Rate'], ascending=[True, False])\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def generate_report_1_3A(v1R):\n",
    "    \n",
    "    v1_actual_correct_by_question = v1_fail_rate_3A(v1R)\n",
    "    \n",
    "    return v1_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 2 : \"Close Match\" - v2_fail_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2_fail_rate_3A(v2R):\n",
    "    \n",
    "    vR_temp = v2R[['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty'])['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Overall_Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', '_unit_id'], ascending = [True, True])\n",
    "    \n",
    "    # drop Score column\n",
    "    vR_grouped = vR_grouped.drop('Score', axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def v2_fail_rate_2_3A(v2R):\n",
    "    \n",
    "    vR_temp = v2R[['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty'])['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', '_unit_id', 'Score', 'Rate'], ascending = [True, True, True, False])\n",
    "    \n",
    "    # drop Score columns\n",
    "    vR_grouped = vR_grouped.drop(['Score', 'Count_of_Test_Takers', 'Total_Test_Takers'], axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    vR_fail_rates  = pd.pivot_table(vR_fail_rates, \n",
    "                           index=['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers'],\n",
    "                           values='Rate', columns=['rater_answer']).reset_index()\n",
    "    vR_fail_rates.columns.name = None # remove name for columns\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_fail_rates = vR_fail_rates.drop_duplicates()\n",
    "    \n",
    "    return vR_fail_rates \n",
    "\n",
    "def merge_v2_fail_rates_3A(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer):\n",
    "    \n",
    "    v2_fail_rates = pd.merge(v2_actual_correct_by_question_with_answer, v2_actual_correct_by_question, how = 'left', \n",
    "                            on = [\"Language\", \"Fluency\", \"_unit_id\", \"question_\", \"a_domain\", \"a_register\", \"wordphrase_a\", \"b_domain\",\n",
    "                                  \"b_register\", \"wordphrase_b\", \"difficulty\", \"Answers\"])\n",
    "    \n",
    "#     v2_fail_rates = v2_fail_rates[['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a',\n",
    "#                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Count_of_Test_Takers', 'Total_Test_Takers',\n",
    "#                 'Overall_Fail_Rate', 'Answers', 'a_and_b_are_not_related', 'a_and_b_are_related', 'a_and_b_have_the_same_meaning',\n",
    "#                 'a_is_more_specific_than_b', 'b_is_more_specific_than_a']]\n",
    "    \n",
    "    return v2_fail_rates\n",
    "\n",
    "def generate_report_2_3A(v2R):\n",
    "    \n",
    "    v2_actual_correct_by_question = v2_fail_rate_3A(v2R)\n",
    "\n",
    "    v2_actual_correct_by_question_with_answer = v2_fail_rate_2_3A(v2R)\n",
    "\n",
    "    v2_fail_rates = merge_v2_fail_rates_3A(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer)\n",
    "    \n",
    "    return v2_fail_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_fail_rate_3A(rcR):\n",
    "\n",
    "    vR_temp = rcR[['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    if vR_temp['question_no_1'].isnull().all() == True or vR_temp['Answer_no_1'].isnull().all() == True:      \n",
    "        vR_temp['a1'] = np.nan      \n",
    "    else:   \n",
    "        vR_temp['a1'] = np.where(vR_temp['question_no_1'] == vR_temp['Answer_no_1'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_2'].isnull().all() == True or vR_temp['Answer_no_2'].isnull().all() == True:        \n",
    "        vR_temp['a2'] = np.nan      \n",
    "    else:       \n",
    "        vR_temp['a2'] = np.where(vR_temp['question_no_2'] == vR_temp['Answer_no_2'], 1, 0).astype('str')      \n",
    "        \n",
    "    if vR_temp['question_no_3'].isnull().all() == True or vR_temp['Answer_no_3'].isnull().all() == True:  \n",
    "        vR_temp['a3'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a3'] = np.where(vR_temp['question_no_3'] == vR_temp['Answer_no_3'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_4'].isnull().all() == True or vR_temp['Answer_no_4'].isnull().all() == True:   \n",
    "        vR_temp['a4'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a4'] = np.where(vR_temp['question_no_4'] == vR_temp['Answer_no_4'], 1, 0).astype('str')\n",
    "    \n",
    "    # Dropping columns\n",
    "    vR_temp = vR_temp.drop(['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score'], axis =1)  \n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    # Dropping more columns\n",
    "    vR_temp = vR_temp.drop(['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4'], axis =1)  \n",
    "    \n",
    "    # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "       '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type',\n",
    "       'complexity', 'familiarity']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Question', 'Difficulty', \n",
    "                                                                                               'Google_Translate_Error', 'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer = vR_temp\n",
    "    \n",
    "    return vR_temp\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc_assign_3A(rc_choices, q_list, choice_list):\n",
    "    \n",
    "    df=[]\n",
    "    for ql in q_list:\n",
    "        for cl in choice_list:\n",
    "            df_temp_1 = rc_choices[rc_choices['variable'].str.contains('question_' + str(ql))]\n",
    "            df_temp_2 = df_temp_1[df_temp_1['variable'].str.contains('choice_' + str(cl))]\n",
    "            df_temp_2['Question'] = 'Question ' + str(ql)\n",
    "            if cl == 1 :\n",
    "                df_temp_2['Answer'] = 'a'\n",
    "            elif cl == 2 :\n",
    "                df_temp_2['Answer'] = 'b'\n",
    "            elif cl == 3 :\n",
    "                df_temp_2['Answer'] = 'c'\n",
    "            df.append(df_temp_2)\n",
    "            \n",
    "    rc_choices = pd.concat(df)\n",
    "    return rc_choices\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc_3A(rcR):\n",
    "\n",
    "    vR_temp = rcR[['Language', '_unit_id', 'title', 'test_',\n",
    "                'question_1_choice_1', 'question_1_choice_2', 'question_1_choice_3',\n",
    "                'question_2_choice_1', 'question_2_choice_2', 'question_2_choice_3',\n",
    "                'question_3_choice_1', 'question_3_choice_2', 'question_3_choice_3',\n",
    "                'question_4_choice_1', 'question_4_choice_2', 'question_4_choice_3']]\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_temp = vR_temp.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    vR_temp = pd.melt(vR_temp, id_vars=['Language', '_unit_id', 'title', 'test_'])\n",
    "    \n",
    "    rc_choices = vR_temp\n",
    "    \n",
    "    q_list, choice_list = [1,2,3,4], [1,2,3]\n",
    "    rc_choices = melt_rc_assign_3A(rc_choices, q_list, choice_list)\n",
    "    rc_choices = rc_choices[['Language', '_unit_id', 'title', 'test_', 'Question', 'Answer', 'variable', 'value']]\n",
    "    rc_choices = rc_choices.sort_values(['Language', 'title', 'test_', 'Question', 'Answer'])\n",
    "    \n",
    "    actual_answer = rc_choices\n",
    "    rater_answer = rc_choices\n",
    "    \n",
    "    return rc_choices, actual_answer, rater_answer\n",
    "\n",
    "# ## Melt RC into long format with actual answers\n",
    "def melt_rc_answer_actual_3A(rcR):\n",
    "    \n",
    "    vR_temp = rcR[['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    if vR_temp['question_no_1'].isnull().all() == True or vR_temp['Answer_no_1'].isnull().all() == True:      \n",
    "        vR_temp['a1'] = np.nan      \n",
    "    else:   \n",
    "        vR_temp['a1'] = np.where(vR_temp['question_no_1'] == vR_temp['Answer_no_1'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_2'].isnull().all() == True or vR_temp['Answer_no_2'].isnull().all() == True:        \n",
    "        vR_temp['a2'] = np.nan      \n",
    "    else:       \n",
    "        vR_temp['a2'] = np.where(vR_temp['question_no_2'] == vR_temp['Answer_no_2'], 1, 0).astype('str')      \n",
    "        \n",
    "    if vR_temp['question_no_3'].isnull().all() == True or vR_temp['Answer_no_3'].isnull().all() == True:  \n",
    "        vR_temp['a3'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a3'] = np.where(vR_temp['question_no_3'] == vR_temp['Answer_no_3'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_4'].isnull().all() == True or vR_temp['Answer_no_4'].isnull().all() == True:   \n",
    "        vR_temp['a4'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a4'] = np.where(vR_temp['question_no_4'] == vR_temp['Answer_no_4'], 1, 0).astype('str')\n",
    "    \n",
    "    vR_temp = vR_temp.drop('Score', axis = 1)\n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Rater_Answer'] = vR_temp[['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4']].astype('str').agg(';'.join, axis=1)\n",
    "    vR_temp['Actual_Answer'] = vR_temp[['Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    vR_temp = vR_temp.drop(['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4'], axis = 1)\n",
    "    \n",
    "     # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "       '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type',\n",
    "       'complexity', 'familiarity']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Rater_Answer', 'Actual_Answer', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Rater_Answer', \n",
    "                                                                                                                                'Actual_Answer','Question', \n",
    "                                                                                                                                'Difficulty', \n",
    "                                                                                                                                'Google_Translate_Error', \n",
    "                                                                                                                                'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer_actual = vR_temp\n",
    "    \n",
    "    return rc_answer_actual\n",
    "\n",
    "def rc_q_s_pass_rate_3A(rc_answer):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer.groupby(['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Score', 'Question', 'Difficulty', 'register', 'Skill'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill'])['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', 'Fail_Rate'], ascending = [True, False])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "def generate_report_3_3A(rcR):\n",
    "    \n",
    "    rc_answer = rc_fail_rate_3A(rcR)\n",
    "    \n",
    "    rc_choices, actual_answer, rater_answer = melt_rc_3A(rcR)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual_3A(rcR)\n",
    "    \n",
    "    rc_question_skill_pass_rate = rc_q_s_pass_rate_3A(rc_answer)\n",
    "    \n",
    "    return rc_question_skill_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 4 : \"RC with Answers\" : rc_question_skill_pass_rate_answer_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_q_s_pass_rate_answer_3A(rc_answer_actual):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer_actual.groupby(['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Actual_Answer', 'Rater_Answer', \n",
    "                                    'Score', 'Question', 'Difficulty', 'register', 'Skill'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill'])['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', '_unit_id', 'Question', 'Fail_Rate'], ascending = [True, True, True, False])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer\n",
    "\n",
    "def join_rc_q_s_pass_rate_answer_3A(rc_question_skill_pass_rate_answer, actual_answer, rater_answer):\n",
    "    \n",
    "    first_join = rc_question_skill_pass_rate_answer\n",
    "    first_join = pd.merge(first_join, actual_answer, how = 'left', \n",
    "                            left_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Actual_Answer\"],\n",
    "                            right_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Answer\"])\n",
    "    first_join = first_join.drop('Answer', axis=1)\n",
    "    \n",
    "    second_join = pd.merge(first_join, rater_answer, how = 'left', \n",
    "                            left_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Rater_Answer\"],\n",
    "                            right_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Answer\"])\n",
    "    second_join = second_join.drop('Answer', axis=1)\n",
    "    \n",
    "    second_join = second_join[['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Difficulty', 'register', 'Skill', 'Question',\n",
    "                               'Actual_Answer', 'value_x', 'Rater_Answer', 'value_y', 'Count', 'Total', 'Fail_Rate']]\n",
    "  \n",
    "    second_join = second_join.rename(columns = { \"Actual_Answer\" : \"Actual_Answer_Letter\", \n",
    "                                       \"value_x\" : \"Actual_Answer_Text\",\n",
    "                                       \"Rater_Answer\" : \"Rater_Answer_Letter\",\n",
    "                                       \"value_y\" : \"Rater_Answer_Text\"})\n",
    "\n",
    "    rc_question_skill_pass_rate_answer_final = second_join\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer_final\n",
    "\n",
    "\n",
    "def generate_report_4_3A(rcR):\n",
    "    \n",
    "    rc_choices, actual_answer, rater_answer = melt_rc_3A(rcR)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual_3A(rcR)\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = rc_q_s_pass_rate_answer_3A(rc_answer_actual)\n",
    "\n",
    "    rc_question_skill_pass_rate_answer_final = join_rc_q_s_pass_rate_answer_3A(rc_question_skill_pass_rate_answer, actual_answer, rater_answer)\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PILOT 1A-1B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v1_fail_rate_1A_1B(v1R):  #Valid for 3A\n",
    "    \n",
    "    vR_temp = v1R[['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                    'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']]\n",
    "       \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty'])['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and Fail_rate descending \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', 'Tenure', 'Fail_Rate'], ascending=[True, True, False])\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def generate_report_1_1A_1B(v1R):\n",
    "    \n",
    "    v1_actual_correct_by_question = v1_fail_rate_1A_1B(v1R)\n",
    "    \n",
    "    return v1_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 2 : \"Close Match\" - v2_fail_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2_fail_rate_1A_1B(v2R):\n",
    "    \n",
    "    vR_temp = v2R[['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty'])['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', 'Tenure', 'Fail_Rate'], ascending = [True, True, False])\n",
    "    \n",
    "    # drop Score column\n",
    "    vR_grouped = vR_grouped.drop('Score', axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def v2_fail_rate_2_1A_1B(v2R):\n",
    "    \n",
    "    vR_temp = v2R[['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty'])['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', 'Tenure', '_unit_id', 'Score', 'Rate'], ascending = [True, True, True, False])\n",
    "    \n",
    "    v2_actual_correct_by_question_with_answer = vR_grouped\n",
    "    \n",
    "    return v2_actual_correct_by_question_with_answer\n",
    "\n",
    "def generate_report_2_1A_1B(v2R):\n",
    "    \n",
    "    v2_actual_correct_by_question = v2_fail_rate_1A_1B(v2R)\n",
    "\n",
    "    v2_actual_correct_by_question_with_answer = v2_fail_rate_2_1A_1B(v2R)\n",
    "\n",
    "    return v2_actual_correct_by_question_with_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_fail_rate_1A_1B(rcR):\n",
    "\n",
    "    vR_temp = rcR[['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    if vR_temp['question_no_1'].isnull().all() == True or vR_temp['Answer_no_1'].isnull().all() == True:      \n",
    "        vR_temp['a1'] = np.nan      \n",
    "    else:   \n",
    "        vR_temp['a1'] = np.where(vR_temp['question_no_1'] == vR_temp['Answer_no_1'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_2'].isnull().all() == True or vR_temp['Answer_no_2'].isnull().all() == True:        \n",
    "        vR_temp['a2'] = np.nan      \n",
    "    else:       \n",
    "        vR_temp['a2'] = np.where(vR_temp['question_no_2'] == vR_temp['Answer_no_2'], 1, 0).astype('str')      \n",
    "        \n",
    "    if vR_temp['question_no_3'].isnull().all() == True or vR_temp['Answer_no_3'].isnull().all() == True:  \n",
    "        vR_temp['a3'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a3'] = np.where(vR_temp['question_no_3'] == vR_temp['Answer_no_3'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_4'].isnull().all() == True or vR_temp['Answer_no_4'].isnull().all() == True:   \n",
    "        vR_temp['a4'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a4'] = np.where(vR_temp['question_no_4'] == vR_temp['Answer_no_4'], 1, 0).astype('str')\n",
    "    \n",
    "    # Dropping columns\n",
    "    vR_temp = vR_temp.drop(['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score'], axis =1)  \n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    # Dropping more columns\n",
    "    vR_temp = vR_temp.drop(['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4'], axis =1)  \n",
    "    \n",
    "    # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "       '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type',\n",
    "       'complexity', 'familiarity']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Question', 'Difficulty', \n",
    "                                                                                               'Google_Translate_Error', 'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer = vR_temp\n",
    "    \n",
    "    return vR_temp\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc_assign_1A_1B(rc_choices, q_list, choice_list):\n",
    "    \n",
    "    df=[]\n",
    "    for ql in q_list:\n",
    "        for cl in choice_list:\n",
    "            df_temp_1 = rc_choices[rc_choices['variable'].str.contains('question_' + str(ql))]\n",
    "            df_temp_2 = df_temp_1[df_temp_1['variable'].str.contains('choice_' + str(cl))]\n",
    "            df_temp_2['Question'] = 'Question ' + str(ql)\n",
    "            if cl == 1 :\n",
    "                df_temp_2['Answer'] = 'a'\n",
    "            elif cl == 2 :\n",
    "                df_temp_2['Answer'] = 'b'\n",
    "            elif cl == 3 :\n",
    "                df_temp_2['Answer'] = 'c'\n",
    "            df.append(df_temp_2)\n",
    "            \n",
    "    rc_choices = pd.concat(df)\n",
    "    return rc_choices\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc_1A_1B(rcR):\n",
    "\n",
    "    vR_temp = rcR[['Language', '_unit_id', 'title', 'test_',\n",
    "                'question_1_choice_1', 'question_1_choice_2', 'question_1_choice_3',\n",
    "                'question_2_choice_1', 'question_2_choice_2', 'question_2_choice_3',\n",
    "                'question_3_choice_1', 'question_3_choice_2', 'question_3_choice_3',\n",
    "                'question_4_choice_1', 'question_4_choice_2', 'question_4_choice_3']]\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_temp = vR_temp.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    vR_temp = pd.melt(vR_temp, id_vars=['Language', '_unit_id', 'title', 'test_'])\n",
    "    \n",
    "    rc_choices = vR_temp\n",
    "    \n",
    "    q_list, choice_list = [1,2,3,4], [1,2,3]\n",
    "    rc_choices = melt_rc_assign_1A_1B(rc_choices, q_list, choice_list)\n",
    "    rc_choices = rc_choices[['Language', '_unit_id', 'title', 'test_', 'Question', 'Answer', 'variable', 'value']]\n",
    "    rc_choices = rc_choices.sort_values(['Language', 'title', 'test_', 'Question', 'Answer'])\n",
    "    \n",
    "    actual_answer = rc_choices\n",
    "    rater_answer = rc_choices\n",
    "    \n",
    "    return rc_choices, actual_answer, rater_answer\n",
    "\n",
    "# ## Melt RC into long format with actual answers\n",
    "def melt_rc_answer_actual_1A_1B(rcR):\n",
    "    \n",
    "    vR_temp = rcR[['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    if vR_temp['question_no_1'].isnull().all() == True or vR_temp['Answer_no_1'].isnull().all() == True:      \n",
    "        vR_temp['a1'] = np.nan      \n",
    "    else:   \n",
    "        vR_temp['a1'] = np.where(vR_temp['question_no_1'] == vR_temp['Answer_no_1'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_2'].isnull().all() == True or vR_temp['Answer_no_2'].isnull().all() == True:        \n",
    "        vR_temp['a2'] = np.nan      \n",
    "    else:       \n",
    "        vR_temp['a2'] = np.where(vR_temp['question_no_2'] == vR_temp['Answer_no_2'], 1, 0).astype('str')      \n",
    "        \n",
    "    if vR_temp['question_no_3'].isnull().all() == True or vR_temp['Answer_no_3'].isnull().all() == True:  \n",
    "        vR_temp['a3'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a3'] = np.where(vR_temp['question_no_3'] == vR_temp['Answer_no_3'], 1, 0).astype('str')\n",
    "        \n",
    "    if vR_temp['question_no_4'].isnull().all() == True or vR_temp['Answer_no_4'].isnull().all() == True:   \n",
    "        vR_temp['a4'] = np.nan \n",
    "    else:\n",
    "        vR_temp['a4'] = np.where(vR_temp['question_no_4'] == vR_temp['Answer_no_4'], 1, 0).astype('str')\n",
    "    \n",
    "    vR_temp = vR_temp.drop('Score', axis = 1)\n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Rater_Answer'] = vR_temp[['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4']].astype('str').agg(';'.join, axis=1)\n",
    "    vR_temp['Actual_Answer'] = vR_temp[['Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    vR_temp = vR_temp.drop(['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4'], axis = 1)\n",
    "    \n",
    "     # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "       '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type',\n",
    "       'complexity', 'familiarity']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Rater_Answer', 'Actual_Answer', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Rater_Answer', \n",
    "                                                                                                                                'Actual_Answer','Question', \n",
    "                                                                                                                                'Difficulty', \n",
    "                                                                                                                                'Google_Translate_Error', \n",
    "                                                                                                                                'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer_actual = vR_temp\n",
    "    \n",
    "    return rc_answer_actual\n",
    "\n",
    "def rc_q_s_pass_rate_1A_1B(rc_answer):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer.groupby(['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Score', 'Question', 'Difficulty', 'register', 'Skill'])['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill'])['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(['Fluency', 'Fail_Rate'], ascending = [True, False])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "def generate_report_3_1A_1B(rcR):\n",
    "    \n",
    "    rc_answer = rc_fail_rate_1A_1B(rcR)\n",
    "    \n",
    "    rc_choices, actual_answer, rater_answer = melt_rc_1A_1B(rcR)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual_1A_1B(rcR)\n",
    "    \n",
    "    rc_question_skill_pass_rate = rc_q_s_pass_rate_1A_1B(rc_answer)\n",
    "    \n",
    "    return rc_question_skill_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_fail_rate_reports(rcR, v1R, v2R, rc, v1, v2, run_value, pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 3A':\n",
    "        \n",
    "        # Report 1 - Near Exact Match - v1_actual_correct_by_question\n",
    "        v1_actual_correct_by_question =  generate_report_1_3A(v1R)\n",
    "\n",
    "        # Report 2 - Close Match - v2_fail_rates\n",
    "        v2_fail_rates = generate_report_2_3A(v2R)\n",
    "\n",
    "        # Report 3 - Reading Comprehension - rc_question_skill_pass_rate\n",
    "        rc_question_skill_pass_rate = generate_report_3_3A(rcR)\n",
    "\n",
    "        # Report 4 - RC with Answers - rc_question_skill_pass_rate_answer_final\n",
    "        rc_question_skill_pass_rate_answer_final = generate_report_4_3A(rcR)\n",
    "\n",
    "        # store all 4 reports into a dictionary set\n",
    "        list_of_datasets = {\"Near Exact Match\" : v1_actual_correct_by_question,\n",
    "                            \"Close Match\" : v2_fail_rates,\n",
    "                            \"Reading Comprehension\" : rc_question_skill_pass_rate,\n",
    "                            \"RC with Answers\" : rc_question_skill_pass_rate_answer_final}\n",
    "\n",
    "        if run_value == 'Deployment':\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = {\"deployment_rc\" : rc,\n",
    "                                \"deployment_v1\" : v1,\n",
    "                                \"deployment_v2\" : v2}\n",
    "\n",
    "        else:\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = { run_value + \"_rc\" : rc,\n",
    "                                  run_value + \"_v1\" : v1,\n",
    "                                  run_value + \"_v2\" : v2}\n",
    "\n",
    "    \n",
    "    return list_of_datasets, list_of_summaries\n",
    "\n",
    "def file_check_create(root_path, config, language_selected, run_value, pilot_var_selected):\n",
    "    \n",
    "    if run_value == 'Deployment':\n",
    "        \n",
    "        run_folder = os.path.join(root_path, config['report']['deliverable'], run_value, language_selected)\n",
    "\n",
    "        if not os.path.exists(run_folder):\n",
    "            os.makedirs(run_folder, exist_ok=True)\n",
    "        \n",
    "        folder_tag = 'Deployment Summary'\n",
    "        analysis_folder = os.path.join(root_path, config['report']['analysis'], folder_tag)\n",
    "\n",
    "        if not os.path.exists(analysis_folder):\n",
    "            os.makedirs(analysis_folder, exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'RC')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'RC'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V1')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V1'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V2')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V2'), exist_ok=True)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        run_folder = os.path.join(root_path, config['report']['deliverable'], run_value, pilot_var_selected, language_selected)\n",
    "\n",
    "        if not os.path.exists(run_folder):\n",
    "            os.makedirs(run_folder, exist_ok=True)\n",
    "            \n",
    "        folder_tag = 'Grand Summary'\n",
    "        analysis_folder = os.path.join(root_path, config['report']['analysis'], folder_tag)\n",
    "\n",
    "        if not os.path.exists(analysis_folder):\n",
    "            os.makedirs(analysis_folder, exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'RC')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'RC'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V1')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V1'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V2')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V2'), exist_ok=True)\n",
    "        \n",
    "    return run_folder, analysis_folder, folder_tag\n",
    "\n",
    "def write_fail_report_to_excel(run_folder, list_of_datasets, encode=None):\n",
    "    \n",
    "    with pd.ExcelWriter(os.path.join(run_folder, 'language_fail_rates.xlsx')) as writer:  \n",
    "        for key, value in list_of_datasets.items():\n",
    "            value.to_excel(writer, sheet_name=key, index=False, encoding=encode)\n",
    "            \n",
    "def write_summary_to_csv(analysis_folder, list_of_summaries, encode=None):\n",
    "    \n",
    "    folders = ['RC', 'V1', 'V2']\n",
    "    for lists, f in zip(list_of_summaries.items(), folders):\n",
    "        key, value = lists[0], lists[1]\n",
    "        value.to_csv(os.path.join(os.path.join(analysis_folder,f), key + '.csv'), index=False, encoding=encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data processing in progress...\n",
      "Initialize data ingestion and file checking...\n",
      "\n",
      "PASS: All files exists!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the type of run e.g. Deployment, Pilot 1, Pilot 2, Pilot 3 .... etc.:  Pilot 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run type: Pilot 3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the pilot subfolder name e.g. Pilot 1A, Pilot 2C, Pilot 3A-B .... etc.:  Pilot 3A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pilot subfolder: Pilot 3A\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you know the 'Language' and/or 'Market code' for this file? (y/n) :  y\n",
      "\n",
      "Please enter the Language:  Turkish\n",
      "\n",
      "Please enter the Market code: eg. EN-EN for English :  TR-TR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting automated data cleaning....\n",
      "\n",
      "Dataframe created from RC file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Missing columns inserted into 'Data' sheet.\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "  Language Market  _worker_id  Score  Percentage  Grouping\n",
      "0  Turkish  TR-TR    45488787     24    1.000000  Pilot 3A\n",
      "1  Turkish  TR-TR    45638661     24    1.000000  Pilot 3A\n",
      "2  Turkish  TR-TR    45638934     24    1.000000  Pilot 3A\n",
      "3  Turkish  TR-TR    45758795     23    0.958333  Pilot 3A\n",
      "4  Turkish  TR-TR    45764098     24    1.000000  Pilot 3A\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "  Language           _id question_no_1 question_no_2 question_no_3  \\\n",
      "0  Turkish  5.868341e+09             a             c             b   \n",
      "1  Turkish  5.868379e+09             a             c             b   \n",
      "2  Turkish  5.868379e+09             a             c             b   \n",
      "3  Turkish  5.868425e+09             a             c             b   \n",
      "4  Turkish  5.868942e+09             a             c             b   \n",
      "\n",
      "   question_no_4  question_no_5  \n",
      "0            NaN            NaN  \n",
      "1            NaN            NaN  \n",
      "2            NaN            NaN  \n",
      "3            NaN            NaN  \n",
      "4            NaN            NaN  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading RC raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : RC - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : RC - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : RC - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : RC - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : RC - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : RC - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-7 : RC - Data : checking if columns in the 'Data' sheet are identical to the reference columns ...\n",
      "\u001b[92mPASS\u001b[0m: The columns in the 'Data' sheet are identical to the reference\n",
      "\u001b[1m\n",
      "RC data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_1 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_1 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "  Language Market _worker_id  Score  Percentage  Grouping\n",
      "0  Turkish  TR-TR   45488787   40.0    0.930233  Pilot 3A\n",
      "1  Turkish  TR-TR   45638661   39.0    0.906977  Pilot 3A\n",
      "2  Turkish  TR-TR   45638934   40.0    0.930233  Pilot 3A\n",
      "3  Turkish  TR-TR   45758795   39.0    0.906977  Pilot 3A\n",
      "4  Turkish  TR-TR   45764098   40.0    0.930233  Pilot 3A\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "  Language         _id rater_answer a_domain a_register b_domain b_register\n",
      "0  Turkish  5868295106          yes   season    neutral   season    neutral\n",
      "1  Turkish  5868300856          yes   season    neutral   season    neutral\n",
      "2  Turkish  5868300866          yes   season    neutral   season    neutral\n",
      "3  Turkish  5868359497          yes   season    neutral   season    neutral\n",
      "4  Turkish  5868406548          yes   season    neutral   season    neutral\n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_1 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_1 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_1 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_1 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_1 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_1 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_1 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_1 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_2 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_2 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "  Language Market _worker_id  Score  Percentage  Grouping\n",
      "0  Turkish  TR-TR   45488787   89.0        0.89  Pilot 3A\n",
      "1  Turkish  TR-TR   45638661   95.0        0.95  Pilot 3A\n",
      "2  Turkish  TR-TR   45638934   92.0        0.92  Pilot 3A\n",
      "3  Turkish  TR-TR   45758795   93.0        0.93  Pilot 3A\n",
      "4  Turkish  TR-TR   45764098   95.0        0.95  Pilot 3A\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "  Language           _id                   rater_answer a_domain a_register  \\\n",
      "0  Turkish  5.868301e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "1  Turkish  5.868344e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "2  Turkish  5.868344e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "3  Turkish  5.868410e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "4  Turkish  5.868781e+09  a_and_b_have_the_same_meaning     time     formal   \n",
      "\n",
      "  b_domain b_register  \n",
      "0     time    neutral  \n",
      "1     time    neutral  \n",
      "2     time    neutral  \n",
      "3     time    neutral  \n",
      "4     time    neutral  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_2 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_2 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_2 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_2 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_2 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_2 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_2 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_2 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Automated data cleaning completed. Cleaned excel files are located in data > processed > Pilot 3 folder. \n",
      "\n",
      "Initialize data ingestion and file checking...\n",
      "\n",
      "\n",
      "\n",
      "     Pilot    Variation\n",
      "0  Pilot 1  Pilot 1A-1B\n",
      "1  Pilot 1     Pilot 1C\n",
      "2  Pilot 1     Pilot 1D\n",
      "3  Pilot 1     Pilot 1E\n",
      "4  Pilot 2     Pilot 2A\n",
      "5  Pilot 2   Pilot 2A-A\n",
      "6  Pilot 2   Pilot 2B-A\n",
      "7  Pilot 2     Pilot 2D\n",
      "8  Pilot 3     Pilot 3A\n",
      "9  Pilot 3   Pilot 3A-A\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the pilot variation:  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 8 for 'Pilot 3A'\n",
      "\n",
      "               Survey Filename\n",
      "0  Survey Pilot 1A and 1B.xlsx\n",
      "1          Survey Pilot 2.xlsx\n",
      "2    Survey Pilot 2 and 3.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the survey filename for your pilot run:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 2 for 'Survey Pilot 2 and 3.xlsx'\n",
      "\n",
      "Data processing completed.\n",
      "\n",
      "\n",
      "  Language\n",
      "0  Turkish\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the Language you are assessing:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 0 for Turkish\n",
      "\n",
      "Generating reports ...\n",
      "\n",
      "1. Language fail rates report completed and stored in reports > deliverables > Pilot 3 > Pilot 3A > Turkish\n",
      "\n",
      "2. Summary report completed and stored in analysis > Grand Summary > RC/V1/V2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    print('\\nData processing in progress...')\n",
    "    # import data from data_processing module\n",
    "    raters, r1, r2, r3, languages, rc, v1, v2, run_value , run_value_2, survey_selected, survey_files, pilot_variation, pilot_selected, pilot_var_selected = data_processing.main()\n",
    "    print('Data processing completed.')\n",
    "    print(\"\\n\")\n",
    "    print(languages)\n",
    "    \n",
    "    # Get input language selection\n",
    "    language_selected = language_selection(languages)\n",
    "      \n",
    "    # Get data from language modification processes\n",
    "    rcR, v1R, v2R = get_time_taken_all(language_selected, rc, v1, v2)\n",
    "    \n",
    "    print('\\nGenerating reports ...')\n",
    "    \n",
    "    # Start generating fail rate reports\n",
    "    list_of_datasets, list_of_summaries = generate_all_fail_rate_reports(rcR, v1R, v2R, rc, v1, v2, run_value, pilot_var_selected)\n",
    "    \n",
    "    # Check the run type and language and create folders in reports > deliverables\n",
    "    run_folder, analysis_folder, folder_tag = file_check_create(root_path, config, language_selected, run_value, pilot_var_selected)\n",
    "    \n",
    "    # Write reports to excel file in run_folder path\n",
    "    write_fail_report_to_excel(run_folder, list_of_datasets, encode=None)\n",
    "    \n",
    "    print(f\"\\n1. Language fail rates report completed and stored in reports > deliverables > {run_value} > {pilot_var_selected} > {language_selected}\")\n",
    "    \n",
    "    # Write summaries to csv file in analysis_folder path\n",
    "    write_summary_to_csv(analysis_folder, list_of_summaries, encode=None)\n",
    "    \n",
    "    print(f\"\\n2. Summary report completed and stored in analysis > {folder_tag} > RC/V1/V2\")\n",
    "    \n",
    "    return r1, r2, r3, rc, v1, v2, pilot_var_selected, rcR, v1R, v2R, list_of_datasets, list_of_summaries\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    "    r1, r2, r3, rc, v1, v2, pilot_var_selected, rcR, v1R, v2R, list_of_datasets, list_of_summaries = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>_id</th>\n",
       "      <th>question_no_1</th>\n",
       "      <th>question_no_2</th>\n",
       "      <th>question_no_3</th>\n",
       "      <th>question_no_4</th>\n",
       "      <th>question_no_5</th>\n",
       "      <th>changes</th>\n",
       "      <th>complexity</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>...</th>\n",
       "      <th>Question 1 Skill tested</th>\n",
       "      <th>Question 2 Skill tested</th>\n",
       "      <th>Question 3 Skill tested</th>\n",
       "      <th>Question 4 Skill tested</th>\n",
       "      <th>Question 5 Skill tested</th>\n",
       "      <th>Grouping</th>\n",
       "      <th>31_language_1</th>\n",
       "      <th>survey_created_at</th>\n",
       "      <th>survey_started_at</th>\n",
       "      <th>Fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868340900</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:01:18</td>\n",
       "      <td>2020-12-23 21:58:15</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868379114</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 21:52:09</td>\n",
       "      <td>2020-12-23 21:47:05</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868379132</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:11:33</td>\n",
       "      <td>2020-12-23 22:07:06</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868424995</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868942308</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-24 07:35:27</td>\n",
       "      <td>2020-12-24 07:26:44</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5871995545</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-27 21:24:30</td>\n",
       "      <td>2020-12-27 21:23:00</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872385930</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 07:35:45</td>\n",
       "      <td>2020-12-28 07:33:19</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872888505</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 10:17:44</td>\n",
       "      <td>2020-12-28 10:12:23</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872947603</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5873505835</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>initial understanding: finding the main idea</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 19:37:56</td>\n",
       "      <td>2020-12-28 19:31:56</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows  79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language         _id question_no_1 question_no_2 question_no_3  \\\n",
       "0    Turkish  5868340900             a             c             b   \n",
       "1    Turkish  5868379114             a             c             b   \n",
       "2    Turkish  5868379132             a             c             b   \n",
       "3    Turkish  5868424995             a             c             b   \n",
       "4    Turkish  5868942308             a             c             b   \n",
       "..       ...         ...           ...           ...           ...   \n",
       "203  Turkish  5871995545             b             c             b   \n",
       "204  Turkish  5872385930             b             b             a   \n",
       "205  Turkish  5872888505             b             b             a   \n",
       "206  Turkish  5872947603             b             b             b   \n",
       "207  Turkish  5873505835             b             b             a   \n",
       "\n",
       "     question_no_4  question_no_5  \\\n",
       "0              NaN            NaN   \n",
       "1              NaN            NaN   \n",
       "2              NaN            NaN   \n",
       "3              NaN            NaN   \n",
       "4              NaN            NaN   \n",
       "..             ...            ...   \n",
       "203            NaN            NaN   \n",
       "204            NaN            NaN   \n",
       "205            NaN            NaN   \n",
       "206            NaN            NaN   \n",
       "207            NaN            NaN   \n",
       "\n",
       "                                               changes       complexity  \\\n",
       "0    two grammatical errors have been corrected \"s...  straightforward   \n",
       "1    two grammatical errors have been corrected \"s...  straightforward   \n",
       "2    two grammatical errors have been corrected \"s...  straightforward   \n",
       "3    two grammatical errors have been corrected \"s...  straightforward   \n",
       "4    two grammatical errors have been corrected \"s...  straightforward   \n",
       "..                                                 ...              ...   \n",
       "203  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "204  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "205  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "206  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "207  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "\n",
       "    familiarity  ...                     Question 1 Skill tested  \\\n",
       "0      familiar  ...  initial understanding: finding key details   \n",
       "1      familiar  ...  initial understanding: finding key details   \n",
       "2      familiar  ...  initial understanding: finding key details   \n",
       "3      familiar  ...  initial understanding: finding key details   \n",
       "4      familiar  ...  initial understanding: finding key details   \n",
       "..          ...  ...                                         ...   \n",
       "203  unfamiliar  ...  initial understanding: finding key details   \n",
       "204  unfamiliar  ...  initial understanding: finding key details   \n",
       "205  unfamiliar  ...  initial understanding: finding key details   \n",
       "206  unfamiliar  ...  initial understanding: finding key details   \n",
       "207  unfamiliar  ...  initial understanding: finding key details   \n",
       "\n",
       "                          Question 2 Skill tested  \\\n",
       "0    initial understanding: finding the main idea   \n",
       "1    initial understanding: finding the main idea   \n",
       "2    initial understanding: finding the main idea   \n",
       "3    initial understanding: finding the main idea   \n",
       "4    initial understanding: finding the main idea   \n",
       "..                                            ...   \n",
       "203  initial understanding: finding the main idea   \n",
       "204  initial understanding: finding the main idea   \n",
       "205  initial understanding: finding the main idea   \n",
       "206  initial understanding: finding the main idea   \n",
       "207  initial understanding: finding the main idea   \n",
       "\n",
       "           Question 3 Skill tested Question 4 Skill tested  \\\n",
       "0    synthesis and decision-making                       0   \n",
       "1    synthesis and decision-making                       0   \n",
       "2    synthesis and decision-making                       0   \n",
       "3    synthesis and decision-making                       0   \n",
       "4    synthesis and decision-making                       0   \n",
       "..                             ...                     ...   \n",
       "203  synthesis and decision-making                       0   \n",
       "204  synthesis and decision-making                       0   \n",
       "205  synthesis and decision-making                       0   \n",
       "206  synthesis and decision-making                       0   \n",
       "207  synthesis and decision-making                       0   \n",
       "\n",
       "    Question 5 Skill tested  Grouping  31_language_1   survey_created_at  \\\n",
       "0                       NaN  Pilot 3A  over_15_years 2020-12-23 22:01:18   \n",
       "1                       NaN  Pilot 3A  over_15_years 2020-12-23 21:52:09   \n",
       "2                       NaN  Pilot 3A  over_15_years 2020-12-23 22:11:33   \n",
       "3                       NaN        GT            NaN                 NaT   \n",
       "4                       NaN  Pilot 3A  over_15_years 2020-12-24 07:35:27   \n",
       "..                      ...       ...            ...                 ...   \n",
       "203                     NaN  Pilot 3A  over_15_years 2020-12-27 21:24:30   \n",
       "204                     NaN  Pilot 3A  over_15_years 2020-12-28 07:35:45   \n",
       "205                     NaN  Pilot 3A  over_15_years 2020-12-28 10:17:44   \n",
       "206                     NaN        GT            NaN                 NaT   \n",
       "207                     NaN  Pilot 3A  over_15_years 2020-12-28 19:37:56   \n",
       "\n",
       "      survey_started_at Fluency  \n",
       "0   2020-12-23 21:58:15  Fluent  \n",
       "1   2020-12-23 21:47:05  Fluent  \n",
       "2   2020-12-23 22:07:06  Fluent  \n",
       "3                   NaT      GT  \n",
       "4   2020-12-24 07:26:44  Fluent  \n",
       "..                  ...     ...  \n",
       "203 2020-12-27 21:23:00  Fluent  \n",
       "204 2020-12-28 07:33:19  Fluent  \n",
       "205 2020-12-28 10:12:23  Fluent  \n",
       "206                 NaT      GT  \n",
       "207 2020-12-28 19:31:56  Fluent  \n",
       "\n",
       "[208 rows x 79 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>_id</th>\n",
       "      <th>rater_answer</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>question_</th>\n",
       "      <th>...</th>\n",
       "      <th>_region</th>\n",
       "      <th>_city</th>\n",
       "      <th>_ip</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Grouping</th>\n",
       "      <th>31_language_1</th>\n",
       "      <th>survey_created_at</th>\n",
       "      <th>survey_started_at</th>\n",
       "      <th>Fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868295106</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>159.146.43.95</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:01:18</td>\n",
       "      <td>2020-12-23 21:58:15</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868300856</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>107.150.95.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:11:33</td>\n",
       "      <td>2020-12-23 22:07:06</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868300866</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>107.150.95.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 21:52:09</td>\n",
       "      <td>2020-12-23 21:47:05</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868359497</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Imus</td>\n",
       "      <td>124.106.180.38</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868406548</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Kellyville</td>\n",
       "      <td>101.179.219.27</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5871973241</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Sakarya</td>\n",
       "      <td>88.230.169.32</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-27 21:24:30</td>\n",
       "      <td>2020-12-27 21:23:00</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872312585</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>46.155.64.92</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 07:35:45</td>\n",
       "      <td>2020-12-28 07:33:19</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872622491</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Izmir</td>\n",
       "      <td>176.88.68.107</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 10:17:44</td>\n",
       "      <td>2020-12-28 10:12:23</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872921698</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Imus</td>\n",
       "      <td>124.106.180.38</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5873470863</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>159.146.40.126</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 19:37:56</td>\n",
       "      <td>2020-12-28 19:31:56</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language         _id rater_answer a_domain a_register b_domain  \\\n",
       "0     Turkish  5868295106          yes   season    neutral   season   \n",
       "1     Turkish  5868300856          yes   season    neutral   season   \n",
       "2     Turkish  5868300866          yes   season    neutral   season   \n",
       "3     Turkish  5868359497          yes   season    neutral   season   \n",
       "4     Turkish  5868406548          yes   season    neutral   season   \n",
       "...       ...         ...          ...      ...        ...      ...   \n",
       "1113  Turkish  5871973241           no   idioms    neutral   idioms   \n",
       "1114  Turkish  5872312585           no   idioms    neutral   idioms   \n",
       "1115  Turkish  5872622491           no   idioms    neutral   idioms   \n",
       "1116  Turkish  5872921698           no   idioms    neutral   idioms   \n",
       "1117  Turkish  5873470863           no   idioms    neutral   idioms   \n",
       "\n",
       "     b_register difficulty familiarity  question_  ... _region       _city  \\\n",
       "0       neutral       easy    familiar          1  ...    34.0    Istanbul   \n",
       "1       neutral       easy    familiar          1  ...    34.0    Istanbul   \n",
       "2       neutral       easy    familiar          1  ...    34.0    Istanbul   \n",
       "3       neutral       easy    familiar          1  ...    20.0        Imus   \n",
       "4       neutral       easy    familiar          1  ...     2.0  Kellyville   \n",
       "...         ...        ...         ...        ...  ...     ...         ...   \n",
       "1113    neutral       hard  unfamiliar         43  ...    54.0     Sakarya   \n",
       "1114    neutral       hard  unfamiliar         43  ...    68.0      Ankara   \n",
       "1115    neutral       hard  unfamiliar         43  ...    35.0       Izmir   \n",
       "1116    neutral       hard  unfamiliar         43  ...    20.0        Imus   \n",
       "1117    neutral       hard  unfamiliar         43  ...    34.0    Istanbul   \n",
       "\n",
       "                 _ip Answer Score  Grouping  31_language_1  \\\n",
       "0      159.146.43.95    yes     1  Pilot 3A  over_15_years   \n",
       "1      107.150.95.12    yes     1  Pilot 3A  over_15_years   \n",
       "2      107.150.95.12    yes     1  Pilot 3A  over_15_years   \n",
       "3     124.106.180.38    yes     1        GT            NaN   \n",
       "4     101.179.219.27    yes     1        GT            NaN   \n",
       "...              ...    ...   ...       ...            ...   \n",
       "1113   88.230.169.32     no     1  Pilot 3A  over_15_years   \n",
       "1114    46.155.64.92     no     1  Pilot 3A  over_15_years   \n",
       "1115   176.88.68.107     no     1  Pilot 3A  over_15_years   \n",
       "1116  124.106.180.38     no     1        GT            NaN   \n",
       "1117  159.146.40.126     no     1  Pilot 3A  over_15_years   \n",
       "\n",
       "       survey_created_at   survey_started_at Fluency  \n",
       "0    2020-12-23 22:01:18 2020-12-23 21:58:15  Fluent  \n",
       "1    2020-12-23 22:11:33 2020-12-23 22:07:06  Fluent  \n",
       "2    2020-12-23 21:52:09 2020-12-23 21:47:05  Fluent  \n",
       "3                    NaT                 NaT      GT  \n",
       "4                    NaT                 NaT      GT  \n",
       "...                  ...                 ...     ...  \n",
       "1113 2020-12-27 21:24:30 2020-12-27 21:23:00  Fluent  \n",
       "1114 2020-12-28 07:35:45 2020-12-28 07:33:19  Fluent  \n",
       "1115 2020-12-28 10:17:44 2020-12-28 10:12:23  Fluent  \n",
       "1116                 NaT                 NaT      GT  \n",
       "1117 2020-12-28 19:37:56 2020-12-28 19:31:56  Fluent  \n",
       "\n",
       "[1118 rows x 33 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>_id</th>\n",
       "      <th>rater_answer</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>question_</th>\n",
       "      <th>...</th>\n",
       "      <th>_ip</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Alternate Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Grouping</th>\n",
       "      <th>31_language_1</th>\n",
       "      <th>survey_created_at</th>\n",
       "      <th>survey_started_at</th>\n",
       "      <th>Fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868301063</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>159.146.43.95</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:01:18</td>\n",
       "      <td>2020-12-23 21:58:15</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868344334</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>107.150.95.100</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:11:33</td>\n",
       "      <td>2020-12-23 22:07:06</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868344361</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>91.140.83.182</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 21:52:09</td>\n",
       "      <td>2020-12-23 21:47:05</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868410262</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>101.179.219.27</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868780952</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.141.60.16</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-24 07:35:27</td>\n",
       "      <td>2020-12-24 07:26:44</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5871990756</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>88.230.169.32</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-27 21:24:30</td>\n",
       "      <td>2020-12-27 21:23:00</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872365862</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>46.155.64.92</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 07:35:45</td>\n",
       "      <td>2020-12-28 07:33:19</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872835237</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>176.88.68.107</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 10:17:44</td>\n",
       "      <td>2020-12-28 10:12:23</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872944308</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>124.106.180.38</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5873485594</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>159.146.40.126</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 19:37:56</td>\n",
       "      <td>2020-12-28 19:31:56</td>\n",
       "      <td>Fluent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language         _id                   rater_answer       a_domain  \\\n",
       "0     Turkish  5868301063  a_and_b_have_the_same_meaning           time   \n",
       "1     Turkish  5868344334  a_and_b_have_the_same_meaning           time   \n",
       "2     Turkish  5868344361  a_and_b_have_the_same_meaning           time   \n",
       "3     Turkish  5868410262  a_and_b_have_the_same_meaning           time   \n",
       "4     Turkish  5868780952  a_and_b_have_the_same_meaning           time   \n",
       "...       ...         ...                            ...            ...   \n",
       "2595  Turkish  5871990756        a_and_b_are_not_related  communication   \n",
       "2596  Turkish  5872365862        a_and_b_are_not_related  communication   \n",
       "2597  Turkish  5872835237        a_and_b_are_not_related  communication   \n",
       "2598  Turkish  5872944308  a_and_b_have_the_same_meaning  communication   \n",
       "2599  Turkish  5873485594        a_and_b_are_not_related  communication   \n",
       "\n",
       "          a_register           b_domain b_register difficulty familiarity  \\\n",
       "0             formal               time    neutral       easy    familiar   \n",
       "1             formal               time    neutral       easy    familiar   \n",
       "2             formal               time    neutral       easy    familiar   \n",
       "3             formal               time    neutral       easy    familiar   \n",
       "4             formal               time    neutral       easy    familiar   \n",
       "...              ...                ...        ...        ...         ...   \n",
       "2595  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2596  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2597  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2598  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2599  slang/informal  physical activity    neutral       easy    familiar   \n",
       "\n",
       "      question_  ...             _ip                         Answer  \\\n",
       "0             1  ...   159.146.43.95  a_and_b_have_the_same_meaning   \n",
       "1             1  ...  107.150.95.100  a_and_b_have_the_same_meaning   \n",
       "2             1  ...   91.140.83.182  a_and_b_have_the_same_meaning   \n",
       "3             1  ...  101.179.219.27  a_and_b_have_the_same_meaning   \n",
       "4             1  ...    31.141.60.16  a_and_b_have_the_same_meaning   \n",
       "...         ...  ...             ...                            ...   \n",
       "2595        100  ...   88.230.169.32        a_and_b_are_not_related   \n",
       "2596        100  ...    46.155.64.92        a_and_b_are_not_related   \n",
       "2597        100  ...   176.88.68.107        a_and_b_are_not_related   \n",
       "2598        100  ...  124.106.180.38        a_and_b_are_not_related   \n",
       "2599        100  ...  159.146.40.126        a_and_b_are_not_related   \n",
       "\n",
       "     Alternate Answer Score                          Answers  Grouping  \\\n",
       "0                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       "1                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       "2                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       "3                   0     1  a_and_b_have_the_same_meaning;0        GT   \n",
       "4                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       "...               ...   ...                              ...       ...   \n",
       "2595                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       "2596                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       "2597                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       "2598                0     0        a_and_b_are_not_related;0        GT   \n",
       "2599                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       "\n",
       "      31_language_1   survey_created_at   survey_started_at Fluency  \n",
       "0     over_15_years 2020-12-23 22:01:18 2020-12-23 21:58:15  Fluent  \n",
       "1     over_15_years 2020-12-23 22:11:33 2020-12-23 22:07:06  Fluent  \n",
       "2     over_15_years 2020-12-23 21:52:09 2020-12-23 21:47:05  Fluent  \n",
       "3               NaN                 NaT                 NaT      GT  \n",
       "4     over_15_years 2020-12-24 07:35:27 2020-12-24 07:26:44  Fluent  \n",
       "...             ...                 ...                 ...     ...  \n",
       "2595  over_15_years 2020-12-27 21:24:30 2020-12-27 21:23:00  Fluent  \n",
       "2596  over_15_years 2020-12-28 07:35:45 2020-12-28 07:33:19  Fluent  \n",
       "2597  over_15_years 2020-12-28 10:17:44 2020-12-28 10:12:23  Fluent  \n",
       "2598            NaN                 NaT                 NaT      GT  \n",
       "2599  over_15_years 2020-12-28 19:37:56 2020-12-28 19:31:56  Fluent  \n",
       "\n",
       "[2600 rows x 35 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pilot 3A'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot_var_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>_id</th>\n",
       "      <th>question_no_1</th>\n",
       "      <th>question_no_2</th>\n",
       "      <th>question_no_3</th>\n",
       "      <th>question_no_4</th>\n",
       "      <th>question_no_5</th>\n",
       "      <th>changes</th>\n",
       "      <th>complexity</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>...</th>\n",
       "      <th>Question 3 Skill tested</th>\n",
       "      <th>Question 4 Skill tested</th>\n",
       "      <th>Question 5 Skill tested</th>\n",
       "      <th>Grouping</th>\n",
       "      <th>31_language_1</th>\n",
       "      <th>survey_created_at</th>\n",
       "      <th>survey_started_at</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Time_Taken_Seconds</th>\n",
       "      <th>Time_Taken_Minutes_Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868340900</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:01:18</td>\n",
       "      <td>2020-12-23 21:58:15</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>160</td>\n",
       "      <td>26.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868379114</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 21:52:09</td>\n",
       "      <td>2020-12-23 21:47:05</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>291</td>\n",
       "      <td>47.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868379132</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:11:33</td>\n",
       "      <td>2020-12-23 22:07:06</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>291</td>\n",
       "      <td>46.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868424995</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "      <td>122</td>\n",
       "      <td>20.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868942308</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two grammatical errors have been corrected \"s...</td>\n",
       "      <td>straightforward</td>\n",
       "      <td>familiar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-24 07:35:27</td>\n",
       "      <td>2020-12-24 07:26:44</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>165</td>\n",
       "      <td>32.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5871995545</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-27 21:24:30</td>\n",
       "      <td>2020-12-27 21:23:00</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>380</td>\n",
       "      <td>27.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872385930</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 07:35:45</td>\n",
       "      <td>2020-12-28 07:33:19</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>413</td>\n",
       "      <td>46.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872888505</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 10:17:44</td>\n",
       "      <td>2020-12-28 10:12:23</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>678</td>\n",
       "      <td>51.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872947603</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "      <td>177</td>\n",
       "      <td>24.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5873505835</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punctuation errors: \"...ina etti, nk...\" -...</td>\n",
       "      <td>complex</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>...</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 19:37:56</td>\n",
       "      <td>2020-12-28 19:31:56</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>146</td>\n",
       "      <td>16.783333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows  81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language         _id question_no_1 question_no_2 question_no_3  \\\n",
       "0    Turkish  5868340900             a             c             b   \n",
       "1    Turkish  5868379114             a             c             b   \n",
       "2    Turkish  5868379132             a             c             b   \n",
       "3    Turkish  5868424995             a             c             b   \n",
       "4    Turkish  5868942308             a             c             b   \n",
       "..       ...         ...           ...           ...           ...   \n",
       "203  Turkish  5871995545             b             c             b   \n",
       "204  Turkish  5872385930             b             b             a   \n",
       "205  Turkish  5872888505             b             b             a   \n",
       "206  Turkish  5872947603             b             b             b   \n",
       "207  Turkish  5873505835             b             b             a   \n",
       "\n",
       "     question_no_4  question_no_5  \\\n",
       "0              NaN            NaN   \n",
       "1              NaN            NaN   \n",
       "2              NaN            NaN   \n",
       "3              NaN            NaN   \n",
       "4              NaN            NaN   \n",
       "..             ...            ...   \n",
       "203            NaN            NaN   \n",
       "204            NaN            NaN   \n",
       "205            NaN            NaN   \n",
       "206            NaN            NaN   \n",
       "207            NaN            NaN   \n",
       "\n",
       "                                               changes       complexity  \\\n",
       "0    two grammatical errors have been corrected \"s...  straightforward   \n",
       "1    two grammatical errors have been corrected \"s...  straightforward   \n",
       "2    two grammatical errors have been corrected \"s...  straightforward   \n",
       "3    two grammatical errors have been corrected \"s...  straightforward   \n",
       "4    two grammatical errors have been corrected \"s...  straightforward   \n",
       "..                                                 ...              ...   \n",
       "203  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "204  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "205  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "206  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "207  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       "\n",
       "    familiarity  ...        Question 3 Skill tested Question 4 Skill tested  \\\n",
       "0      familiar  ...  synthesis and decision-making                       0   \n",
       "1      familiar  ...  synthesis and decision-making                       0   \n",
       "2      familiar  ...  synthesis and decision-making                       0   \n",
       "3      familiar  ...  synthesis and decision-making                       0   \n",
       "4      familiar  ...  synthesis and decision-making                       0   \n",
       "..          ...  ...                            ...                     ...   \n",
       "203  unfamiliar  ...  synthesis and decision-making                       0   \n",
       "204  unfamiliar  ...  synthesis and decision-making                       0   \n",
       "205  unfamiliar  ...  synthesis and decision-making                       0   \n",
       "206  unfamiliar  ...  synthesis and decision-making                       0   \n",
       "207  unfamiliar  ...  synthesis and decision-making                       0   \n",
       "\n",
       "    Question 5 Skill tested  Grouping  31_language_1   survey_created_at  \\\n",
       "0                       NaN  Pilot 3A  over_15_years 2020-12-23 22:01:18   \n",
       "1                       NaN  Pilot 3A  over_15_years 2020-12-23 21:52:09   \n",
       "2                       NaN  Pilot 3A  over_15_years 2020-12-23 22:11:33   \n",
       "3                       NaN        GT            NaN                 NaT   \n",
       "4                       NaN  Pilot 3A  over_15_years 2020-12-24 07:35:27   \n",
       "..                      ...       ...            ...                 ...   \n",
       "203                     NaN  Pilot 3A  over_15_years 2020-12-27 21:24:30   \n",
       "204                     NaN  Pilot 3A  over_15_years 2020-12-28 07:35:45   \n",
       "205                     NaN  Pilot 3A  over_15_years 2020-12-28 10:17:44   \n",
       "206                     NaN        GT            NaN                 NaT   \n",
       "207                     NaN  Pilot 3A  over_15_years 2020-12-28 19:37:56   \n",
       "\n",
       "      survey_started_at Fluency Time_Taken_Seconds Time_Taken_Minutes_Overall  \n",
       "0   2020-12-23 21:58:15  Fluent                160                  26.983333  \n",
       "1   2020-12-23 21:47:05  Fluent                291                  47.366667  \n",
       "2   2020-12-23 22:07:06  Fluent                291                  46.983333  \n",
       "3                   NaT      GT                122                  20.533333  \n",
       "4   2020-12-24 07:26:44  Fluent                165                  32.400000  \n",
       "..                  ...     ...                ...                        ...  \n",
       "203 2020-12-27 21:23:00  Fluent                380                  27.666667  \n",
       "204 2020-12-28 07:33:19  Fluent                413                  46.766667  \n",
       "205 2020-12-28 10:12:23  Fluent                678                  51.766667  \n",
       "206                 NaT      GT                177                  24.716667  \n",
       "207 2020-12-28 19:31:56  Fluent                146                  16.783333  \n",
       "\n",
       "[208 rows x 81 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>_id</th>\n",
       "      <th>rater_answer</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>question_</th>\n",
       "      <th>...</th>\n",
       "      <th>_ip</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Grouping</th>\n",
       "      <th>31_language_1</th>\n",
       "      <th>survey_created_at</th>\n",
       "      <th>survey_started_at</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Time_Taken_Seconds</th>\n",
       "      <th>Time_Taken_Minutes_Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868295106</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>159.146.43.95</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:01:18</td>\n",
       "      <td>2020-12-23 21:58:15</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>20</td>\n",
       "      <td>8.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868300856</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>107.150.95.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:11:33</td>\n",
       "      <td>2020-12-23 22:07:06</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>36</td>\n",
       "      <td>22.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868300866</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>107.150.95.12</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 21:52:09</td>\n",
       "      <td>2020-12-23 21:47:05</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>21</td>\n",
       "      <td>23.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868359497</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>124.106.180.38</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "      <td>37</td>\n",
       "      <td>7.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868406548</td>\n",
       "      <td>yes</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>season</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>101.179.219.27</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "      <td>34</td>\n",
       "      <td>8.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5871973241</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>88.230.169.32</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-27 21:24:30</td>\n",
       "      <td>2020-12-27 21:23:00</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>4</td>\n",
       "      <td>8.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872312585</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>46.155.64.92</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 07:35:45</td>\n",
       "      <td>2020-12-28 07:33:19</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>10</td>\n",
       "      <td>10.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872622491</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>176.88.68.107</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 10:17:44</td>\n",
       "      <td>2020-12-28 10:12:23</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>9</td>\n",
       "      <td>11.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872921698</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>124.106.180.38</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "      <td>9</td>\n",
       "      <td>7.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5873470863</td>\n",
       "      <td>no</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>idioms</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hard</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>159.146.40.126</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 19:37:56</td>\n",
       "      <td>2020-12-28 19:31:56</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>9</td>\n",
       "      <td>5.516667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language         _id rater_answer a_domain a_register b_domain  \\\n",
       "0     Turkish  5868295106          yes   season    neutral   season   \n",
       "1     Turkish  5868300856          yes   season    neutral   season   \n",
       "2     Turkish  5868300866          yes   season    neutral   season   \n",
       "3     Turkish  5868359497          yes   season    neutral   season   \n",
       "4     Turkish  5868406548          yes   season    neutral   season   \n",
       "...       ...         ...          ...      ...        ...      ...   \n",
       "1113  Turkish  5871973241           no   idioms    neutral   idioms   \n",
       "1114  Turkish  5872312585           no   idioms    neutral   idioms   \n",
       "1115  Turkish  5872622491           no   idioms    neutral   idioms   \n",
       "1116  Turkish  5872921698           no   idioms    neutral   idioms   \n",
       "1117  Turkish  5873470863           no   idioms    neutral   idioms   \n",
       "\n",
       "     b_register difficulty familiarity  question_  ...             _ip Answer  \\\n",
       "0       neutral       easy    familiar          1  ...   159.146.43.95    yes   \n",
       "1       neutral       easy    familiar          1  ...   107.150.95.12    yes   \n",
       "2       neutral       easy    familiar          1  ...   107.150.95.12    yes   \n",
       "3       neutral       easy    familiar          1  ...  124.106.180.38    yes   \n",
       "4       neutral       easy    familiar          1  ...  101.179.219.27    yes   \n",
       "...         ...        ...         ...        ...  ...             ...    ...   \n",
       "1113    neutral       hard  unfamiliar         43  ...   88.230.169.32     no   \n",
       "1114    neutral       hard  unfamiliar         43  ...    46.155.64.92     no   \n",
       "1115    neutral       hard  unfamiliar         43  ...   176.88.68.107     no   \n",
       "1116    neutral       hard  unfamiliar         43  ...  124.106.180.38     no   \n",
       "1117    neutral       hard  unfamiliar         43  ...  159.146.40.126     no   \n",
       "\n",
       "     Score  Grouping  31_language_1   survey_created_at   survey_started_at  \\\n",
       "0        1  Pilot 3A  over_15_years 2020-12-23 22:01:18 2020-12-23 21:58:15   \n",
       "1        1  Pilot 3A  over_15_years 2020-12-23 22:11:33 2020-12-23 22:07:06   \n",
       "2        1  Pilot 3A  over_15_years 2020-12-23 21:52:09 2020-12-23 21:47:05   \n",
       "3        1        GT            NaN                 NaT                 NaT   \n",
       "4        1        GT            NaN                 NaT                 NaT   \n",
       "...    ...       ...            ...                 ...                 ...   \n",
       "1113     1  Pilot 3A  over_15_years 2020-12-27 21:24:30 2020-12-27 21:23:00   \n",
       "1114     1  Pilot 3A  over_15_years 2020-12-28 07:35:45 2020-12-28 07:33:19   \n",
       "1115     1  Pilot 3A  over_15_years 2020-12-28 10:17:44 2020-12-28 10:12:23   \n",
       "1116     1        GT            NaN                 NaT                 NaT   \n",
       "1117     1  Pilot 3A  over_15_years 2020-12-28 19:37:56 2020-12-28 19:31:56   \n",
       "\n",
       "     Fluency  Time_Taken_Seconds Time_Taken_Minutes_Overall  \n",
       "0     Fluent                  20                   8.233333  \n",
       "1     Fluent                  36                  22.250000  \n",
       "2     Fluent                  21                  23.566667  \n",
       "3         GT                  37                   7.716667  \n",
       "4         GT                  34                   8.183333  \n",
       "...      ...                 ...                        ...  \n",
       "1113  Fluent                   4                   8.766667  \n",
       "1114  Fluent                  10                  10.350000  \n",
       "1115  Fluent                   9                  11.283333  \n",
       "1116      GT                   9                   7.716667  \n",
       "1117  Fluent                   9                   5.516667  \n",
       "\n",
       "[1118 rows x 35 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>_id</th>\n",
       "      <th>rater_answer</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>familiarity</th>\n",
       "      <th>question_</th>\n",
       "      <th>...</th>\n",
       "      <th>Alternate Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Grouping</th>\n",
       "      <th>31_language_1</th>\n",
       "      <th>survey_created_at</th>\n",
       "      <th>survey_started_at</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Time_Taken_Seconds</th>\n",
       "      <th>Time_Taken_Minutes_Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868301063</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:01:18</td>\n",
       "      <td>2020-12-23 21:58:15</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>46</td>\n",
       "      <td>30.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868344334</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 22:11:33</td>\n",
       "      <td>2020-12-23 22:07:06</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>4</td>\n",
       "      <td>29.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868344361</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-23 21:52:09</td>\n",
       "      <td>2020-12-23 21:47:05</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>10</td>\n",
       "      <td>31.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868410262</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "      <td>19</td>\n",
       "      <td>23.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5868780952</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>time</td>\n",
       "      <td>formal</td>\n",
       "      <td>time</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_have_the_same_meaning;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-24 07:35:27</td>\n",
       "      <td>2020-12-24 07:26:44</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>11</td>\n",
       "      <td>23.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5871990756</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-27 21:24:30</td>\n",
       "      <td>2020-12-27 21:23:00</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>9</td>\n",
       "      <td>27.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872365862</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 07:35:45</td>\n",
       "      <td>2020-12-28 07:33:19</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>51</td>\n",
       "      <td>32.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872835237</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 10:17:44</td>\n",
       "      <td>2020-12-28 10:12:23</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>28</td>\n",
       "      <td>37.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5872944308</td>\n",
       "      <td>a_and_b_have_the_same_meaning</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>GT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>GT</td>\n",
       "      <td>8</td>\n",
       "      <td>22.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>5873485594</td>\n",
       "      <td>a_and_b_are_not_related</td>\n",
       "      <td>communication</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td>physical activity</td>\n",
       "      <td>neutral</td>\n",
       "      <td>easy</td>\n",
       "      <td>familiar</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>Pilot 3A</td>\n",
       "      <td>over_15_years</td>\n",
       "      <td>2020-12-28 19:37:56</td>\n",
       "      <td>2020-12-28 19:31:56</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>10</td>\n",
       "      <td>16.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language         _id                   rater_answer       a_domain  \\\n",
       "0     Turkish  5868301063  a_and_b_have_the_same_meaning           time   \n",
       "1     Turkish  5868344334  a_and_b_have_the_same_meaning           time   \n",
       "2     Turkish  5868344361  a_and_b_have_the_same_meaning           time   \n",
       "3     Turkish  5868410262  a_and_b_have_the_same_meaning           time   \n",
       "4     Turkish  5868780952  a_and_b_have_the_same_meaning           time   \n",
       "...       ...         ...                            ...            ...   \n",
       "2595  Turkish  5871990756        a_and_b_are_not_related  communication   \n",
       "2596  Turkish  5872365862        a_and_b_are_not_related  communication   \n",
       "2597  Turkish  5872835237        a_and_b_are_not_related  communication   \n",
       "2598  Turkish  5872944308  a_and_b_have_the_same_meaning  communication   \n",
       "2599  Turkish  5873485594        a_and_b_are_not_related  communication   \n",
       "\n",
       "          a_register           b_domain b_register difficulty familiarity  \\\n",
       "0             formal               time    neutral       easy    familiar   \n",
       "1             formal               time    neutral       easy    familiar   \n",
       "2             formal               time    neutral       easy    familiar   \n",
       "3             formal               time    neutral       easy    familiar   \n",
       "4             formal               time    neutral       easy    familiar   \n",
       "...              ...                ...        ...        ...         ...   \n",
       "2595  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2596  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2597  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2598  slang/informal  physical activity    neutral       easy    familiar   \n",
       "2599  slang/informal  physical activity    neutral       easy    familiar   \n",
       "\n",
       "      question_  ... Alternate Answer Score                          Answers  \\\n",
       "0             1  ...                0     1  a_and_b_have_the_same_meaning;0   \n",
       "1             1  ...                0     1  a_and_b_have_the_same_meaning;0   \n",
       "2             1  ...                0     1  a_and_b_have_the_same_meaning;0   \n",
       "3             1  ...                0     1  a_and_b_have_the_same_meaning;0   \n",
       "4             1  ...                0     1  a_and_b_have_the_same_meaning;0   \n",
       "...         ...  ...              ...   ...                              ...   \n",
       "2595        100  ...                0     1        a_and_b_are_not_related;0   \n",
       "2596        100  ...                0     1        a_and_b_are_not_related;0   \n",
       "2597        100  ...                0     1        a_and_b_are_not_related;0   \n",
       "2598        100  ...                0     0        a_and_b_are_not_related;0   \n",
       "2599        100  ...                0     1        a_and_b_are_not_related;0   \n",
       "\n",
       "      Grouping  31_language_1   survey_created_at   survey_started_at Fluency  \\\n",
       "0     Pilot 3A  over_15_years 2020-12-23 22:01:18 2020-12-23 21:58:15  Fluent   \n",
       "1     Pilot 3A  over_15_years 2020-12-23 22:11:33 2020-12-23 22:07:06  Fluent   \n",
       "2     Pilot 3A  over_15_years 2020-12-23 21:52:09 2020-12-23 21:47:05  Fluent   \n",
       "3           GT            NaN                 NaT                 NaT      GT   \n",
       "4     Pilot 3A  over_15_years 2020-12-24 07:35:27 2020-12-24 07:26:44  Fluent   \n",
       "...        ...            ...                 ...                 ...     ...   \n",
       "2595  Pilot 3A  over_15_years 2020-12-27 21:24:30 2020-12-27 21:23:00  Fluent   \n",
       "2596  Pilot 3A  over_15_years 2020-12-28 07:35:45 2020-12-28 07:33:19  Fluent   \n",
       "2597  Pilot 3A  over_15_years 2020-12-28 10:17:44 2020-12-28 10:12:23  Fluent   \n",
       "2598        GT            NaN                 NaT                 NaT      GT   \n",
       "2599  Pilot 3A  over_15_years 2020-12-28 19:37:56 2020-12-28 19:31:56  Fluent   \n",
       "\n",
       "      Time_Taken_Seconds Time_Taken_Minutes_Overall  \n",
       "0                     46                  30.383333  \n",
       "1                      4                  29.250000  \n",
       "2                     10                  31.450000  \n",
       "3                     19                  23.016667  \n",
       "4                     11                  23.516667  \n",
       "...                  ...                        ...  \n",
       "2595                   9                  27.883333  \n",
       "2596                  51                  32.600000  \n",
       "2597                  28                  37.183333  \n",
       "2598                   8                  22.150000  \n",
       "2599                  10                  16.166667  \n",
       "\n",
       "[2600 rows x 37 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Near Exact Match':    Language Fluency    _unit_id  question_                     a_domain  \\\n",
       " 0   Turkish  Fluent  2914019180          6                architectural   \n",
       " 1   Turkish  Fluent  2914019177          3                architectural   \n",
       " 2   Turkish  Fluent  2914019183          9                       nature   \n",
       " 3   Turkish  Fluent  2914019185         11            Literature-cinema   \n",
       " 4   Turkish  Fluent  2914019200         26                   night life   \n",
       " 5   Turkish  Fluent  2914019198         24                         verb   \n",
       " 6   Turkish  Fluent  2914019179          5                       idioms   \n",
       " 7   Turkish  Fluent  2914019196         22                      politic   \n",
       " 8   Turkish  Fluent  2914019209         35                  house items   \n",
       " 9   Turkish  Fluent  2914019184         10                       idioms   \n",
       " 10  Turkish  Fluent  2914019207         33                general words   \n",
       " 11  Turkish  Fluent  2914019215         41                       idioms   \n",
       " 12  Turkish  Fluent  2914019181          7                     vehicles   \n",
       " 13  Turkish  Fluent  2914019187         13                     politics   \n",
       " 14  Turkish  Fluent  2914019190         16                  measurement   \n",
       " 15  Turkish  Fluent  2914019208         34                       idioms   \n",
       " 16  Turkish  Fluent  2914019212         38                       idioms   \n",
       " 17  Turkish      GT  2914019179          5                       idioms   \n",
       " 18  Turkish      GT  2914019182          8  bank stock exchange/economy   \n",
       " 19  Turkish      GT  2914019183          9                       nature   \n",
       " 20  Turkish      GT  2914019188         14                     location   \n",
       " 21  Turkish      GT  2914019198         24                         verb   \n",
       " 22  Turkish      GT  2914019201         37                       idioms   \n",
       " 23  Turkish      GT  2914019212         38                       idioms   \n",
       " 24  Turkish      GT  2914019214         40                       idioms   \n",
       " 25  Turkish      GT  2914019215         41                       idioms   \n",
       " 26  Turkish      GT  2914019185         11            Literature-cinema   \n",
       " 27  Turkish      GT  2914019200         26                   night life   \n",
       " 28  Turkish      GT  2914019204         30                   Literature   \n",
       " 29  Turkish      GT  2914019208         34                       idioms   \n",
       " 30  Turkish      GT  2914019210         36                       idioms   \n",
       " 31  Turkish      GT  2914019211         37                       idioms   \n",
       " \n",
       "         a_register    wordphrase_a                     b_domain  \\\n",
       " 0        technical            at                architectural   \n",
       " 1           formal           konut                architectural   \n",
       " 2          neutral           sahil                       nature   \n",
       " 3        technical        karakter            literature-cinema   \n",
       " 4   slang/informal     fitil olmak                   night life   \n",
       " 5   slang/informal       tav olmak                         verb   \n",
       " 6          neutral      gz koymak                       idioms   \n",
       " 7           formal         ittifak                      politic   \n",
       " 8          neutral          grgr                       idioms   \n",
       " 9          neutral    yenik dmek                general words   \n",
       " 10         neutral           sebep                general words   \n",
       " 11         neutral       laf amak                       idioms   \n",
       " 12          formal        otomobil                     vehicles   \n",
       " 13         neutral           snr                     politics   \n",
       " 14         neutral           buket                   mesurement   \n",
       " 15  slang/informal     duman etmek                       idioms   \n",
       " 16  slang/informal     hava basmak                       idioms   \n",
       " 17         neutral      gz koymak                       idioms   \n",
       " 18       technical             pay  bank stock exchange/economy   \n",
       " 19         neutral           sahil                       nature   \n",
       " 20          formal            rak                     location   \n",
       " 21  slang/informal       tav olmak                         verb   \n",
       " 22  slang/informal    ayvay yemek                         food   \n",
       " 23  slang/informal     hava basmak                       idioms   \n",
       " 24  slang/informal   sinek avlamak                       idioms   \n",
       " 25         neutral       laf amak                       idioms   \n",
       " 26       technical        karakter            literature-cinema   \n",
       " 27  slang/informal     fitil olmak                   night life   \n",
       " 28         neutral           roman                   Literature   \n",
       " 29  slang/informal     duman etmek                       idioms   \n",
       " 30         neutral     volta atmak                       idioms   \n",
       " 31  slang/informal   buuk atmak                       idioms   \n",
       " \n",
       "         b_register         wordphrase_b difficulty Answer  Score  \\\n",
       " 0          neutral                  dam       hard     no      0   \n",
       " 1          neutral                daire       hard     no      0   \n",
       " 2          neutral                 plaj     medium     no      0   \n",
       " 3        technical                  tip       hard     no      0   \n",
       " 4          neutral         sarho olmak       hard    yes      0   \n",
       " 5   slang/informal          tava gelmek     medium    yes      0   \n",
       " 6          neutral           gz dikmek       hard    yes      0   \n",
       " 7          neutral              anlama     medium    yes      0   \n",
       " 8   slang/informal        grgr gemek       hard     no      0   \n",
       " 9          neutral         malup olmak     medium    yes      0   \n",
       " 10         neutral                neden     medium    yes      0   \n",
       " 11         neutral            laf atmak     medium     no      0   \n",
       " 12         neutral                araba       easy    yes      0   \n",
       " 13          formal                hudut     medium    yes      0   \n",
       " 14         neutral                demet       easy    yes      0   \n",
       " 15  slang/informal          duman olmak       hard     no      0   \n",
       " 16  slang/informal       havasn almak       hard     no      0   \n",
       " 17         neutral           gz dikmek       hard    yes      0   \n",
       " 18       technical                hisse       hard    yes      0   \n",
       " 19         neutral                 plaj     medium     no      0   \n",
       " 20         neutral                 uzak     medium    yes      0   \n",
       " 21  slang/informal          tava gelmek     medium    yes      0   \n",
       " 22         neutral           ayva yemek       hard     no      0   \n",
       " 23  slang/informal       havasn almak       hard     no      0   \n",
       " 24         neutral       gafil avlanmak     medium     no      0   \n",
       " 25         neutral            laf atmak     medium     no      0   \n",
       " 26       technical                  tip       hard     no      0   \n",
       " 27         neutral         sarho olmak       hard    yes      0   \n",
       " 28         neutral          izgi roman     medium     no      0   \n",
       " 29  slang/informal          duman olmak       hard     no      0   \n",
       " 30         neutral           olta atmak       hard     no      0   \n",
       " 31         neutral   aa be yukar     medium     no      0   \n",
       " \n",
       "     Count_of_Test_Takers  Total_Test_Takers  Fail_Rate  \n",
       " 0                     20                 24       0.83  \n",
       " 1                     17                 24       0.71  \n",
       " 2                     14                 24       0.58  \n",
       " 3                     11                 24       0.46  \n",
       " 4                     10                 24       0.42  \n",
       " 5                      7                 24       0.29  \n",
       " 6                      3                 24       0.12  \n",
       " 7                      3                 24       0.12  \n",
       " 8                      3                 24       0.12  \n",
       " 9                      2                 24       0.08  \n",
       " 10                     2                 24       0.08  \n",
       " 11                     2                 24       0.08  \n",
       " 12                     1                 24       0.04  \n",
       " 13                     1                 24       0.04  \n",
       " 14                     1                 24       0.04  \n",
       " 15                     1                 24       0.04  \n",
       " 16                     1                 24       0.04  \n",
       " 17                     2                  2       1.00  \n",
       " 18                     2                  2       1.00  \n",
       " 19                     2                  2       1.00  \n",
       " 20                     2                  2       1.00  \n",
       " 21                     2                  2       1.00  \n",
       " 22                     2                  2       1.00  \n",
       " 23                     2                  2       1.00  \n",
       " 24                     2                  2       1.00  \n",
       " 25                     2                  2       1.00  \n",
       " 26                     1                  2       0.50  \n",
       " 27                     1                  2       0.50  \n",
       " 28                     1                  2       0.50  \n",
       " 29                     1                  2       0.50  \n",
       " 30                     1                  2       0.50  \n",
       " 31                     1                  2       0.50  ,\n",
       " 'Close Match':     Language Fluency    _unit_id  question_       a_domain      a_register  \\\n",
       " 0    Turkish  Fluent  2914019221          2       politics          formal   \n",
       " 1    Turkish  Fluent  2914019225          6        clothes         neutral   \n",
       " 2    Turkish  Fluent  2914019226          7         nature          formal   \n",
       " 3    Turkish  Fluent  2914019229         10    house items         neutral   \n",
       " 4    Turkish  Fluent  2914019233         14           food         neutral   \n",
       " ..       ...     ...         ...        ...            ...             ...   \n",
       " 119  Turkish      GT  2914019314         95       conflict  slang/informal   \n",
       " 120  Turkish      GT  2914019316         97  communication  slang/informal   \n",
       " 121  Turkish      GT  2914019317         98  communication  slang/informal   \n",
       " 122  Turkish      GT  2914019318         99  communication  slang/informal   \n",
       " 123  Turkish      GT  2914019319        100  communication  slang/informal   \n",
       " \n",
       "             wordphrase_a           b_domain      b_register  \\\n",
       " 0                siyaset           politics         neutral   \n",
       " 1                  ark            clothes         neutral   \n",
       " 2                  nar             nature         neutral   \n",
       " 3                  kadeh        house items         neutral   \n",
       " 4                  pasta               food         neutral   \n",
       " ..                   ...                ...             ...   \n",
       " 119       arza karmak         technology         neutral   \n",
       " 120             laflamak      communication  slang/informal   \n",
       " 121  bann etini yemek             living  slang/informal   \n",
       " 122           azar yemek      communication         neutral   \n",
       " 123      birine taklmak  physical activity         neutral   \n",
       " \n",
       "                 wordphrase_b difficulty                          Answers  \\\n",
       " 0                   politika     medium  a_and_b_have_the_same_meaning;0   \n",
       " 1                   ayakkab     medium      a_is_more_specific_than_b;0   \n",
       " 2                       aa       hard      a_is_more_specific_than_b;0   \n",
       " 3                     bardak       easy      a_is_more_specific_than_b;0   \n",
       " 4                    makarna       easy            a_and_b_are_related;0   \n",
       " ..                       ...        ...                              ...   \n",
       " 119              arzalanmak       hard        a_and_b_are_not_related;0   \n",
       " 120           muhabbet etmek     medium  a_and_b_have_the_same_meaning;0   \n",
       " 121  bann aresine bakmak       easy        a_and_b_are_not_related;0   \n",
       " 122                azarlamak     medium            a_and_b_are_related;0   \n",
       " 123        bir eye taklmak       easy        a_and_b_are_not_related;0   \n",
       " \n",
       "      a_and_b_are_not_related  a_and_b_are_related  \\\n",
       " 0                        NaN                 0.04   \n",
       " 1                        NaN                 0.08   \n",
       " 2                        NaN                  NaN   \n",
       " 3                        NaN                 0.25   \n",
       " 4                       0.25                  NaN   \n",
       " ..                       ...                  ...   \n",
       " 119                      NaN                  NaN   \n",
       " 120                      NaN                  NaN   \n",
       " 121                      NaN                  NaN   \n",
       " 122                     0.50                  NaN   \n",
       " 123                      NaN                 0.50   \n",
       " \n",
       "      a_and_b_have_the_same_meaning  a_is_more_specific_than_b  \\\n",
       " 0                              NaN                        NaN   \n",
       " 1                             0.17                        NaN   \n",
       " 2                             0.04                        NaN   \n",
       " 3                              NaN                        NaN   \n",
       " 4                              NaN                        NaN   \n",
       " ..                             ...                        ...   \n",
       " 119                           0.50                        NaN   \n",
       " 120                            NaN                        NaN   \n",
       " 121                           0.50                        NaN   \n",
       " 122                            NaN                        NaN   \n",
       " 123                           0.50                        NaN   \n",
       " \n",
       "      b_is_more_specific_than_a  Count_of_Test_Takers  Total_Test_Takers  \\\n",
       " 0                          NaN                     1                 24   \n",
       " 1                          NaN                     6                 24   \n",
       " 2                          NaN                     1                 24   \n",
       " 3                          NaN                     6                 24   \n",
       " 4                          NaN                     6                 24   \n",
       " ..                         ...                   ...                ...   \n",
       " 119                        0.5                     2                  2   \n",
       " 120                        1.0                     2                  2   \n",
       " 121                        0.5                     2                  2   \n",
       " 122                        0.5                     2                  2   \n",
       " 123                        NaN                     2                  2   \n",
       " \n",
       "      Overall_Fail_Rate  \n",
       " 0                 0.04  \n",
       " 1                 0.25  \n",
       " 2                 0.04  \n",
       " 3                 0.25  \n",
       " 4                 0.25  \n",
       " ..                 ...  \n",
       " 119               1.00  \n",
       " 120               1.00  \n",
       " 121               1.00  \n",
       " 122               1.00  \n",
       " 123               1.00  \n",
       " \n",
       " [124 rows x 20 columns],\n",
       " 'Reading Comprehension':    Language Fluency    _unit_id                                     title  \\\n",
       " 0   Turkish  Fluent  2914019342     Pandemi Sonras Galatasaray'n Durumu   \n",
       " 1   Turkish  Fluent  2914019338                        Yapay Sinir Alar   \n",
       " 2   Turkish  Fluent  2914019339                                    Tekila   \n",
       " 3   Turkish  Fluent  2914019338                        Yapay Sinir Alar   \n",
       " 4   Turkish  Fluent  2914019339                                    Tekila   \n",
       " 5   Turkish  Fluent  2914019344             Michel Foucault'nun Felsefesi   \n",
       " 6   Turkish  Fluent  2914019337                 Ispana Nasl Tketmeli?   \n",
       " 7   Turkish  Fluent  2914019343  Elon Musk'tan Bill Gates'e: Ta kafal\\n   \n",
       " 8   Turkish  Fluent  2914019344             Michel Foucault'nun Felsefesi   \n",
       " 9   Turkish      GT  2914019338                        Yapay Sinir Alar   \n",
       " 10  Turkish      GT  2914019342     Pandemi Sonras Galatasaray'n Durumu   \n",
       " 11  Turkish      GT  2914019343  Elon Musk'tan Bill Gates'e: Ta kafal\\n   \n",
       " 12  Turkish      GT  2914019337                 Ispana Nasl Tketmeli?   \n",
       " 13  Turkish      GT  2914019339                                    Tekila   \n",
       " 14  Turkish      GT  2914019340                           Kahve Abonelii   \n",
       " 15  Turkish      GT  2914019340                           Kahve Abonelii   \n",
       " 16  Turkish      GT  2914019343  Elon Musk'tan Bill Gates'e: Ta kafal\\n   \n",
       " 17  Turkish      GT  2914019344             Michel Foucault'nun Felsefesi   \n",
       " 18  Turkish      GT  2914019344             Michel Foucault'nun Felsefesi   \n",
       " \n",
       "     test_  Score    Question Difficulty   register  \\\n",
       " 0       6      0  Question 1       easy   informal   \n",
       " 1       2      0  Question 3       hard  technical   \n",
       " 2       3      0  Question 3       hard    neutral   \n",
       " 3       2      0  Question 1       easy  technical   \n",
       " 4       3      0  Question 1       easy    neutral   \n",
       " 5       8      0  Question 3       hard  technical   \n",
       " 6       1      0  Question 2     medium     formal   \n",
       " 7       7      0  Question 2     medium     formal   \n",
       " 8       8      0  Question 2     medium  technical   \n",
       " 9       2      0  Question 2     medium  technical   \n",
       " 10      6      0  Question 1       easy   informal   \n",
       " 11      7      0  Question 1       easy     formal   \n",
       " 12      1      0  Question 2     medium     formal   \n",
       " 13      3      0  Question 3       hard    neutral   \n",
       " 14      4      0  Question 2     medium    neutral   \n",
       " 15      4      0  Question 3       hard    neutral   \n",
       " 16      7      0  Question 3       hard     formal   \n",
       " 17      8      0  Question 1       easy  technical   \n",
       " 18      8      0  Question 3       hard  technical   \n",
       " \n",
       "                                            Skill  Count  Total  Fail_Rate  \n",
       " 0     initial understanding: finding key details      7     24       0.29  \n",
       " 1                  synthesis and decision-making      4     24       0.17  \n",
       " 2                  synthesis and decision-making      4     24       0.17  \n",
       " 3     initial understanding: finding key details      3     24       0.12  \n",
       " 4     initial understanding: finding key details      3     24       0.12  \n",
       " 5                  synthesis and decision-making      3     24       0.12  \n",
       " 6   initial understanding: finding the main idea      1     24       0.04  \n",
       " 7                  synthesis and decision-making      1     24       0.04  \n",
       " 8   initial understanding: finding the main idea      1     24       0.04  \n",
       " 9   initial understanding: finding the main idea      2      2       1.00  \n",
       " 10    initial understanding: finding key details      2      2       1.00  \n",
       " 11    initial understanding: finding key details      2      2       1.00  \n",
       " 12  initial understanding: finding the main idea      1      2       0.50  \n",
       " 13                 synthesis and decision-making      1      2       0.50  \n",
       " 14    initial understanding: finding key details      1      2       0.50  \n",
       " 15                 synthesis and decision-making      1      2       0.50  \n",
       " 16                 synthesis and decision-making      1      2       0.50  \n",
       " 17    initial understanding: finding key details      1      2       0.50  \n",
       " 18                 synthesis and decision-making      1      2       0.50  ,\n",
       " 'RC with Answers':    Language Fluency    _unit_id                                     title  \\\n",
       " 0   Turkish  Fluent  2914019337                 Ispana Nasl Tketmeli?   \n",
       " 1   Turkish  Fluent  2914019338                        Yapay Sinir Alar   \n",
       " 2   Turkish  Fluent  2914019338                        Yapay Sinir Alar   \n",
       " 3   Turkish  Fluent  2914019338                        Yapay Sinir Alar   \n",
       " 4   Turkish  Fluent  2914019339                                    Tekila   \n",
       " 5   Turkish  Fluent  2914019339                                    Tekila   \n",
       " 6   Turkish  Fluent  2914019339                                    Tekila   \n",
       " 7   Turkish  Fluent  2914019342     Pandemi Sonras Galatasaray'n Durumu   \n",
       " 8   Turkish  Fluent  2914019343  Elon Musk'tan Bill Gates'e: Ta kafal\\n   \n",
       " 9   Turkish  Fluent  2914019344             Michel Foucault'nun Felsefesi   \n",
       " 10  Turkish  Fluent  2914019344             Michel Foucault'nun Felsefesi   \n",
       " 11  Turkish  Fluent  2914019344             Michel Foucault'nun Felsefesi   \n",
       " 12  Turkish      GT  2914019337                 Ispana Nasl Tketmeli?   \n",
       " 13  Turkish      GT  2914019338                        Yapay Sinir Alar   \n",
       " 14  Turkish      GT  2914019338                        Yapay Sinir Alar   \n",
       " 15  Turkish      GT  2914019339                                    Tekila   \n",
       " 16  Turkish      GT  2914019340                           Kahve Abonelii   \n",
       " 17  Turkish      GT  2914019340                           Kahve Abonelii   \n",
       " 18  Turkish      GT  2914019342     Pandemi Sonras Galatasaray'n Durumu   \n",
       " 19  Turkish      GT  2914019343  Elon Musk'tan Bill Gates'e: Ta kafal\\n   \n",
       " 20  Turkish      GT  2914019343  Elon Musk'tan Bill Gates'e: Ta kafal\\n   \n",
       " 21  Turkish      GT  2914019343  Elon Musk'tan Bill Gates'e: Ta kafal\\n   \n",
       " 22  Turkish      GT  2914019344             Michel Foucault'nun Felsefesi   \n",
       " 23  Turkish      GT  2914019344             Michel Foucault'nun Felsefesi   \n",
       " \n",
       "     test_ Difficulty   register                                         Skill  \\\n",
       " 0       1     medium     formal  initial understanding: finding the main idea   \n",
       " 1       2       easy  technical    initial understanding: finding key details   \n",
       " 2       2       easy  technical    initial understanding: finding key details   \n",
       " 3       2       hard  technical                 synthesis and decision-making   \n",
       " 4       3       easy    neutral    initial understanding: finding key details   \n",
       " 5       3       hard    neutral                 synthesis and decision-making   \n",
       " 6       3       hard    neutral                 synthesis and decision-making   \n",
       " 7       6       easy   informal    initial understanding: finding key details   \n",
       " 8       7     medium     formal                 synthesis and decision-making   \n",
       " 9       8     medium  technical  initial understanding: finding the main idea   \n",
       " 10      8       hard  technical                 synthesis and decision-making   \n",
       " 11      8       hard  technical                 synthesis and decision-making   \n",
       " 12      1     medium     formal  initial understanding: finding the main idea   \n",
       " 13      2     medium  technical  initial understanding: finding the main idea   \n",
       " 14      2     medium  technical  initial understanding: finding the main idea   \n",
       " 15      3       hard    neutral                 synthesis and decision-making   \n",
       " 16      4     medium    neutral    initial understanding: finding key details   \n",
       " 17      4       hard    neutral                 synthesis and decision-making   \n",
       " 18      6       easy   informal    initial understanding: finding key details   \n",
       " 19      7       easy     formal    initial understanding: finding key details   \n",
       " 20      7       easy     formal    initial understanding: finding key details   \n",
       " 21      7       hard     formal                 synthesis and decision-making   \n",
       " 22      8       easy  technical    initial understanding: finding key details   \n",
       " 23      8       hard  technical                 synthesis and decision-making   \n",
       " \n",
       "       Question Actual_Answer_Letter  \\\n",
       " 0   Question 2                    c   \n",
       " 1   Question 1                    a   \n",
       " 2   Question 1                    a   \n",
       " 3   Question 3                    b   \n",
       " 4   Question 1                    b   \n",
       " 5   Question 3                    b   \n",
       " 6   Question 3                    b   \n",
       " 7   Question 1                    a   \n",
       " 8   Question 2                    b   \n",
       " 9   Question 2                    b   \n",
       " 10  Question 3                    a   \n",
       " 11  Question 3                    a   \n",
       " 12  Question 2                    c   \n",
       " 13  Question 2                    c   \n",
       " 14  Question 2                    c   \n",
       " 15  Question 3                    b   \n",
       " 16  Question 2                    a   \n",
       " 17  Question 3                    c   \n",
       " 18  Question 1                    a   \n",
       " 19  Question 1                    b   \n",
       " 20  Question 1                    b   \n",
       " 21  Question 3                    c   \n",
       " 22  Question 1                    b   \n",
       " 23  Question 3                    a   \n",
       " \n",
       "                                    Actual_Answer_Text Rater_Answer_Letter  \\\n",
       " 0      deal hazrlama yntemi ve piirme sresine.\\n                   b   \n",
       " 1   YSA'lar insan beynini taklit ederek problemler...                   b   \n",
       " 2   YSA'lar insan beynini taklit ederek problemler...                   c   \n",
       " 3                                          Yapay zeka                   a   \n",
       " 4   Avrupallar ilk olarak tekilay ktalararas y...                   a   \n",
       " 5         eriinin yzde yz agave olup olmadna.                   a   \n",
       " 6         eriinin yzde yz agave olup olmadna.                   c   \n",
       " 7   Galatasaray'n baz oyuncular tam performans ...                   c   \n",
       " 8                  Kendisinin risk grubunda olmamas.                   a   \n",
       " 9   Foucaultnun amac kapitalizmi darda tutan ...                   c   \n",
       " 10  Foucault'yu kendine yakn bulsa da gelitirdi...                   b   \n",
       " 11  Foucault'yu kendine yakn bulsa da gelitirdi...                   c   \n",
       " 12     deal hazrlama yntemi ve piirme sresine.\\n                   a   \n",
       " 13          YSA'larn neden esinlenerek tasarland.                   a   \n",
       " 14          YSA'larn neden esinlenerek tasarland.                   b   \n",
       " 15        eriinin yzde yz agave olup olmadna.                   a   \n",
       " 16                                   Kavrulma zaman.                   c   \n",
       " 17  Evde hala kahve varsa bir sonraki sevkiyat er...                   b   \n",
       " 18  Galatasaray'n baz oyuncular tam performans ...                   c   \n",
       " 19  Harvard epidemiyoloji ekibi antikor almalar...                   a   \n",
       " 20  Harvard epidemiyoloji ekibi antikor almalar...                   c   \n",
       " 21  Koronavirs iin fazla tedbir alndn savun...                   a   \n",
       " 22              ok karmak ve detayl bir modeldir.                   a   \n",
       " 23  Foucault'yu kendine yakn bulsa da gelitirdi...                   b   \n",
       " \n",
       "                                     Rater_Answer_Text  Count  Total  Fail_Rate  \n",
       " 0                       indeki faydal vitaminlere.      1     24       0.04  \n",
       " 1               YSA basit biyolojik sinir sistemidir.      2     24       0.08  \n",
       " 2           YSA'lar yaayarak veya deneyerek renir.      1     24       0.04  \n",
       " 3                                            Biyoloji      4     24       0.17  \n",
       " 4   Tekila agave denilen bir tr kaktsten yaplma...      3     24       0.12  \n",
       " 5      Agavenin yksek blgede yetiip yetimediine.      2     24       0.08  \n",
       " 6          Markann adnda \"Tequila\" olup olmadna.      2     24       0.08  \n",
       " 7   Galatasaray pandemiden oyuncular hastaland...      7     24       0.29  \n",
       " 8          Hastaln lm orannn ok dk olmas.      1     24       0.04  \n",
       " 9   Foucault kapitalizmin topluma olan kt etkile...      1     24       0.04  \n",
       " 10  Kapitalizmin toplumdaki etkisinin eitli oldu...      2     24       0.08  \n",
       " 11  Foucault'nun modelini Batlamyus'un modeline k...      1     24       0.04  \n",
       " 12                    Semizotu ile ortak faydalarna.      1      2       0.50  \n",
       " 13     Nronlarn hangi farkl ekillerde baland.      1      2       0.50  \n",
       " 14  YSA'larn problem zerken hangi yntemleri ku...      1      2       0.50  \n",
       " 15     Agavenin yksek blgede yetiip yetimediine.      1      2       0.50  \n",
       " 16                           Kahve ekirdeinin tr.      1      2       0.50  \n",
       " 17  Kahvenin ne kadar kavrulmu olacana karar ve...      1      2       0.50  \n",
       " 18  Galatasaray pandemiden oyuncular hastaland...      2      2       1.00  \n",
       " 19  Bill Gates, CureVac a makinelerini yapmaktadr.      1      2       0.50  \n",
       " 20  Elon Musk a retimi iin hibir ey yapmamak...      1      2       0.50  \n",
       " 21  nsanlarn koronavirs asn olmasnn gerek...      1      2       0.50  \n",
       " 22              Temelleri Antik dneme dayanmaktadr.      1      2       0.50  \n",
       " 23  Kapitalizmin toplumdaki etkisinin eitli oldu...      1      2       0.50  }"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pilot 3_rc':     Language         _id question_no_1 question_no_2 question_no_3  \\\n",
       " 0    Turkish  5868340900             a             c             b   \n",
       " 1    Turkish  5868379114             a             c             b   \n",
       " 2    Turkish  5868379132             a             c             b   \n",
       " 3    Turkish  5868424995             a             c             b   \n",
       " 4    Turkish  5868942308             a             c             b   \n",
       " ..       ...         ...           ...           ...           ...   \n",
       " 203  Turkish  5871995545             b             c             b   \n",
       " 204  Turkish  5872385930             b             b             a   \n",
       " 205  Turkish  5872888505             b             b             a   \n",
       " 206  Turkish  5872947603             b             b             b   \n",
       " 207  Turkish  5873505835             b             b             a   \n",
       " \n",
       "      question_no_4  question_no_5  \\\n",
       " 0              NaN            NaN   \n",
       " 1              NaN            NaN   \n",
       " 2              NaN            NaN   \n",
       " 3              NaN            NaN   \n",
       " 4              NaN            NaN   \n",
       " ..             ...            ...   \n",
       " 203            NaN            NaN   \n",
       " 204            NaN            NaN   \n",
       " 205            NaN            NaN   \n",
       " 206            NaN            NaN   \n",
       " 207            NaN            NaN   \n",
       " \n",
       "                                                changes       complexity  \\\n",
       " 0    two grammatical errors have been corrected \"s...  straightforward   \n",
       " 1    two grammatical errors have been corrected \"s...  straightforward   \n",
       " 2    two grammatical errors have been corrected \"s...  straightforward   \n",
       " 3    two grammatical errors have been corrected \"s...  straightforward   \n",
       " 4    two grammatical errors have been corrected \"s...  straightforward   \n",
       " ..                                                 ...              ...   \n",
       " 203  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       " 204  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       " 205  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       " 206  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       " 207  punctuation errors: \"...ina etti, nk...\" -...          complex   \n",
       " \n",
       "     familiarity  ...                     Question 1 Skill tested  \\\n",
       " 0      familiar  ...  initial understanding: finding key details   \n",
       " 1      familiar  ...  initial understanding: finding key details   \n",
       " 2      familiar  ...  initial understanding: finding key details   \n",
       " 3      familiar  ...  initial understanding: finding key details   \n",
       " 4      familiar  ...  initial understanding: finding key details   \n",
       " ..          ...  ...                                         ...   \n",
       " 203  unfamiliar  ...  initial understanding: finding key details   \n",
       " 204  unfamiliar  ...  initial understanding: finding key details   \n",
       " 205  unfamiliar  ...  initial understanding: finding key details   \n",
       " 206  unfamiliar  ...  initial understanding: finding key details   \n",
       " 207  unfamiliar  ...  initial understanding: finding key details   \n",
       " \n",
       "                           Question 2 Skill tested  \\\n",
       " 0    initial understanding: finding the main idea   \n",
       " 1    initial understanding: finding the main idea   \n",
       " 2    initial understanding: finding the main idea   \n",
       " 3    initial understanding: finding the main idea   \n",
       " 4    initial understanding: finding the main idea   \n",
       " ..                                            ...   \n",
       " 203  initial understanding: finding the main idea   \n",
       " 204  initial understanding: finding the main idea   \n",
       " 205  initial understanding: finding the main idea   \n",
       " 206  initial understanding: finding the main idea   \n",
       " 207  initial understanding: finding the main idea   \n",
       " \n",
       "            Question 3 Skill tested Question 4 Skill tested  \\\n",
       " 0    synthesis and decision-making                       0   \n",
       " 1    synthesis and decision-making                       0   \n",
       " 2    synthesis and decision-making                       0   \n",
       " 3    synthesis and decision-making                       0   \n",
       " 4    synthesis and decision-making                       0   \n",
       " ..                             ...                     ...   \n",
       " 203  synthesis and decision-making                       0   \n",
       " 204  synthesis and decision-making                       0   \n",
       " 205  synthesis and decision-making                       0   \n",
       " 206  synthesis and decision-making                       0   \n",
       " 207  synthesis and decision-making                       0   \n",
       " \n",
       "     Question 5 Skill tested  Grouping  31_language_1   survey_created_at  \\\n",
       " 0                       NaN  Pilot 3A  over_15_years 2020-12-23 22:01:18   \n",
       " 1                       NaN  Pilot 3A  over_15_years 2020-12-23 21:52:09   \n",
       " 2                       NaN  Pilot 3A  over_15_years 2020-12-23 22:11:33   \n",
       " 3                       NaN        GT            NaN                 NaT   \n",
       " 4                       NaN  Pilot 3A  over_15_years 2020-12-24 07:35:27   \n",
       " ..                      ...       ...            ...                 ...   \n",
       " 203                     NaN  Pilot 3A  over_15_years 2020-12-27 21:24:30   \n",
       " 204                     NaN  Pilot 3A  over_15_years 2020-12-28 07:35:45   \n",
       " 205                     NaN  Pilot 3A  over_15_years 2020-12-28 10:17:44   \n",
       " 206                     NaN        GT            NaN                 NaT   \n",
       " 207                     NaN  Pilot 3A  over_15_years 2020-12-28 19:37:56   \n",
       " \n",
       "       survey_started_at Fluency  \n",
       " 0   2020-12-23 21:58:15  Fluent  \n",
       " 1   2020-12-23 21:47:05  Fluent  \n",
       " 2   2020-12-23 22:07:06  Fluent  \n",
       " 3                   NaT      GT  \n",
       " 4   2020-12-24 07:26:44  Fluent  \n",
       " ..                  ...     ...  \n",
       " 203 2020-12-27 21:23:00  Fluent  \n",
       " 204 2020-12-28 07:33:19  Fluent  \n",
       " 205 2020-12-28 10:12:23  Fluent  \n",
       " 206                 NaT      GT  \n",
       " 207 2020-12-28 19:31:56  Fluent  \n",
       " \n",
       " [208 rows x 79 columns],\n",
       " 'Pilot 3_v1':      Language         _id rater_answer a_domain a_register b_domain  \\\n",
       " 0     Turkish  5868295106          yes   season    neutral   season   \n",
       " 1     Turkish  5868300856          yes   season    neutral   season   \n",
       " 2     Turkish  5868300866          yes   season    neutral   season   \n",
       " 3     Turkish  5868359497          yes   season    neutral   season   \n",
       " 4     Turkish  5868406548          yes   season    neutral   season   \n",
       " ...       ...         ...          ...      ...        ...      ...   \n",
       " 1113  Turkish  5871973241           no   idioms    neutral   idioms   \n",
       " 1114  Turkish  5872312585           no   idioms    neutral   idioms   \n",
       " 1115  Turkish  5872622491           no   idioms    neutral   idioms   \n",
       " 1116  Turkish  5872921698           no   idioms    neutral   idioms   \n",
       " 1117  Turkish  5873470863           no   idioms    neutral   idioms   \n",
       " \n",
       "      b_register difficulty familiarity  question_  ... _region       _city  \\\n",
       " 0       neutral       easy    familiar          1  ...    34.0    Istanbul   \n",
       " 1       neutral       easy    familiar          1  ...    34.0    Istanbul   \n",
       " 2       neutral       easy    familiar          1  ...    34.0    Istanbul   \n",
       " 3       neutral       easy    familiar          1  ...    20.0        Imus   \n",
       " 4       neutral       easy    familiar          1  ...     2.0  Kellyville   \n",
       " ...         ...        ...         ...        ...  ...     ...         ...   \n",
       " 1113    neutral       hard  unfamiliar         43  ...    54.0     Sakarya   \n",
       " 1114    neutral       hard  unfamiliar         43  ...    68.0      Ankara   \n",
       " 1115    neutral       hard  unfamiliar         43  ...    35.0       Izmir   \n",
       " 1116    neutral       hard  unfamiliar         43  ...    20.0        Imus   \n",
       " 1117    neutral       hard  unfamiliar         43  ...    34.0    Istanbul   \n",
       " \n",
       "                  _ip Answer Score  Grouping  31_language_1  \\\n",
       " 0      159.146.43.95    yes     1  Pilot 3A  over_15_years   \n",
       " 1      107.150.95.12    yes     1  Pilot 3A  over_15_years   \n",
       " 2      107.150.95.12    yes     1  Pilot 3A  over_15_years   \n",
       " 3     124.106.180.38    yes     1        GT            NaN   \n",
       " 4     101.179.219.27    yes     1        GT            NaN   \n",
       " ...              ...    ...   ...       ...            ...   \n",
       " 1113   88.230.169.32     no     1  Pilot 3A  over_15_years   \n",
       " 1114    46.155.64.92     no     1  Pilot 3A  over_15_years   \n",
       " 1115   176.88.68.107     no     1  Pilot 3A  over_15_years   \n",
       " 1116  124.106.180.38     no     1        GT            NaN   \n",
       " 1117  159.146.40.126     no     1  Pilot 3A  over_15_years   \n",
       " \n",
       "        survey_created_at   survey_started_at Fluency  \n",
       " 0    2020-12-23 22:01:18 2020-12-23 21:58:15  Fluent  \n",
       " 1    2020-12-23 22:11:33 2020-12-23 22:07:06  Fluent  \n",
       " 2    2020-12-23 21:52:09 2020-12-23 21:47:05  Fluent  \n",
       " 3                    NaT                 NaT      GT  \n",
       " 4                    NaT                 NaT      GT  \n",
       " ...                  ...                 ...     ...  \n",
       " 1113 2020-12-27 21:24:30 2020-12-27 21:23:00  Fluent  \n",
       " 1114 2020-12-28 07:35:45 2020-12-28 07:33:19  Fluent  \n",
       " 1115 2020-12-28 10:17:44 2020-12-28 10:12:23  Fluent  \n",
       " 1116                 NaT                 NaT      GT  \n",
       " 1117 2020-12-28 19:37:56 2020-12-28 19:31:56  Fluent  \n",
       " \n",
       " [1118 rows x 33 columns],\n",
       " 'Pilot 3_v2':      Language         _id                   rater_answer       a_domain  \\\n",
       " 0     Turkish  5868301063  a_and_b_have_the_same_meaning           time   \n",
       " 1     Turkish  5868344334  a_and_b_have_the_same_meaning           time   \n",
       " 2     Turkish  5868344361  a_and_b_have_the_same_meaning           time   \n",
       " 3     Turkish  5868410262  a_and_b_have_the_same_meaning           time   \n",
       " 4     Turkish  5868780952  a_and_b_have_the_same_meaning           time   \n",
       " ...       ...         ...                            ...            ...   \n",
       " 2595  Turkish  5871990756        a_and_b_are_not_related  communication   \n",
       " 2596  Turkish  5872365862        a_and_b_are_not_related  communication   \n",
       " 2597  Turkish  5872835237        a_and_b_are_not_related  communication   \n",
       " 2598  Turkish  5872944308  a_and_b_have_the_same_meaning  communication   \n",
       " 2599  Turkish  5873485594        a_and_b_are_not_related  communication   \n",
       " \n",
       "           a_register           b_domain b_register difficulty familiarity  \\\n",
       " 0             formal               time    neutral       easy    familiar   \n",
       " 1             formal               time    neutral       easy    familiar   \n",
       " 2             formal               time    neutral       easy    familiar   \n",
       " 3             formal               time    neutral       easy    familiar   \n",
       " 4             formal               time    neutral       easy    familiar   \n",
       " ...              ...                ...        ...        ...         ...   \n",
       " 2595  slang/informal  physical activity    neutral       easy    familiar   \n",
       " 2596  slang/informal  physical activity    neutral       easy    familiar   \n",
       " 2597  slang/informal  physical activity    neutral       easy    familiar   \n",
       " 2598  slang/informal  physical activity    neutral       easy    familiar   \n",
       " 2599  slang/informal  physical activity    neutral       easy    familiar   \n",
       " \n",
       "       question_  ...             _ip                         Answer  \\\n",
       " 0             1  ...   159.146.43.95  a_and_b_have_the_same_meaning   \n",
       " 1             1  ...  107.150.95.100  a_and_b_have_the_same_meaning   \n",
       " 2             1  ...   91.140.83.182  a_and_b_have_the_same_meaning   \n",
       " 3             1  ...  101.179.219.27  a_and_b_have_the_same_meaning   \n",
       " 4             1  ...    31.141.60.16  a_and_b_have_the_same_meaning   \n",
       " ...         ...  ...             ...                            ...   \n",
       " 2595        100  ...   88.230.169.32        a_and_b_are_not_related   \n",
       " 2596        100  ...    46.155.64.92        a_and_b_are_not_related   \n",
       " 2597        100  ...   176.88.68.107        a_and_b_are_not_related   \n",
       " 2598        100  ...  124.106.180.38        a_and_b_are_not_related   \n",
       " 2599        100  ...  159.146.40.126        a_and_b_are_not_related   \n",
       " \n",
       "      Alternate Answer Score                          Answers  Grouping  \\\n",
       " 0                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       " 1                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       " 2                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       " 3                   0     1  a_and_b_have_the_same_meaning;0        GT   \n",
       " 4                   0     1  a_and_b_have_the_same_meaning;0  Pilot 3A   \n",
       " ...               ...   ...                              ...       ...   \n",
       " 2595                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       " 2596                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       " 2597                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       " 2598                0     0        a_and_b_are_not_related;0        GT   \n",
       " 2599                0     1        a_and_b_are_not_related;0  Pilot 3A   \n",
       " \n",
       "       31_language_1   survey_created_at   survey_started_at Fluency  \n",
       " 0     over_15_years 2020-12-23 22:01:18 2020-12-23 21:58:15  Fluent  \n",
       " 1     over_15_years 2020-12-23 22:11:33 2020-12-23 22:07:06  Fluent  \n",
       " 2     over_15_years 2020-12-23 21:52:09 2020-12-23 21:47:05  Fluent  \n",
       " 3               NaN                 NaT                 NaT      GT  \n",
       " 4     over_15_years 2020-12-24 07:35:27 2020-12-24 07:26:44  Fluent  \n",
       " ...             ...                 ...                 ...     ...  \n",
       " 2595  over_15_years 2020-12-27 21:24:30 2020-12-27 21:23:00  Fluent  \n",
       " 2596  over_15_years 2020-12-28 07:35:45 2020-12-28 07:33:19  Fluent  \n",
       " 2597  over_15_years 2020-12-28 10:17:44 2020-12-28 10:12:23  Fluent  \n",
       " 2598            NaN                 NaT                 NaT      GT  \n",
       " 2599  over_15_years 2020-12-28 19:37:56 2020-12-28 19:31:56  Fluent  \n",
       " \n",
       " [2600 rows x 35 columns]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALA",
   "language": "python",
   "name": "ala"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
