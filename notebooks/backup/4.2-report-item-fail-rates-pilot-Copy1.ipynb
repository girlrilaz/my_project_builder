{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################       \n",
    "#Script Name    :                                                                                              \n",
    "#Description    :                                                                                 \n",
    "#Args           :                                                                                           \n",
    "#Author         : Nikhil Rao in R, converted to Python by Nor Raymond                                              \n",
    "#Email          : nraymond@appen.com                                          \n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fail Rate Reports for Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import warnings\n",
    "from functools import reduce\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load yaml configuration file\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(config_path, config_name), 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "config_path = \"conf/base\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "    \n",
    "except:\n",
    "    \n",
    "    os.chdir('..')\n",
    "    # load yaml catalog configuration file\n",
    "    config = load_config(\"catalog.yml\")\n",
    "\n",
    "    os.chdir(config[\"project_path\"])\n",
    "    root_path = os.getcwd()\n",
    "    \n",
    "# import data_processing module\n",
    "import src.data.data_processing as data_processing\n",
    "# import data_processing module\n",
    "import src.data.data_cleaning as data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_selection(languages):\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            language_index = int(input(\"\\nPlease select the number of the Language you are assessing: \"))\n",
    "            if language_index < min(languages.index) or language_index > max(languages.index):\n",
    "                print(f\"\\nYou must enter numbers between {min(languages.index)} - {max(languages.index)}... Please try again\")\n",
    "                continue\n",
    "            elif language_index == \"\":\n",
    "                print(\"\\nYou must enter any numbers\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"\\nYou have selected {language_index} for {languages.iloc[language_index, 0]}\")\n",
    "                language_selected = languages.iloc[language_index, 0]\n",
    "                break\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"\\nYou must enter numerical values only... Please try again\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return language_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Language Modification - getting the overall time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Language Modification\n",
    "def get_time_taken(df, language_selected):\n",
    "\n",
    "    # Filter data based on selected language\n",
    "    dfr = df[df['Language'] == language_selected]\n",
    "\n",
    "    # Time Taken by Item\n",
    "    dfr[\"Time_Taken_Seconds\"] = (dfr['_created_at'] - dfr['_started_at']).dt.seconds\n",
    "\n",
    "    # Time Taken Overall\n",
    "    dfr_grouped = dfr.groupby('_worker_id').sum('Time_Taken_Seconds')\n",
    "    dfr_grouped[\"Time_Taken_Minutes_Overall\"] = dfr_grouped[\"Time_Taken_Seconds\"] / 60\n",
    "    dfr_grouped = dfr_grouped.reset_index()\n",
    "    dfr = pd.merge(dfr, dfr_grouped[[\"Time_Taken_Minutes_Overall\", \"_worker_id\"]], how = 'left', on = '_worker_id')\n",
    "\n",
    "    return dfr\n",
    "\n",
    "def get_time_taken_all(language_selected, rc, v1, v2):\n",
    "    \n",
    "    df_list = [rc, v1, v2]\n",
    "    keys = [\"rcR\", \"v1R\", \"v2R\"]\n",
    "    df_time = {}\n",
    "    \n",
    "    for df, key in zip(df_list, keys) :\n",
    "\n",
    "        dfr = get_time_taken(df, language_selected)\n",
    "        df_time[key] = dfr\n",
    "\n",
    "    rcR, v1R, v2R = df_time[\"rcR\"], df_time[\"v1R\"], df_time[\"v2R\"]    \n",
    "    \n",
    "    return rcR, v1R, v2R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for pilot variant selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_1_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', 'Fail_Rate'], [True, True, False]     \n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "\n",
    "    elif pilot_var_selected == 'Pilot 1C':\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A'):\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "    \n",
    "    elif pilot_var_selected == 'Pilot 3A':\n",
    "    \n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_1 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    return selector_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_2_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "    \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "\n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Answer', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', 'Fail_Rate'], [True, True, False]\n",
    "        \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answer', 'Score']\n",
    "        \n",
    "        groupby3 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answer', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', 'Tenure', '_unit_id', 'question_', 'a_domain', 'a_register', \n",
    "                        'wordphrase_a', 'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', 'Tenure', '_unit_id','Fail_Rate'], [True, True ,True, False]\n",
    "        \n",
    "        drop_cols, explode, join_on, select3 = [],[],[],[]\n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "              \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "              \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : select3}\n",
    "        \n",
    "        \n",
    "    elif pilot_var_selected == 'Pilot 1C':\n",
    "        \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "                 \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "\n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id'], [True, True]\n",
    "                \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', 'Tenure', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "\n",
    "        groupby3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', '_unit_id', 'Score', 'Rate'], [True, True, True, False]\n",
    "        \n",
    "        drop_cols = ['Score', 'Count_of_Test_Takers', 'Total_Test_Takers']\n",
    "        \n",
    "        explode = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers']\n",
    "        \n",
    "        # for merge_v2_fail_rates\n",
    "        join_on = [\"Language\", \"Fluency\", \"_unit_id\", \"question_\", \"a_domain\", \"a_register\", \"wordphrase_a\", \"b_domain\",\n",
    "                                  \"b_register\", \"wordphrase_b\", \"difficulty\", \"Answers\"]\n",
    "        \n",
    "        select3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a',\n",
    "                'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Count_of_Test_Takers', 'Total_Test_Takers',\n",
    "                'Overall_Fail_Rate', 'Answers', 'a_and_b_are_not_related', 'a_and_b_are_related', 'a_and_b_have_the_same_meaning',\n",
    "                'a_is_more_specific_than_b', 'b_is_more_specific_than_a'] \n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "              \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "              \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : select3}\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id'], [True, True]\n",
    "                \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', '_unit_id', 'Score', 'Rate'], [True, True, True, False]\n",
    "        \n",
    "        drop_cols = ['Score', 'Count_of_Test_Takers', 'Total_Test_Takers']\n",
    "        \n",
    "        explode = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers']\n",
    "        \n",
    "        # for merge_v2_fail_rates\n",
    "        join_on = [\"Language\", \"Fluency\", \"_unit_id\", \"question_\", \"a_domain\", \"a_register\", \"wordphrase_a\", \"b_domain\",\n",
    "                                  \"b_register\", \"wordphrase_b\", \"difficulty\", \"Answers\"]\n",
    "        \n",
    "        select3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a',\n",
    "                'b_domain', 'b_register', 'wordphrase_b', 'difficulty', 'Count_of_Test_Takers', 'Total_Test_Takers',\n",
    "                'Overall_Fail_Rate', 'Answers', 'a_and_b_are_not_related', 'a_and_b_are_related', 'a_and_b_have_the_same_meaning',\n",
    "                'a_is_more_specific_than_b', 'b_is_more_specific_than_a']\n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "                      \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "                      \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : select3}\n",
    "        \n",
    "    elif pilot_var_selected == 'Pilot 2B-A':\n",
    "        \n",
    "        # for v2_fail_rate\n",
    "        select1 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers', 'Score']\n",
    "        \n",
    "        groupby2 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', \n",
    "                                    'b_domain', 'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id'], [True, True]\n",
    "                \n",
    "        # for v2_fail_rate_2\n",
    "        select2 = ['Language', 'Fluency', '_worker_id', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                   'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby3 = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'rater_answer', 'Answers', 'Score']\n",
    "        \n",
    "        groupby4 = ['Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                                          'b_register', 'wordphrase_b', 'difficulty']\n",
    "        \n",
    "        sort_values_2, sort_order_2 = ['Fluency', '_unit_id', 'Score', 'Rate'], [True, True, True, False]\n",
    "        \n",
    "        drop_cols = ['Score', 'Count_of_Test_Takers', 'Total_Test_Takers']\n",
    "        \n",
    "        explode = ['Language', 'Fluency', '_unit_id', 'question_', 'a_domain', 'a_register', 'wordphrase_a', 'b_domain', \n",
    "                                  'b_register', 'wordphrase_b', 'difficulty', 'Answers']\n",
    "        \n",
    "        # for merge_v2_fail_rates\n",
    "        join_on = [\"Language\", \"Fluency\", \"_unit_id\", \"question_\", \"a_domain\", \"a_register\", \"wordphrase_a\", \"b_domain\",\n",
    "                                  \"b_register\", \"wordphrase_b\", \"difficulty\", \"Answers\"]\n",
    "        \n",
    "        selector_2 = {\"select1\" : select1, \"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order,\n",
    "                      \"select2\" : select2, \"groupby3\" : groupby3, \"groupby4\" : groupby4, \"sort_values_2\" : sort_values_2, \"sort_order_2\" : sort_order_2, \n",
    "                      \"drop_cols\" : drop_cols, \"explode\" : explode, \"join_on\" : join_on, \"select3\" : []}\n",
    "            \n",
    "    return selector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_3_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "        \n",
    "        # for rc_fail_rate_1A_1B\n",
    "        select1 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds', '_unit_id', 'title',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_1 = ['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score']\n",
    "        \n",
    "        drop_cols_2 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "         \n",
    "        explode =  ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds','_unit_id', 'title', \n",
    "                    'register', 'topic', 'text_type','complexity', 'familiarity']\n",
    "        \n",
    "        # for melt_rc_answer_actual_1A_1B\n",
    "        select2 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds', '_unit_id', 'title',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_3 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode2 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds',\n",
    "                       '_unit_id', 'title', 'register', 'topic', 'text_type', 'complexity', 'familiarity']\n",
    "        \n",
    "        #for rc_q_s_pass_rate_1A_1B\n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'a', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', 'Fail_Rate'], [True, True, False]\n",
    "        \n",
    "        selector_3 = {\"select1\" : select1, \"drop_cols_1\" : drop_cols_1, \"drop_cols_2\" : drop_cols_2, \"explode\" : explode,\n",
    "                      \"select2\" : select2, \"select3\" : [], \"drop_cols_3\" : drop_cols_3, \"explode2\" : explode2, \"groupby1\" : groupby1, \n",
    "                      \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    elif pilot_var_selected == 'Pilot 1C':\n",
    "               \n",
    "        # for rc_fail_rate\n",
    "        select1 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_1 = ['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score']\n",
    "        \n",
    "        drop_cols_2 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds',\n",
    "                   '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type', 'complexity', 'familiarity']\n",
    "        \n",
    "        # for melt_rc\n",
    "        select2 = ['Language', '_unit_id', 'title', 'test_',\n",
    "                'question_1_choice_1', 'question_1_choice_2', 'question_1_choice_3',\n",
    "                'question_2_choice_1', 'question_2_choice_2', 'question_2_choice_3',\n",
    "                'question_3_choice_1', 'question_3_choice_2', 'question_3_choice_3',\n",
    "                'question_4_choice_1', 'question_4_choice_2', 'question_4_choice_3']\n",
    "        \n",
    "        #for melt_rc_answer_actual\n",
    "        select3 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure' ,'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_3 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode2 = ['Language', '_worker_id', '_country', 'Fluency', 'Tenure', 'Time_Taken_Seconds',\n",
    "                    '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type','complexity', 'familiarity']\n",
    "        \n",
    "        #for rc_q_s_pass_rate\n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Score', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_3 = {\"select1\" : select1, \"drop_cols_1\" : drop_cols_1, \"drop_cols_2\" : drop_cols_2, \"explode\" : explode,\n",
    "                      \"select2\" : select2, \"select3\" : select3, \"drop_cols_3\" : drop_cols_3, \"explode2\" : explode2, \"groupby1\" : groupby1, \n",
    "                      \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        # for rc_fail_rate\n",
    "        select1 = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity', \n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_1 = ['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4', 'Score']\n",
    "        \n",
    "        drop_cols_2 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "                   '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type', 'complexity', 'familiarity']\n",
    "        \n",
    "        # for melt_rc\n",
    "        select2 = ['Language', '_unit_id', 'title', 'test_',\n",
    "                'question_1_choice_1', 'question_1_choice_2', 'question_1_choice_3',\n",
    "                'question_2_choice_1', 'question_2_choice_2', 'question_2_choice_3',\n",
    "                'question_3_choice_1', 'question_3_choice_2', 'question_3_choice_3',\n",
    "                'question_4_choice_1', 'question_4_choice_2', 'question_4_choice_3']\n",
    "        \n",
    "        #for melt_rc_answer_actual\n",
    "        select3 = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds', '_unit_id', 'title', 'test_',\n",
    "                'question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested',\n",
    "                'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                'register', 'topic', 'text_type', 'complexity', 'familiarity',\n",
    "                'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                'Score']\n",
    "        \n",
    "        drop_cols_3 = ['question_1_difficulty', 'question_1_google_translate_error', 'Question 1 Skill tested', \n",
    "                            'question_2_difficulty', 'question_2_google_translate_error', 'Question 2 Skill tested',\n",
    "                            'question_3_difficulty', 'question_3_google_translate_error', 'Question 3 Skill tested',\n",
    "                            'question_4_difficulty', 'question_4_google_translate_error', 'Question 4 Skill tested',\n",
    "                            'question_no_1', 'question_no_2', 'question_no_3', 'question_no_4',\n",
    "                            'Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4',\n",
    "                            'a1', 'a2', 'a3', 'a4']\n",
    "        \n",
    "        explode2 = ['Language', '_worker_id', '_country', 'Fluency', 'Time_Taken_Seconds',\n",
    "                    '_unit_id', 'title', 'test_', 'register', 'topic', 'text_type','complexity', 'familiarity']\n",
    "        \n",
    "        #for rc_q_s_pass_rate\n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Score', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Fail_Rate'], [True, False]\n",
    "        \n",
    "        selector_3 = {\"select1\" : select1, \"drop_cols_1\" : drop_cols_1, \"drop_cols_2\" : drop_cols_2, \"explode\" : explode,\n",
    "                      \"select2\" : select2, \"select3\" : select3, \"drop_cols_3\" : drop_cols_3, \"explode2\" : explode2, \"groupby1\" : groupby1, \n",
    "                      \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "    return selector_3\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_4_selector(pilot_var_selected):\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 1A-1B':\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'aa', 'ra', 'a', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', 'Tenure', '_unit_id', 'title', 'q', 'd', 'register', 'skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', 'Tenure', '_unit_id', 'q', 'Fail_Rate'], [True, True, True, True, False]\n",
    "        \n",
    "        selector_4 = {\"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}        \n",
    "            \n",
    "    elif (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        groupby1 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Actual_Answer', 'Rater_Answer', \n",
    "                                    'Score', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        groupby2 = ['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Question', 'Difficulty', 'register', 'Skill']\n",
    "        \n",
    "        sort_values, sort_order = ['Fluency', '_unit_id', 'Question', 'Fail_Rate'], [True, True, True, False]\n",
    "        \n",
    "        selector_4 = {\"groupby1\" : groupby1, \"groupby2\" : groupby2, \"sort_values\" : sort_values, \"sort_order\" : sort_order}\n",
    "        \n",
    "        \n",
    "    return selector_4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for calculating Fail Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PILOT 3A, 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ---------------------------------------------------------------\n",
    "\n",
    "def v1_fail_rate(v1R, selector_1):  #Valid for Pilot 3A, 1C\n",
    "    \n",
    "    vR_temp = v1R[selector_1['select1']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_1['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_1['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0\n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and Fail_rate descending \n",
    "    vR_grouped = vR_grouped.sort_values(selector_1['sort_values'], ascending = selector_1['sort_order'])\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def generate_report_1(v1R, selector_1):\n",
    "    \n",
    "    v1_actual_correct_by_question = v1_fail_rate(v1R, selector_1)\n",
    "    \n",
    "    return v1_actual_correct_by_question\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 2 : \"Close Match\" - v2_fail_rates  ---------------------------------------------------------------------------------------\n",
    "\n",
    "def v2_fail_rate(v2R, selector_2):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select1']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Overall_Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values'], ascending = selector_2['sort_order'])\n",
    "    \n",
    "    # drop Score column\n",
    "    vR_grouped = vR_grouped.drop('Score', axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def v2_fail_rate_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select2']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby3'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby4'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 . Note Pilot 1C,1D seem to have this disabled, but it's not making sense as Fail Rate should have Score = 0.\n",
    "    if (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)'):\n",
    "        vR_grouped = vR_grouped\n",
    "        \n",
    "    elif (pilot_var_selected == 'Pilot 3A' or pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A'):\n",
    "        vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values_2'], ascending = selector_2['sort_order_2'])\n",
    "    \n",
    "    # drop Score columns\n",
    "    vR_grouped = vR_grouped.drop(selector_2['drop_cols'], axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].fillna('Null')\n",
    "    \n",
    "    vR_fail_rates  = pd.pivot_table(vR_fail_rates, \n",
    "                           index = selector_2['explode'],\n",
    "                           values='Rate', columns=['rater_answer']).reset_index()\n",
    "    vR_fail_rates.columns.name = None # remove name for columns\n",
    "    \n",
    "    vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].replace('Null', np.nan)\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_fail_rates = vR_fail_rates.drop_duplicates()\n",
    "    \n",
    "    return vR_fail_rates \n",
    "\n",
    "def merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2, pilot_var_selected):\n",
    "    \n",
    "    v2_fail_rates = pd.merge(v2_actual_correct_by_question_with_answer, v2_actual_correct_by_question, how = 'left', \n",
    "                            on = selector_2['join_on'])\n",
    "    \n",
    "    if pilot_var_selected == 'Pilot 2B-A':\n",
    "        v2_fail_rates = v2_fail_rates\n",
    "    elif (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "          pilot_var_selected == 'Pilot 2A' or \n",
    "          pilot_var_selected == 'Pilot 3A'):\n",
    "        v2_fail_rates = v2_fail_rates[selector_2['select3']]\n",
    "    \n",
    "    return v2_fail_rates\n",
    "\n",
    "def generate_report_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "    v2_actual_correct_by_question = v2_fail_rate(v2R, selector_2)\n",
    "\n",
    "    v2_actual_correct_by_question_with_answer = v2_fail_rate_2(v2R, selector_2, pilot_var_selected)\n",
    "\n",
    "    v2_fail_rates = merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2, pilot_var_selected)\n",
    "    \n",
    "    return v2_fail_rates\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate  ---------------------------------------------------------------\n",
    "\n",
    "def rc_fail_rate(rcR, selector_3):\n",
    "\n",
    "    vR_temp = rcR[selector_3['select1']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    # Dropping columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_1'], axis =1)  \n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    # Dropping more columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_2'], axis =1)  \n",
    "    \n",
    "    # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Question', 'Difficulty', \n",
    "                                                                                               'Google_Translate_Error', 'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer = vR_temp\n",
    "    \n",
    "    return rc_answer\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc_assign(rc_choices, q_list, choice_list):\n",
    "    \n",
    "    df=[]\n",
    "    for ql in q_list:\n",
    "        for cl in choice_list:\n",
    "            df_temp_1 = rc_choices[rc_choices['variable'].str.contains('question_' + str(ql))]\n",
    "            df_temp_2 = df_temp_1[df_temp_1['variable'].str.contains('choice_' + str(cl))]\n",
    "            df_temp_2['Question'] = 'Question ' + str(ql)\n",
    "            if cl == 1 :\n",
    "                df_temp_2['Answer'] = 'a'\n",
    "            elif cl == 2 :\n",
    "                df_temp_2['Answer'] = 'b'\n",
    "            elif cl == 3 :\n",
    "                df_temp_2['Answer'] = 'c'\n",
    "            df.append(df_temp_2)\n",
    "            \n",
    "    rc_choices = pd.concat(df)\n",
    "    return rc_choices\n",
    "\n",
    "## Melt RC and categorize question choice with letter and question number\n",
    "def melt_rc(rcR, selector_3):\n",
    "\n",
    "    vR_temp = rcR[selector_3['select2']]\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_temp = vR_temp.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    vR_temp = pd.melt(vR_temp, id_vars=['Language', '_unit_id', 'title', 'test_'])\n",
    "    \n",
    "    rc_choices = vR_temp\n",
    "    \n",
    "    q_list, choice_list = [1,2,3,4], [1,2,3]\n",
    "    rc_choices = melt_rc_assign(rc_choices, q_list, choice_list)\n",
    "    rc_choices = rc_choices[['Language', '_unit_id', 'title', 'test_', 'Question', 'Answer', 'variable', 'value']]\n",
    "    rc_choices = rc_choices.sort_values(['Language', 'title', 'test_', 'Question', 'Answer'])\n",
    "    \n",
    "    actual_answer = rc_choices\n",
    "    rater_answer = rc_choices\n",
    "    \n",
    "    return rc_choices, actual_answer, rater_answer\n",
    "\n",
    "# ## Melt RC into long format with actual answers\n",
    "def melt_rc_answer_actual(rcR, selector_3):\n",
    "    \n",
    "    vR_temp = rcR[selector_3['select3']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    vR_temp = vR_temp.drop('Score', axis = 1)\n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Rater_Answer'] = vR_temp[['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4']].astype('str').agg(';'.join, axis=1)\n",
    "    vR_temp['Actual_Answer'] = vR_temp[['Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_3'], axis = 1)\n",
    "    \n",
    "     # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode2']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Rater_Answer', 'Actual_Answer', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Rater_Answer', \n",
    "                                                                                                                                'Actual_Answer','Question', \n",
    "                                                                                                                                'Difficulty', \n",
    "                                                                                                                                'Google_Translate_Error', \n",
    "                                                                                                                                'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer_actual = vR_temp\n",
    "    \n",
    "    return rc_answer_actual\n",
    "\n",
    "def rc_q_s_pass_rate(rc_answer, selector_3):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer.groupby(selector_3['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_3['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_3['sort_values'], ascending = selector_3['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "def generate_report_3(rcR, selector_3):\n",
    "    \n",
    "    rc_answer = rc_fail_rate(rcR, selector_3)\n",
    "    \n",
    "    rc_choices, actual_answer, rater_answer = melt_rc(rcR, selector_3)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate = rc_q_s_pass_rate(rc_answer, selector_3)\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 4 : \"RC with Answers\" : rc_question_skill_pass_rate_answer_final  --------------------------------------------------------\n",
    "\n",
    "def rc_q_s_pass_rate_answer(rc_answer_actual, selector_4):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer_actual.groupby(selector_4['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_4['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_4['sort_values'], ascending = selector_4['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer\n",
    "\n",
    "def join_rc_q_s_pass_rate_answer(rc_question_skill_pass_rate_answer, actual_answer, rater_answer):\n",
    "    \n",
    "    first_join = rc_question_skill_pass_rate_answer\n",
    "    first_join = pd.merge(first_join, actual_answer, how = 'left', \n",
    "                            left_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Actual_Answer\"],\n",
    "                            right_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Answer\"])\n",
    "    first_join = first_join.drop('Answer', axis=1)\n",
    "    \n",
    "    second_join = pd.merge(first_join, rater_answer, how = 'left', \n",
    "                            left_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Rater_Answer\"],\n",
    "                            right_on = [\"Language\", \"_unit_id\", \"title\" , \"test_\", \"Question\", \"Answer\"])\n",
    "    second_join = second_join.drop('Answer', axis=1)\n",
    "    \n",
    "    second_join = second_join[['Language', 'Fluency', '_unit_id', 'title', 'test_', 'Difficulty', 'register', 'Skill', 'Question',\n",
    "                               'Actual_Answer', 'value_x', 'Rater_Answer', 'value_y', 'Count', 'Total', 'Fail_Rate']]\n",
    "  \n",
    "    second_join = second_join.rename(columns = { \"Actual_Answer\" : \"Actual_Answer_Letter\", \n",
    "                                       \"value_x\" : \"Actual_Answer_Text\",\n",
    "                                       \"Rater_Answer\" : \"Rater_Answer_Letter\",\n",
    "                                       \"value_y\" : \"Rater_Answer_Text\"})\n",
    "\n",
    "    rc_question_skill_pass_rate_answer_final = second_join\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer_final\n",
    "\n",
    "\n",
    "def generate_report_4(rcR, selector_3, selector_4):\n",
    "    \n",
    "    rc_choices, actual_answer, rater_answer = melt_rc(rcR, selector_3)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = rc_q_s_pass_rate_answer(rc_answer_actual, selector_4)\n",
    "\n",
    "    rc_question_skill_pass_rate_answer_final = join_rc_q_s_pass_rate_answer(rc_question_skill_pass_rate_answer, actual_answer, rater_answer)\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer_final\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PILOT 1A-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ------------------------------------------------------------------\n",
    "\n",
    "def v1_fail_rate_1A_1B(v1R, selector_1):  #Valid for Pilot 1A-1B\n",
    "    \n",
    "    vR_temp = v1R[selector_1['select1']]\n",
    "       \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_1['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_1['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and Fail_rate descending \n",
    "    vR_grouped = vR_grouped.sort_values(selector_1['sort_values'], ascending=selector_1['sort_order'])\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def generate_report_1_1A_1B(v1R, selector_1):\n",
    "    \n",
    "    v1_actual_correct_by_question = v1_fail_rate_1A_1B(v1R, selector_1)\n",
    "    \n",
    "    return v1_actual_correct_by_question\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 2 : \"Close Match\" - v2_fail_rates  ---------------------------------------------------------------------------------------\n",
    "\n",
    "def v2_fail_rate_1A_1B(v2R, selector_2):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select1']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values'], ascending = selector_2['sort_order'])\n",
    "    \n",
    "    # drop Score column\n",
    "    vR_grouped = vR_grouped.drop('Score', axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_fail_rates\n",
    "\n",
    "def v2_fail_rate_2_1A_1B(v2R, selector_2):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select2']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby3'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby4'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values_2'], ascending = selector_2['sort_order_2'])\n",
    "    \n",
    "    v2_actual_correct_by_question_with_answer = vR_grouped\n",
    "    \n",
    "    return v2_actual_correct_by_question_with_answer\n",
    "\n",
    "def generate_report_2_1A_1B(v2R, selector_2):\n",
    "    \n",
    "    v2_actual_correct_by_question = v2_fail_rate_1A_1B(v2R, selector_2)\n",
    "\n",
    "    v2_actual_correct_by_question_with_answer = v2_fail_rate_2_1A_1B(v2R, selector_2)\n",
    "\n",
    "    return v2_actual_correct_by_question_with_answer\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate  ---------------------------------------------------------------\n",
    "\n",
    "def rc_fail_rate_1A_1B(rcR, selector_3):\n",
    "\n",
    "    vR_temp = rcR[selector_3['select1']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    # Dropping columns  drop_cols_1\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_1'], axis =1)  \n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['a'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['q'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['d'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['ge'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    # Dropping more columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_2'], axis =1)  \n",
    "    \n",
    "    # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['a', 'q', 'd', 'ge', 'skill']] = vR_temp[['a', 'q', 'd', 'ge', 'skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['a'])  # remove rows with NaN values in Score \n",
    "    vR_temp['a'] = vR_temp['a'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer = vR_temp\n",
    "    \n",
    "    return rc_answer\n",
    "\n",
    "# ## Melt RC into long format with actual answers\n",
    "def melt_rc_answer_actual_1A_1B(rcR, selector_3):\n",
    "    \n",
    "    vR_temp = rcR[selector_3['select2']]\n",
    "    \n",
    "    # evaluate if Answers are the same as the questions. If either Q or A are empty, return NaN\n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    vR_temp = vR_temp.drop('Score', axis = 1)\n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['a'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['ra'] = vR_temp[['question_no_1', 'question_no_2', 'question_no_3', 'question_no_4']].astype('str').agg(';'.join, axis=1)\n",
    "    vR_temp['aa'] = vR_temp[['Answer_no_1', 'Answer_no_2', 'Answer_no_3', 'Answer_no_4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['q'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['d'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['ge'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_3'], axis = 1)\n",
    "    \n",
    "     # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode2']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['a', 'ra', 'aa', 'q', 'd', 'ge', 'skill']] = vR_temp[['a', 'ra', 'aa', 'q', 'd', 'ge', 'skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['a'])  # remove rows with NaN values in Score \n",
    "    vR_temp['a'] = vR_temp['a'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer_actual = vR_temp\n",
    "    \n",
    "    return rc_answer_actual\n",
    "\n",
    "def rc_q_s_pass_rate_1A_1B(rc_answer, selector_3):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer.groupby(selector_3['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_3['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['a'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_3['sort_values'], ascending = selector_3['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "def generate_report_3_1A_1B(rcR, selector_3):\n",
    "    \n",
    "    rc_answer = rc_fail_rate_1A_1B(rcR, selector_3)\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual_1A_1B(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate = rc_q_s_pass_rate_1A_1B(rc_answer, selector_3)\n",
    "    \n",
    "    return rc_question_skill_pass_rate\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 4 : \"RC with Answers\" : rc_question_skill_pass_rate_answer_final  --------------------------------------------------------\n",
    "\n",
    "def rc_q_s_pass_rate_answer_1A_1B(rc_answer_actual, selector_4):\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = rc_answer_actual.groupby(selector_4['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total'] = vR_grouped.groupby(selector_4['groupby2'], dropna =False)['Count'].transform('sum')   \n",
    "    vR_grouped['Fail_Rate'] = round((vR_grouped['Count'] / vR_grouped['Total']), 2)\n",
    "    \n",
    "    # filter Score 0 \n",
    "    vR_grouped = vR_grouped[vR_grouped['a'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_4['sort_values'], ascending = selector_4['sort_order'])\n",
    "    vR_grouped = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer = vR_grouped\n",
    "    \n",
    "    return rc_question_skill_pass_rate_answer\n",
    "\n",
    "def generate_report_4_1A_1B(rcR, selector_3, selector_4):\n",
    "    \n",
    "    rc_answer_actual = melt_rc_answer_actual_1A_1B(rcR, selector_3)\n",
    "    \n",
    "    rc_question_skill_pass_rate_answer_final = rc_q_s_pass_rate_answer_1A_1B(rc_answer_actual, selector_4)  #THIS ONE\n",
    "   \n",
    "    return rc_question_skill_pass_rate_answer_final\n",
    "\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_fail_rate_reports(rcR, v1R, v2R, rc, v1, v2, run_value, pilot_var_selected):\n",
    "    \n",
    "    if (pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D' or pilot_var_selected == 'Pilot 1E' or pilot_var_selected == 'Pilot 1E(ES)' or \n",
    "        pilot_var_selected == 'Pilot 2A' or pilot_var_selected == 'Pilot 2B-A' or\n",
    "        pilot_var_selected == 'Pilot 3A'):\n",
    "        \n",
    "        # Report 1 - Near Exact Match - v1_actual_correct_by_question\n",
    "        selector_1 = report_1_selector(pilot_var_selected)\n",
    "        v1_actual_correct_by_question =  generate_report_1(v1R, selector_1)\n",
    "\n",
    "        # Report 2 - Close Match - v2_fail_rates\n",
    "        selector_2 = report_2_selector(pilot_var_selected)\n",
    "        v2_fail_rates = generate_report_2(v2R, selector_2, pilot_var_selected)\n",
    "\n",
    "        # Report 3 - Reading Comprehension - rc_question_skill_pass_rate\n",
    "        selector_3 = report_3_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate = generate_report_3(rcR, selector_3)\n",
    "\n",
    "        # Report 4 - RC with Answers - rc_question_skill_pass_rate_answer_final\n",
    "        selector_4 = report_4_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate_answer_final = generate_report_4(rcR, selector_3, selector_4)\n",
    "\n",
    "        # store all 4 reports into a dictionary set\n",
    "        list_of_datasets = {\"Near Exact Match\" : v1_actual_correct_by_question,\n",
    "                            \"Close Match\" : v2_fail_rates,\n",
    "                            \"Reading Comprehension\" : rc_question_skill_pass_rate,\n",
    "                            \"RC with Answers\" : rc_question_skill_pass_rate_answer_final}\n",
    "\n",
    "        if run_value == 'Deployment':\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = {\"deployment_rc\" : rc,\n",
    "                                \"deployment_v1\" : v1,\n",
    "                                \"deployment_v2\" : v2}\n",
    "\n",
    "        else:\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = { pilot_var_selected + \"_rc\" : rc,\n",
    "                                  pilot_var_selected + \"_v1\" : v1,\n",
    "                                  pilot_var_selected + \"_v2\" : v2}\n",
    "            \n",
    "            \n",
    "    elif pilot_var_selected == 'Pilot 1A-1B':\n",
    "        \n",
    "        # Report 1 - Near Exact Match - v1_actual_correct_by_question\n",
    "        selector_1 = report_1_selector(pilot_var_selected)\n",
    "        v1_actual_correct_by_question =  generate_report_1_1A_1B(v1R, selector_1)\n",
    "\n",
    "        # Report 2 - Close Match - v2_fail_rates\n",
    "        selector_2 = report_2_selector(pilot_var_selected)\n",
    "        v2_fail_rates = generate_report_2_1A_1B(v2R, selector_2)\n",
    "\n",
    "        # Report 3 - Reading Comprehension - rc_question_skill_pass_rate\n",
    "        selector_3 = report_3_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate = generate_report_3_1A_1B(rcR, selector_3)\n",
    "\n",
    "        # Report 4 - RC with Answers - rc_question_skill_pass_rate_answer_final\n",
    "        selector_4 = report_4_selector(pilot_var_selected)\n",
    "        rc_question_skill_pass_rate_answer_final = generate_report_4_1A_1B(rcR, selector_3, selector_4)\n",
    "\n",
    "        # store all 4 reports into a dictionary set\n",
    "        # v2_fail_rates = v2_actual_correct_by_question_with_answer\n",
    "        list_of_datasets = {\"Near Exact Match\" : v1_actual_correct_by_question,\n",
    "                            \"Close Match\" : v2_fail_rates,\n",
    "                            \"Reading Comprehension\" : rc_question_skill_pass_rate,\n",
    "                            \"RC with Answers\" : rc_question_skill_pass_rate_answer_final}\n",
    "\n",
    "        if run_value == 'Deployment':\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = {\"deployment_rc\" : rc,\n",
    "                                \"deployment_v1\" : v1,\n",
    "                                \"deployment_v2\" : v2}\n",
    "\n",
    "        else:\n",
    "\n",
    "            # store all 3 summaries into a dictionary set\n",
    "            list_of_summaries = { pilot_var_selected + \"_rc\" : rc,\n",
    "                                  pilot_var_selected + \"_v1\" : v1,\n",
    "                                  pilot_var_selected + \"_v2\" : v2}\n",
    "\n",
    "    \n",
    "    return list_of_datasets, list_of_summaries\n",
    "\n",
    "def file_check_create(root_path, config, language_selected, run_value, pilot_var_selected):\n",
    "    \n",
    "    if run_value == 'Deployment':\n",
    "        \n",
    "        run_folder = os.path.join(root_path, config['report']['deliverable'], run_value, language_selected)\n",
    "\n",
    "        if not os.path.exists(run_folder):\n",
    "            os.makedirs(run_folder, exist_ok=True)\n",
    "        \n",
    "        folder_tag = 'Deployment Summary'\n",
    "        analysis_folder = os.path.join(root_path, config['report']['analysis'], folder_tag)\n",
    "\n",
    "        if not os.path.exists(analysis_folder):\n",
    "            os.makedirs(analysis_folder, exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'RC')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'RC'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V1')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V1'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V2')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V2'), exist_ok=True)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        run_folder = os.path.join(root_path, config['report']['deliverable'], run_value, pilot_var_selected, language_selected)\n",
    "\n",
    "        if not os.path.exists(run_folder):\n",
    "            os.makedirs(run_folder, exist_ok=True)\n",
    "            \n",
    "        folder_tag = 'Grand Summary'\n",
    "        analysis_folder = os.path.join(root_path, config['report']['analysis'], folder_tag)\n",
    "\n",
    "        if not os.path.exists(analysis_folder):\n",
    "            os.makedirs(analysis_folder, exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'RC')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'RC'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V1')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V1'), exist_ok=True)\n",
    "            \n",
    "        if not os.path.exists(os.path.join(analysis_folder, 'V2')):\n",
    "            os.makedirs(os.path.join(analysis_folder, 'V2'), exist_ok=True)\n",
    "        \n",
    "    return run_folder, analysis_folder, folder_tag\n",
    "\n",
    "def write_fail_report_to_excel(run_folder, list_of_datasets, encoding=None):\n",
    "    \n",
    "    with pd.ExcelWriter(os.path.join(run_folder, 'language_fail_rates.xlsx')) as writer:  \n",
    "        for key, value in list_of_datasets.items():\n",
    "            value.to_excel(writer, sheet_name=key, index=False, encoding=None)\n",
    "            \n",
    "def write_summary_to_excel(analysis_folder, list_of_summaries, encoding=None):\n",
    "    \n",
    "    folders = ['RC', 'V1', 'V2']\n",
    "    for lists, f in zip(list_of_summaries.items(), folders):\n",
    "        key, value = lists[0], lists[1]\n",
    "        #value.to_csv(os.path.join(os.path.join(analysis_folder,f), key + '.csv'), index=False, encoding=None)\n",
    "        value.to_excel(os.path.join(os.path.join(analysis_folder,f), key + '.xlsx'), index=False, encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data processing in progress...\n",
      "Initialize data ingestion and file checking...\n",
      "\n",
      "PASS: All files exists!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the type of run e.g. Deployment, Pilot 1, Pilot 2, Pilot 3 .... etc.:  Pilot 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run type: Pilot 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the pilot subfolder name e.g. Pilot 1A, Pilot 2C, Pilot 3A-B .... etc.:  Pilot 2B-A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pilot subfolder: Pilot 2B-A\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you know the 'Language' and/or 'Market code' for this file? (y/n) :  y\n",
      "\n",
      "Please enter the Language:  Japanese\n",
      "\n",
      "Please enter the Market code: eg. EN-EN for English :  JP-JP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting automated data cleaning....\n",
      "\n",
      "Dataframe created from RC file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Missing columns inserted into 'Data' sheet.\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "   Language Market  _worker_id  Score  Percentage Grouping\n",
      "0  Japanese  JP-JP    45109843      3        0.75  Pilot 2\n",
      "1  Japanese  JP-JP    45112013      3        0.75  Pilot 2\n",
      "2  Japanese  JP-JP    45115101      2        0.50  Pilot 2\n",
      "3  Japanese  JP-JP    45135604      4        1.00  Pilot 2\n",
      "4  Japanese  JP-JP    45135810      3        0.75  Pilot 2\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "   Language           _id question_no_1 question_no_2  question_no_3  \\\n",
      "0  Japanese  5.875255e+09             c             a            NaN   \n",
      "1  Japanese  5.875264e+09             b             c            NaN   \n",
      "2  Japanese  5.875275e+09             a             c            NaN   \n",
      "3  Japanese  5.875300e+09             b             c            NaN   \n",
      "4  Japanese  5.875344e+09             b             c            NaN   \n",
      "\n",
      "   question_no_4  question_no_5  \n",
      "0            NaN            NaN  \n",
      "1            NaN            NaN  \n",
      "2            NaN            NaN  \n",
      "3            NaN            NaN  \n",
      "4            NaN            NaN  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading RC raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : RC - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : RC - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : RC - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : RC - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : RC - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : RC - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-7 : RC - Data : checking if columns in the 'Data' sheet are identical to the reference columns ...\n",
      "\u001b[92mPASS\u001b[0m: The columns in the 'Data' sheet are identical to the reference\n",
      "\u001b[1m\n",
      "RC data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_1 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_1 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "   Language Market  _worker_id  Score  Percentage Grouping\n",
      "0  Japanese  JP-JP    45109843      6       0.750  Pilot 2\n",
      "1  Japanese  JP-JP    45112013      5       0.625  Pilot 2\n",
      "2  Japanese  JP-JP    45115101      6       0.750  Pilot 2\n",
      "3  Japanese  JP-JP    45135604      4       0.500  Pilot 2\n",
      "4  Japanese  JP-JP    45135810      8       1.000  Pilot 2\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "   Language           _id rater_answer            a_domain a_register  \\\n",
      "0  Japanese  5.875214e+09           no  general vocabulary    neutral   \n",
      "1  Japanese  5.875222e+09          yes  general vocabulary    neutral   \n",
      "2  Japanese  5.875261e+09          yes  general vocabulary    neutral   \n",
      "3  Japanese  5.875273e+09          yes  general vocabulary    neutral   \n",
      "4  Japanese  5.875289e+09          yes  general vocabulary    neutral   \n",
      "\n",
      "             b_domain b_register  \n",
      "0  general vocabulary    neutral  \n",
      "1  general vocabulary    neutral  \n",
      "2  general vocabulary    neutral  \n",
      "3  general vocabulary    neutral  \n",
      "4  general vocabulary    neutral  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_1 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_1 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_1 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_1 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_1 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_1 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_1 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_1 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_2 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_2 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "   Language Market  _worker_id  Score  Percentage Grouping\n",
      "0  Japanese  JP-JP    45109843      6       0.750  Pilot 2\n",
      "1  Japanese  JP-JP    45112013      4       0.500  Pilot 2\n",
      "2  Japanese  JP-JP    45115101      5       0.625  Pilot 2\n",
      "3  Japanese  JP-JP    45135604      3       0.375  Pilot 2\n",
      "4  Japanese  JP-JP    45135810      7       0.875  Pilot 2\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "   Language           _id             rater_answer            a_domain  \\\n",
      "0  Japanese  5.875252e+09  a_and_b_are_not_related  general vocabulary   \n",
      "1  Japanese  5.875262e+09  a_and_b_are_not_related  general vocabulary   \n",
      "2  Japanese  5.875274e+09  a_and_b_are_not_related  general vocabulary   \n",
      "3  Japanese  5.875294e+09  a_and_b_are_not_related  general vocabulary   \n",
      "4  Japanese  5.875322e+09  a_and_b_are_not_related  general vocabulary   \n",
      "\n",
      "  a_register            b_domain b_register  \n",
      "0    neutral  general vocabulary    neutral  \n",
      "1    neutral  general vocabulary    neutral  \n",
      "2    neutral  general vocabulary    neutral  \n",
      "3    neutral  general vocabulary    neutral  \n",
      "4    neutral  general vocabulary    neutral  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_2 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_2 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_2 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_2 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_2 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_2 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_2 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_2 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Automated data cleaning completed. Cleaned excel files are located in data > processed > Pilot 2 folder. \n",
      "\n",
      "Initialize data ingestion and file checking...\n",
      "\n",
      "\n",
      "\n",
      "      Pilot     Variation\n",
      "0   Pilot 1   Pilot 1A-1B\n",
      "1   Pilot 1      Pilot 1C\n",
      "2   Pilot 1      Pilot 1D\n",
      "3   Pilot 1      Pilot 1E\n",
      "4   Pilot 1  Pilot 1E(ES)\n",
      "5   Pilot 2      Pilot 2A\n",
      "6   Pilot 2    Pilot 2A-A\n",
      "7   Pilot 2    Pilot 2B-A\n",
      "8   Pilot 2      Pilot 2D\n",
      "9   Pilot 3      Pilot 3A\n",
      "10  Pilot 3    Pilot 3A-A\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the pilot variation:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 7 for 'Pilot 2B-A'\n",
      "\n",
      "               Survey Filename\n",
      "0  Survey Pilot 1A and 1B.xlsx\n",
      "1          Survey Pilot 2.xlsx\n",
      "2    Survey Pilot 2 and 3.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the survey filename for your pilot run:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 1 for 'Survey Pilot 2.xlsx'\n",
      "\n",
      "Data processing completed.\n",
      "\n",
      "\n",
      "   Language\n",
      "0  Japanese\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the Language you are assessing:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 0 for Japanese\n",
      "\n",
      "Generating reports ...\n",
      "\n",
      "1. Language fail rates report completed and stored in reports > deliverables > Pilot 2 > Pilot 2B-A > Japanese\n",
      "\n",
      "2. Summary report completed and stored in analysis > Grand Summary > RC/V1/V2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    print('\\nData processing in progress...')\n",
    "    # import data from data_processing module\n",
    "    raters, r1, r2, r3, languages, rc, v1, v2, run_value , run_value_2, survey_selected, survey_files, pilot_variation, pilot_selected, pilot_var_selected = data_processing.main()\n",
    "    print('Data processing completed.')\n",
    "    print(\"\\n\")\n",
    "    print(languages)\n",
    "    \n",
    "    # Get input language selection\n",
    "    language_selected = language_selection(languages)\n",
    "      \n",
    "    # Get data from language modification processes\n",
    "    rcR, v1R, v2R = get_time_taken_all(language_selected, rc, v1, v2)\n",
    "    \n",
    "    print('\\nGenerating reports ...')\n",
    "    \n",
    "    # Start generating fail rate reports\n",
    "    list_of_datasets, list_of_summaries = generate_all_fail_rate_reports(rcR, v1R, v2R, rc, v1, v2, run_value, pilot_var_selected)\n",
    "    \n",
    "    # Check the run type and language and create folders in reports > deliverables\n",
    "    run_folder, analysis_folder, folder_tag = file_check_create(root_path, config, language_selected, run_value, pilot_var_selected)\n",
    "    \n",
    "    # Write reports to excel file in run_folder path\n",
    "    write_fail_report_to_excel(run_folder, list_of_datasets)\n",
    "    \n",
    "    print(f\"\\n1. Language fail rates report completed and stored in reports > deliverables > {run_value} > {pilot_var_selected} > {language_selected}\")\n",
    "    \n",
    "    # Write summaries to csv file in analysis_folder path\n",
    "    write_summary_to_excel(analysis_folder, list_of_summaries, encoding='utf-8')\n",
    "    \n",
    "    print(f\"\\n2. Summary report completed and stored in analysis > {folder_tag} > RC/V1/V2\")\n",
    "    \n",
    "    return r1, r2, r3, rc, v1, v2, pilot_var_selected, rcR, v1R, v2R, list_of_datasets, list_of_summaries\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    "    r1, r2, r3, rc, v1, v2, pilot_var_selected, rcR, v1R, v2R, list_of_datasets, list_of_summaries = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 79)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 33)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 35)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pilot 2B-A'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot_var_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 81)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 35)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 37)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_actual_correct_by_question_with_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>question_</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>wordphrase_a</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>wordphrase_b</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Count_of_Test_Takers</th>\n",
       "      <th>Total_Test_Takers</th>\n",
       "      <th>Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919932400</td>\n",
       "      <td>26</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>formal</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919932405</td>\n",
       "      <td>44</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919932403</td>\n",
       "      <td>42</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>hard</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919932404</td>\n",
       "      <td>43</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919932399</td>\n",
       "      <td>21</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language Fluency    _unit_id  question_            a_domain a_register  \\\n",
       "0  Japanese  Fluent  2919932400         26  general vocabulary    neutral   \n",
       "1  Japanese  Fluent  2919932405         44  general vocabulary    neutral   \n",
       "2  Japanese  Fluent  2919932403         42  general vocabulary    neutral   \n",
       "3  Japanese  Fluent  2919932404         43  general vocabulary    neutral   \n",
       "4  Japanese  Fluent  2919932399         21  general vocabulary    neutral   \n",
       "\n",
       "  wordphrase_a            b_domain b_register wordphrase_b difficulty Answer  \\\n",
       "0             general vocabulary     formal                medium     no   \n",
       "1            general vocabulary    neutral                 easy     no   \n",
       "2             general vocabulary    neutral                  hard     no   \n",
       "3            general vocabulary    neutral               medium     no   \n",
       "4             general vocabulary    neutral                medium     no   \n",
       "\n",
       "   Score  Count_of_Test_Takers  Total_Test_Takers  Fail_Rate  \n",
       "0      0                    10                 15       0.67  \n",
       "1      0                     5                 15       0.33  \n",
       "2      0                     4                 15       0.27  \n",
       "3      0                     3                 15       0.20  \n",
       "4      0                     2                 15       0.13  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Near Exact Match'].head() # v1_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>question_</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>wordphrase_a</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>wordphrase_b</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Answers</th>\n",
       "      <th>a_and_b_are_related</th>\n",
       "      <th>a_and_b_have_the_same_meaning</th>\n",
       "      <th>a_is_more_specific_than_b</th>\n",
       "      <th>b_is_more_specific_than_a</th>\n",
       "      <th>Count_of_Test_Takers</th>\n",
       "      <th>Total_Test_Takers</th>\n",
       "      <th>Overall_Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933195</td>\n",
       "      <td>2</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933196</td>\n",
       "      <td>5</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933197</td>\n",
       "      <td>32</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933198</td>\n",
       "      <td>78</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933200</td>\n",
       "      <td>82</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language Fluency    _unit_id  question_            a_domain a_register  \\\n",
       "0  Japanese  Fluent  2919933195          2  general vocabulary    neutral   \n",
       "1  Japanese  Fluent  2919933196          5  general vocabulary    neutral   \n",
       "2  Japanese  Fluent  2919933197         32  general vocabulary    neutral   \n",
       "3  Japanese  Fluent  2919933198         78  general vocabulary    neutral   \n",
       "4  Japanese  Fluent  2919933200         82  general vocabulary    neutral   \n",
       "\n",
       "  wordphrase_a            b_domain b_register wordphrase_b difficulty  \\\n",
       "0             general vocabulary    neutral                medium   \n",
       "1             general vocabulary    neutral                medium   \n",
       "2             general vocabulary    neutral                 easy   \n",
       "3            general vocabulary    neutral               medium   \n",
       "4             general vocabulary    neutral                  easy   \n",
       "\n",
       "                       Answers  a_and_b_are_related  \\\n",
       "0    a_and_b_are_not_related;0                 0.07   \n",
       "1  a_is_more_specific_than_b;0                 0.27   \n",
       "2    a_and_b_are_not_related;0                 0.40   \n",
       "3    a_and_b_are_not_related;0                 0.47   \n",
       "4    a_and_b_are_not_related;0                 0.53   \n",
       "\n",
       "   a_and_b_have_the_same_meaning  a_is_more_specific_than_b  \\\n",
       "0                            NaN                        NaN   \n",
       "1                            0.2                        NaN   \n",
       "2                            NaN                        NaN   \n",
       "3                            NaN                       0.07   \n",
       "4                            NaN                        NaN   \n",
       "\n",
       "   b_is_more_specific_than_a  Count_of_Test_Takers  Total_Test_Takers  \\\n",
       "0                        NaN                     1                 15   \n",
       "1                        NaN                     7                 15   \n",
       "2                        NaN                     6                 15   \n",
       "3                        NaN                     8                 15   \n",
       "4                       0.13                    10                 15   \n",
       "\n",
       "   Overall_Fail_Rate  \n",
       "0               0.07  \n",
       "1               0.47  \n",
       "2               0.40  \n",
       "3               0.53  \n",
       "4               0.67  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Close Match'].head() #v2_fail_rates or v2_actual_correct_by_question_with_answer for 1A-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>title</th>\n",
       "      <th>test_</th>\n",
       "      <th>Score</th>\n",
       "      <th>Question</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>register</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Count</th>\n",
       "      <th>Total</th>\n",
       "      <th>Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934733</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934734</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 2</td>\n",
       "      <td>easy</td>\n",
       "      <td>informal</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934733</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 2</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934734</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>easy</td>\n",
       "      <td>informal</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919934734</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Question 2</td>\n",
       "      <td>easy</td>\n",
       "      <td>informal</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language Fluency    _unit_id                         title  test_  Score  \\\n",
       "0  Japanese  Fluent  2919934733  4      4      0   \n",
       "1  Japanese  Fluent  2919934734                   5      0   \n",
       "2  Japanese  Fluent  2919934733  4      4      0   \n",
       "3  Japanese  Fluent  2919934734                   5      0   \n",
       "4  Japanese      GT  2919934734                   5      0   \n",
       "\n",
       "     Question Difficulty   register  \\\n",
       "0  Question 1       hard  technical   \n",
       "1  Question 2       easy   informal   \n",
       "2  Question 2       hard  technical   \n",
       "3  Question 1       easy   informal   \n",
       "4  Question 2       easy   informal   \n",
       "\n",
       "                                        Skill  Count  Total  Fail_Rate  \n",
       "0               synthesis and decision-making      8     15       0.53  \n",
       "1  initial understanding: finding key details      4     15       0.27  \n",
       "2               synthesis and decision-making      2     15       0.13  \n",
       "3  initial understanding: finding key details      1     15       0.07  \n",
       "4  initial understanding: finding key details      2      2       1.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['Reading Comprehension'].head() # rc_question_skill_pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>title</th>\n",
       "      <th>test_</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>register</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Question</th>\n",
       "      <th>Actual_Answer_Letter</th>\n",
       "      <th>Actual_Answer_Text</th>\n",
       "      <th>Rater_Answer_Letter</th>\n",
       "      <th>Rater_Answer_Text</th>\n",
       "      <th>Count</th>\n",
       "      <th>Total</th>\n",
       "      <th>Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934733</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>c</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934733</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>c</td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934733</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "      <td>synthesis and decision-making</td>\n",
       "      <td>Question 2</td>\n",
       "      <td>c</td>\n",
       "      <td></td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934734</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>easy</td>\n",
       "      <td>informal</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>Question 1</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>c</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919934734</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>easy</td>\n",
       "      <td>informal</td>\n",
       "      <td>initial understanding: finding key details</td>\n",
       "      <td>Question 2</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>c</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language Fluency    _unit_id                         title  test_  \\\n",
       "0  Japanese  Fluent  2919934733  4      4   \n",
       "1  Japanese  Fluent  2919934733  4      4   \n",
       "2  Japanese  Fluent  2919934733  4      4   \n",
       "3  Japanese  Fluent  2919934734                   5   \n",
       "4  Japanese  Fluent  2919934734                   5   \n",
       "\n",
       "  Difficulty   register                                       Skill  \\\n",
       "0       hard  technical               synthesis and decision-making   \n",
       "1       hard  technical               synthesis and decision-making   \n",
       "2       hard  technical               synthesis and decision-making   \n",
       "3       easy   informal  initial understanding: finding key details   \n",
       "4       easy   informal  initial understanding: finding key details   \n",
       "\n",
       "     Question Actual_Answer_Letter                  Actual_Answer_Text  \\\n",
       "0  Question 1                    c     \n",
       "1  Question 1                    c     \n",
       "2  Question 2                    c                               \n",
       "3  Question 1                    b                             \n",
       "4  Question 2                    b                            \n",
       "\n",
       "  Rater_Answer_Letter        Rater_Answer_Text  Count  Total  Fail_Rate  \n",
       "0                   b        6     15       0.40  \n",
       "1                   a        2     15       0.13  \n",
       "2                   a                     2     15       0.13  \n",
       "3                   c                 1     15       0.07  \n",
       "4                   c               3     15       0.20  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets['RC with Answers'].head() # rc_question_skill_pass_rate_answer_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store all 4 reports into a dictionary set\n",
    "# list_of_datasets = {\"Near Exact Match\" : v1_actual_correct_by_question,\n",
    "#                     \"Close Match\" : v2_fail_rates,\n",
    "#                     \"Reading Comprehension\" : rc_question_skill_pass_rate,\n",
    "#                     \"RC with Answers\" : rc_question_skill_pass_rate_answer_final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ------------------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 2 : \"Close Match\" - v2_fail_rates  ---------------------------------------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 3 : \"Reading Comprehension\" : rc_question_skill_pass_rate  ---------------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "####  ------------------------REPORT 4 : \"RC with Answers\" : rc_question_skill_pass_rate_answer_final  --------------------------------------------------------\n",
    "####  ---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize data ingestion and file checking...\n",
      "\n",
      "PASS: All files exists!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the type of run e.g. Deployment, Pilot 1, Pilot 2, Pilot 3 .... etc.:  Pilot 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run type: Pilot 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input the pilot subfolder name e.g. Pilot 1A, Pilot 2C, Pilot 3A-B .... etc.:  Pilot 2B-A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pilot subfolder: Pilot 2B-A\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you know the 'Language' and/or 'Market code' for this file? (y/n) :  y\n",
      "\n",
      "Please enter the Language:  Japanese\n",
      "\n",
      "Please enter the Market code: eg. EN-EN for English :  JP-JP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting automated data cleaning....\n",
      "\n",
      "Dataframe created from RC file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Missing columns inserted into 'Data' sheet.\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "   Language Market  _worker_id  Score  Percentage Grouping\n",
      "0  Japanese  JP-JP    45109843      3        0.75  Pilot 2\n",
      "1  Japanese  JP-JP    45112013      3        0.75  Pilot 2\n",
      "2  Japanese  JP-JP    45115101      2        0.50  Pilot 2\n",
      "3  Japanese  JP-JP    45135604      4        1.00  Pilot 2\n",
      "4  Japanese  JP-JP    45135810      3        0.75  Pilot 2\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "   Language           _id question_no_1 question_no_2  question_no_3  \\\n",
      "0  Japanese  5.875255e+09             c             a            NaN   \n",
      "1  Japanese  5.875264e+09             b             c            NaN   \n",
      "2  Japanese  5.875275e+09             a             c            NaN   \n",
      "3  Japanese  5.875300e+09             b             c            NaN   \n",
      "4  Japanese  5.875344e+09             b             c            NaN   \n",
      "\n",
      "   question_no_4  question_no_5  \n",
      "0            NaN            NaN  \n",
      "1            NaN            NaN  \n",
      "2            NaN            NaN  \n",
      "3            NaN            NaN  \n",
      "4            NaN            NaN  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading RC raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : RC - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : RC - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : RC - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : RC - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : RC - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : RC - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-7 : RC - Data : checking if columns in the 'Data' sheet are identical to the reference columns ...\n",
      "\u001b[92mPASS\u001b[0m: The columns in the 'Data' sheet are identical to the reference\n",
      "\u001b[1m\n",
      "RC data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_1 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_1 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "   Language Market  _worker_id  Score  Percentage Grouping\n",
      "0  Japanese  JP-JP    45109843      6       0.750  Pilot 2\n",
      "1  Japanese  JP-JP    45112013      5       0.625  Pilot 2\n",
      "2  Japanese  JP-JP    45115101      6       0.750  Pilot 2\n",
      "3  Japanese  JP-JP    45135604      4       0.500  Pilot 2\n",
      "4  Japanese  JP-JP    45135810      8       1.000  Pilot 2\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "   Language           _id rater_answer            a_domain a_register  \\\n",
      "0  Japanese  5.875214e+09           no  general vocabulary    neutral   \n",
      "1  Japanese  5.875222e+09          yes  general vocabulary    neutral   \n",
      "2  Japanese  5.875261e+09          yes  general vocabulary    neutral   \n",
      "3  Japanese  5.875273e+09          yes  general vocabulary    neutral   \n",
      "4  Japanese  5.875289e+09          yes  general vocabulary    neutral   \n",
      "\n",
      "             b_domain b_register  \n",
      "0  general vocabulary    neutral  \n",
      "1  general vocabulary    neutral  \n",
      "2  general vocabulary    neutral  \n",
      "3  general vocabulary    neutral  \n",
      "4  general vocabulary    neutral  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_1 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_1 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_1 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_1 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_1 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_1 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_1 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_1 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Dataframe created from Vocab_2 file\n",
      "Language and Market columns and values inserted to 'Summary' sheet\n",
      "Language column and values inserted to 'Data' sheet\n",
      "Removing unwanted columns from Vocab_2 Data sheet\n",
      "\n",
      "Preview cleaned datasets:\n",
      "\n",
      "\n",
      "\n",
      "df_summary_cleaned\n",
      "\n",
      "\n",
      "   Language Market  _worker_id  Score  Percentage Grouping\n",
      "0  Japanese  JP-JP    45109843      6       0.750  Pilot 2\n",
      "1  Japanese  JP-JP    45112013      4       0.500  Pilot 2\n",
      "2  Japanese  JP-JP    45115101      5       0.625  Pilot 2\n",
      "3  Japanese  JP-JP    45135604      3       0.375  Pilot 2\n",
      "4  Japanese  JP-JP    45135810      7       0.875  Pilot 2\n",
      "\n",
      "\n",
      "df_data_cleaned\n",
      "\n",
      "\n",
      "   Language           _id             rater_answer            a_domain  \\\n",
      "0  Japanese  5.875252e+09  a_and_b_are_not_related  general vocabulary   \n",
      "1  Japanese  5.875262e+09  a_and_b_are_not_related  general vocabulary   \n",
      "2  Japanese  5.875274e+09  a_and_b_are_not_related  general vocabulary   \n",
      "3  Japanese  5.875294e+09  a_and_b_are_not_related  general vocabulary   \n",
      "4  Japanese  5.875322e+09  a_and_b_are_not_related  general vocabulary   \n",
      "\n",
      "  a_register            b_domain b_register  \n",
      "0    neutral  general vocabulary    neutral  \n",
      "1    neutral  general vocabulary    neutral  \n",
      "2    neutral  general vocabulary    neutral  \n",
      "3    neutral  general vocabulary    neutral  \n",
      "4    neutral  general vocabulary    neutral  \n",
      "\n",
      "Data integrity report post clean-up:\n",
      "\n",
      "\u001b[1mReading Vocab_2 raw data and perform data integrity scanning...:\n",
      "\u001b[0m\n",
      "\n",
      "SCAN-1 : Vocab_2 - Summary : Checking if the sheet contains either 'Language' and 'Market' columns ...\n",
      "\u001b[92mPASS\u001b[0m: 'Summary' sheet contains both 'Language' and 'Market' columns\n",
      "\n",
      "SCAN-2 : Vocab_2 - Summary : Checking if Language' and 'Market' columns are empty ...\n",
      "\u001b[92mPASS\u001b[0m: Both 'Language' and 'Market' columns in 'Summary' contains complete data\n",
      "\n",
      "SCAN-3 : Vocab_2 - Summary : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\n",
      "SCAN-4 : Vocab_2 - Data : Checking if sheet contains 'Language' column ...\n",
      "\u001b[92mPASS\u001b[0m: 'Data' sheet contains 'Language' columns\n",
      "\n",
      "SCAN-5 : Vocab_2 - Data : Checking if Language' column are empty ...\n",
      "\u001b[92mPASS\u001b[0m: 'Language'column in 'Data' contains complete data\n",
      "\n",
      "SCAN-6 : Vocab_2 - Data : Checking if '_worker_id' column name is correct ...\n",
      "\u001b[92mPASS\u001b[0m: valid '_workder_id' column name\n",
      "\u001b[1m\n",
      "Vocab_2 data integrity result:\u001b[92m PASS\u001b[0m\n",
      "\n",
      "Automated data cleaning completed. Cleaned excel files are located in data > processed > Pilot 2 folder. \n",
      "\n",
      "Initialize data ingestion and file checking...\n",
      "\n",
      "\n",
      "\n",
      "      Pilot     Variation\n",
      "0   Pilot 1   Pilot 1A-1B\n",
      "1   Pilot 1      Pilot 1C\n",
      "2   Pilot 1      Pilot 1D\n",
      "3   Pilot 1      Pilot 1E\n",
      "4   Pilot 1  Pilot 1E(ES)\n",
      "5   Pilot 2      Pilot 2A\n",
      "6   Pilot 2    Pilot 2A-A\n",
      "7   Pilot 2    Pilot 2B-A\n",
      "8   Pilot 2      Pilot 2D\n",
      "9   Pilot 3      Pilot 3A\n",
      "10  Pilot 3    Pilot 3A-A\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the pilot variation:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 7 for 'Pilot 2B-A'\n",
      "\n",
      "               Survey Filename\n",
      "0  Survey Pilot 1A and 1B.xlsx\n",
      "1          Survey Pilot 2.xlsx\n",
      "2    Survey Pilot 2 and 3.xlsx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the number of the survey filename for your pilot run:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You have selected 1 for 'Survey Pilot 2.xlsx'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Language Fluency    _unit_id  question_            a_domain  \\\n",
       " 0   Japanese  Fluent  2919933195          2  general vocabulary   \n",
       " 1   Japanese  Fluent  2919933196          5  general vocabulary   \n",
       " 2   Japanese  Fluent  2919933197         32  general vocabulary   \n",
       " 3   Japanese  Fluent  2919933198         78  general vocabulary   \n",
       " 4   Japanese  Fluent  2919933199         81  general vocabulary   \n",
       " 5   Japanese  Fluent  2919933200         82  general vocabulary   \n",
       " 6   Japanese  Fluent  2919933201         83  general vocabulary   \n",
       " 7   Japanese  Fluent  2919933202         84  general vocabulary   \n",
       " 8   Japanese      GT  2919933195          2  general vocabulary   \n",
       " 9   Japanese      GT  2919933196          5  general vocabulary   \n",
       " 10  Japanese      GT  2919933197         32  general vocabulary   \n",
       " 11  Japanese      GT  2919933198         78  general vocabulary   \n",
       " 12  Japanese      GT  2919933199         81  general vocabulary   \n",
       " 13  Japanese      GT  2919933200         82  general vocabulary   \n",
       " 14  Japanese      GT  2919933201         83  general vocabulary   \n",
       " 15  Japanese      GT  2919933202         84  general vocabulary   \n",
       " \n",
       "         a_register wordphrase_a            b_domain      b_register  \\\n",
       " 0          neutral             general vocabulary         neutral   \n",
       " 1          neutral             general vocabulary         neutral   \n",
       " 2          neutral             general vocabulary         neutral   \n",
       " 3          neutral            general vocabulary         neutral   \n",
       " 4   slang/informal           general vocabulary  slang/informal   \n",
       " 5          neutral             general vocabulary         neutral   \n",
       " 6          neutral             general vocabulary         neutral   \n",
       " 7          neutral             general vocabulary         neutral   \n",
       " 8          neutral             general vocabulary         neutral   \n",
       " 9          neutral             general vocabulary         neutral   \n",
       " 10         neutral             general vocabulary         neutral   \n",
       " 11         neutral            general vocabulary         neutral   \n",
       " 12  slang/informal           general vocabulary  slang/informal   \n",
       " 13         neutral             general vocabulary         neutral   \n",
       " 14         neutral             general vocabulary         neutral   \n",
       " 15         neutral             general vocabulary         neutral   \n",
       " \n",
       "    wordphrase_b difficulty  Count_of_Test_Takers  Total_Test_Takers  \\\n",
       " 0                 medium                   1.0               15.0   \n",
       " 1                 medium                   7.0               15.0   \n",
       " 2                  easy                   6.0               15.0   \n",
       " 3                medium                   8.0               15.0   \n",
       " 4                 easy                   NaN                NaN   \n",
       " 5                   easy                  10.0               15.0   \n",
       " 6                 medium                   3.0               15.0   \n",
       " 7                   hard                   4.0               15.0   \n",
       " 8                 medium                   NaN                NaN   \n",
       " 9                 medium                   2.0                2.0   \n",
       " 10                 easy                   2.0                2.0   \n",
       " 11               medium                   2.0                2.0   \n",
       " 12                easy                   1.0                2.0   \n",
       " 13                  easy                   2.0                2.0   \n",
       " 14                medium                   2.0                2.0   \n",
       " 15                  hard                   2.0                2.0   \n",
       " \n",
       "     Overall_Fail_Rate                      Answers  a_and_b_are_not_related  \\\n",
       " 0                0.07    a_and_b_are_not_related;0                     0.93   \n",
       " 1                0.47  a_is_more_specific_than_b;0                      NaN   \n",
       " 2                0.40    a_and_b_are_not_related;0                     0.60   \n",
       " 3                0.53    a_and_b_are_not_related;0                     0.47   \n",
       " 4                 NaN    a_and_b_are_not_related;0                     1.00   \n",
       " 5                0.67    a_and_b_are_not_related;0                     0.33   \n",
       " 6                0.20    a_and_b_are_not_related;0                     0.80   \n",
       " 7                0.27  a_is_more_specific_than_b;0                      NaN   \n",
       " 8                 NaN    a_and_b_are_not_related;0                     1.00   \n",
       " 9                1.00  a_is_more_specific_than_b;0                      NaN   \n",
       " 10               1.00    a_and_b_are_not_related;0                      NaN   \n",
       " 11               1.00    a_and_b_are_not_related;0                      NaN   \n",
       " 12               0.50    a_and_b_are_not_related;0                     0.50   \n",
       " 13               1.00    a_and_b_are_not_related;0                      NaN   \n",
       " 14               1.00    a_and_b_are_not_related;0                      NaN   \n",
       " 15               1.00  a_is_more_specific_than_b;0                      NaN   \n",
       " \n",
       "     a_and_b_are_related  a_and_b_have_the_same_meaning  \\\n",
       " 0                  0.07                            NaN   \n",
       " 1                  0.27                            0.2   \n",
       " 2                  0.40                            NaN   \n",
       " 3                  0.47                            NaN   \n",
       " 4                   NaN                            NaN   \n",
       " 5                  0.53                            NaN   \n",
       " 6                  0.20                            NaN   \n",
       " 7                  0.07                            0.2   \n",
       " 8                   NaN                            NaN   \n",
       " 9                  0.50                            NaN   \n",
       " 10                 1.00                            NaN   \n",
       " 11                  NaN                            0.5   \n",
       " 12                  NaN                            0.5   \n",
       " 13                 0.50                            NaN   \n",
       " 14                 1.00                            NaN   \n",
       " 15                  NaN                            1.0   \n",
       " \n",
       "     a_is_more_specific_than_b  b_is_more_specific_than_a  \n",
       " 0                         NaN                        NaN  \n",
       " 1                        0.53                        NaN  \n",
       " 2                         NaN                        NaN  \n",
       " 3                        0.07                        NaN  \n",
       " 4                         NaN                        NaN  \n",
       " 5                         NaN                       0.13  \n",
       " 6                         NaN                        NaN  \n",
       " 7                        0.73                        NaN  \n",
       " 8                         NaN                        NaN  \n",
       " 9                         NaN                       0.50  \n",
       " 10                        NaN                        NaN  \n",
       " 11                       0.50                        NaN  \n",
       " 12                        NaN                        NaN  \n",
       " 13                        NaN                       0.50  \n",
       " 14                        NaN                        NaN  \n",
       " 15                        NaN                        NaN  ,\n",
       "     Language Fluency    _unit_id  question_            a_domain  \\\n",
       " 0   Japanese  Fluent  2919933195          2  general vocabulary   \n",
       " 1   Japanese  Fluent  2919933196          5  general vocabulary   \n",
       " 2   Japanese  Fluent  2919933197         32  general vocabulary   \n",
       " 3   Japanese  Fluent  2919933198         78  general vocabulary   \n",
       " 4   Japanese  Fluent  2919933200         82  general vocabulary   \n",
       " 5   Japanese  Fluent  2919933201         83  general vocabulary   \n",
       " 6   Japanese  Fluent  2919933202         84  general vocabulary   \n",
       " 7   Japanese      GT  2919933196          5  general vocabulary   \n",
       " 8   Japanese      GT  2919933197         32  general vocabulary   \n",
       " 9   Japanese      GT  2919933198         78  general vocabulary   \n",
       " 10  Japanese      GT  2919933199         81  general vocabulary   \n",
       " 11  Japanese      GT  2919933200         82  general vocabulary   \n",
       " 12  Japanese      GT  2919933201         83  general vocabulary   \n",
       " 13  Japanese      GT  2919933202         84  general vocabulary   \n",
       " \n",
       "         a_register wordphrase_a            b_domain      b_register  \\\n",
       " 0          neutral             general vocabulary         neutral   \n",
       " 1          neutral             general vocabulary         neutral   \n",
       " 2          neutral             general vocabulary         neutral   \n",
       " 3          neutral            general vocabulary         neutral   \n",
       " 4          neutral             general vocabulary         neutral   \n",
       " 5          neutral             general vocabulary         neutral   \n",
       " 6          neutral             general vocabulary         neutral   \n",
       " 7          neutral             general vocabulary         neutral   \n",
       " 8          neutral             general vocabulary         neutral   \n",
       " 9          neutral            general vocabulary         neutral   \n",
       " 10  slang/informal           general vocabulary  slang/informal   \n",
       " 11         neutral             general vocabulary         neutral   \n",
       " 12         neutral             general vocabulary         neutral   \n",
       " 13         neutral             general vocabulary         neutral   \n",
       " \n",
       "    wordphrase_b difficulty                      Answers  Count_of_Test_Takers  \\\n",
       " 0                 medium    a_and_b_are_not_related;0                     1   \n",
       " 1                 medium  a_is_more_specific_than_b;0                     7   \n",
       " 2                  easy    a_and_b_are_not_related;0                     6   \n",
       " 3                medium    a_and_b_are_not_related;0                     8   \n",
       " 4                   easy    a_and_b_are_not_related;0                    10   \n",
       " 5                 medium    a_and_b_are_not_related;0                     3   \n",
       " 6                   hard  a_is_more_specific_than_b;0                     4   \n",
       " 7                 medium  a_is_more_specific_than_b;0                     2   \n",
       " 8                  easy    a_and_b_are_not_related;0                     2   \n",
       " 9                medium    a_and_b_are_not_related;0                     2   \n",
       " 10                easy    a_and_b_are_not_related;0                     1   \n",
       " 11                  easy    a_and_b_are_not_related;0                     2   \n",
       " 12                medium    a_and_b_are_not_related;0                     2   \n",
       " 13                  hard  a_is_more_specific_than_b;0                     2   \n",
       " \n",
       "     Total_Test_Takers  Overall_Fail_Rate  \n",
       " 0                  15               0.07  \n",
       " 1                  15               0.47  \n",
       " 2                  15               0.40  \n",
       " 3                  15               0.53  \n",
       " 4                  15               0.67  \n",
       " 5                  15               0.20  \n",
       " 6                  15               0.27  \n",
       " 7                   2               1.00  \n",
       " 8                   2               1.00  \n",
       " 9                   2               1.00  \n",
       " 10                  2               0.50  \n",
       " 11                  2               1.00  \n",
       " 12                  2               1.00  \n",
       " 13                  2               1.00  )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def v2_fail_rate_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "    vR_temp = v2R[selector_2['select2']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_2['groupby3'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "    # second grouping\n",
    "    vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_2['groupby4'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "    vR_grouped['Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "    # filter Score 0 . Note Pilot 1C,1D seem to have this disabled, but it's not making sense as Fail Rate should have Score = 0.\n",
    "    if pilot_var_selected == 'Pilot 1C' or pilot_var_selected == 'Pilot 1D':\n",
    "        vR_grouped = vR_grouped\n",
    "        \n",
    "    elif pilot_var_selected == 'Pilot 3A':\n",
    "        vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "    # sort values by Market and _unit_id \n",
    "    vR_grouped = vR_grouped.sort_values(selector_2['sort_values_2'], ascending = selector_2['sort_order_2'])\n",
    "    \n",
    "    # drop Score columns\n",
    "    vR_grouped = vR_grouped.drop(selector_2['drop_cols'], axis = 1)\n",
    "    \n",
    "    vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "     \n",
    "    vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].fillna('Null')\n",
    "    \n",
    "    vR_fail_rates  = pd.pivot_table(vR_fail_rates, \n",
    "                           index = selector_2['explode'],\n",
    "                           values='Rate', columns=['rater_answer']).reset_index()\n",
    "    vR_fail_rates.columns.name = None # remove name for columns\n",
    "    \n",
    "    vR_fail_rates[selector_2['explode']] = vR_fail_rates[selector_2['explode']].replace('Null', np.nan)\n",
    "    \n",
    "    # remove duplicate rows in the dataframe\n",
    "    vR_fail_rates = vR_fail_rates.drop_duplicates()\n",
    "    \n",
    "    return vR_fail_rates #vR_fail_rates \n",
    "\n",
    "def generate_report_2(v2R, selector_2, pilot_var_selected):\n",
    "    \n",
    "    v2_actual_correct_by_question = v2_fail_rate(v2R, selector_2)\n",
    "\n",
    "    v2_actual_correct_by_question_with_answer = v2_fail_rate_2(v2R, selector_2, pilot_var_selected)\n",
    "\n",
    "    v2_fail_rates = merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2)\n",
    "    \n",
    "    return v2_fail_rates, v2_actual_correct_by_question,  v2_actual_correct_by_question_with_answer\n",
    "\n",
    "raters, r1, r2, r3, languages, rc, v1, v2, run_value , run_value_2, survey_selected, survey_files, pilot_variation, pilot_selected, pilot_var_selected = data_processing.main()\n",
    "\n",
    "# Get data from language modification processes\n",
    "rcR, v1R, v2R = get_time_taken_all('Japanese', rc, v1, v2)\n",
    "\n",
    "selector_2 = report_2_selector('Pilot 2B-A')\n",
    "#vR_fail_rates = v2_fail_rate_2(v2R, selector_2, 'Pilot 1E')\n",
    "v2_fail_rates, v2_actual_correct_by_question,  v2_actual_correct_by_question_with_answer = generate_report_2(v2R, selector_2, 'Pilot 2B-A')\n",
    "v2_actual_correct_by_question_with_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>question_</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>wordphrase_a</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>wordphrase_b</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Count_of_Test_Takers</th>\n",
       "      <th>Total_Test_Takers</th>\n",
       "      <th>Overall_Fail_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933195</td>\n",
       "      <td>2</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933196</td>\n",
       "      <td>5</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933197</td>\n",
       "      <td>32</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933198</td>\n",
       "      <td>78</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933200</td>\n",
       "      <td>82</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933201</td>\n",
       "      <td>83</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933202</td>\n",
       "      <td>84</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>hard</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933196</td>\n",
       "      <td>5</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933197</td>\n",
       "      <td>32</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933198</td>\n",
       "      <td>78</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933199</td>\n",
       "      <td>81</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933200</td>\n",
       "      <td>82</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933201</td>\n",
       "      <td>83</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933202</td>\n",
       "      <td>84</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>hard</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language Fluency    _unit_id  question_            a_domain  \\\n",
       "0   Japanese  Fluent  2919933195          2  general vocabulary   \n",
       "1   Japanese  Fluent  2919933196          5  general vocabulary   \n",
       "2   Japanese  Fluent  2919933197         32  general vocabulary   \n",
       "3   Japanese  Fluent  2919933198         78  general vocabulary   \n",
       "4   Japanese  Fluent  2919933200         82  general vocabulary   \n",
       "5   Japanese  Fluent  2919933201         83  general vocabulary   \n",
       "6   Japanese  Fluent  2919933202         84  general vocabulary   \n",
       "7   Japanese      GT  2919933196          5  general vocabulary   \n",
       "8   Japanese      GT  2919933197         32  general vocabulary   \n",
       "9   Japanese      GT  2919933198         78  general vocabulary   \n",
       "10  Japanese      GT  2919933199         81  general vocabulary   \n",
       "11  Japanese      GT  2919933200         82  general vocabulary   \n",
       "12  Japanese      GT  2919933201         83  general vocabulary   \n",
       "13  Japanese      GT  2919933202         84  general vocabulary   \n",
       "\n",
       "        a_register wordphrase_a            b_domain      b_register  \\\n",
       "0          neutral             general vocabulary         neutral   \n",
       "1          neutral             general vocabulary         neutral   \n",
       "2          neutral             general vocabulary         neutral   \n",
       "3          neutral            general vocabulary         neutral   \n",
       "4          neutral             general vocabulary         neutral   \n",
       "5          neutral             general vocabulary         neutral   \n",
       "6          neutral             general vocabulary         neutral   \n",
       "7          neutral             general vocabulary         neutral   \n",
       "8          neutral             general vocabulary         neutral   \n",
       "9          neutral            general vocabulary         neutral   \n",
       "10  slang/informal           general vocabulary  slang/informal   \n",
       "11         neutral             general vocabulary         neutral   \n",
       "12         neutral             general vocabulary         neutral   \n",
       "13         neutral             general vocabulary         neutral   \n",
       "\n",
       "   wordphrase_b difficulty                      Answers  Count_of_Test_Takers  \\\n",
       "0                 medium    a_and_b_are_not_related;0                     1   \n",
       "1                 medium  a_is_more_specific_than_b;0                     7   \n",
       "2                  easy    a_and_b_are_not_related;0                     6   \n",
       "3                medium    a_and_b_are_not_related;0                     8   \n",
       "4                   easy    a_and_b_are_not_related;0                    10   \n",
       "5                 medium    a_and_b_are_not_related;0                     3   \n",
       "6                   hard  a_is_more_specific_than_b;0                     4   \n",
       "7                 medium  a_is_more_specific_than_b;0                     2   \n",
       "8                  easy    a_and_b_are_not_related;0                     2   \n",
       "9                medium    a_and_b_are_not_related;0                     2   \n",
       "10                easy    a_and_b_are_not_related;0                     1   \n",
       "11                  easy    a_and_b_are_not_related;0                     2   \n",
       "12                medium    a_and_b_are_not_related;0                     2   \n",
       "13                  hard  a_is_more_specific_than_b;0                     2   \n",
       "\n",
       "    Total_Test_Takers  Overall_Fail_Rate  \n",
       "0                  15               0.07  \n",
       "1                  15               0.47  \n",
       "2                  15               0.40  \n",
       "3                  15               0.53  \n",
       "4                  15               0.67  \n",
       "5                  15               0.20  \n",
       "6                  15               0.27  \n",
       "7                   2               1.00  \n",
       "8                   2               1.00  \n",
       "9                   2               1.00  \n",
       "10                  2               0.50  \n",
       "11                  2               1.00  \n",
       "12                  2               1.00  \n",
       "13                  2               1.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2_actual_correct_by_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>question_</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>wordphrase_a</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>wordphrase_b</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Answers</th>\n",
       "      <th>a_and_b_are_not_related</th>\n",
       "      <th>a_and_b_are_related</th>\n",
       "      <th>a_and_b_have_the_same_meaning</th>\n",
       "      <th>a_is_more_specific_than_b</th>\n",
       "      <th>b_is_more_specific_than_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933195</td>\n",
       "      <td>2</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933196</td>\n",
       "      <td>5</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933197</td>\n",
       "      <td>32</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933198</td>\n",
       "      <td>78</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933199</td>\n",
       "      <td>81</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933200</td>\n",
       "      <td>82</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933201</td>\n",
       "      <td>83</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933202</td>\n",
       "      <td>84</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>hard</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933195</td>\n",
       "      <td>2</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933196</td>\n",
       "      <td>5</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933197</td>\n",
       "      <td>32</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933198</td>\n",
       "      <td>78</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933199</td>\n",
       "      <td>81</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933200</td>\n",
       "      <td>82</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933201</td>\n",
       "      <td>83</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933202</td>\n",
       "      <td>84</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>hard</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language Fluency    _unit_id  question_            a_domain  \\\n",
       "0   Japanese  Fluent  2919933195          2  general vocabulary   \n",
       "1   Japanese  Fluent  2919933196          5  general vocabulary   \n",
       "2   Japanese  Fluent  2919933197         32  general vocabulary   \n",
       "3   Japanese  Fluent  2919933198         78  general vocabulary   \n",
       "4   Japanese  Fluent  2919933199         81  general vocabulary   \n",
       "5   Japanese  Fluent  2919933200         82  general vocabulary   \n",
       "6   Japanese  Fluent  2919933201         83  general vocabulary   \n",
       "7   Japanese  Fluent  2919933202         84  general vocabulary   \n",
       "8   Japanese      GT  2919933195          2  general vocabulary   \n",
       "9   Japanese      GT  2919933196          5  general vocabulary   \n",
       "10  Japanese      GT  2919933197         32  general vocabulary   \n",
       "11  Japanese      GT  2919933198         78  general vocabulary   \n",
       "12  Japanese      GT  2919933199         81  general vocabulary   \n",
       "13  Japanese      GT  2919933200         82  general vocabulary   \n",
       "14  Japanese      GT  2919933201         83  general vocabulary   \n",
       "15  Japanese      GT  2919933202         84  general vocabulary   \n",
       "\n",
       "        a_register wordphrase_a            b_domain      b_register  \\\n",
       "0          neutral             general vocabulary         neutral   \n",
       "1          neutral             general vocabulary         neutral   \n",
       "2          neutral             general vocabulary         neutral   \n",
       "3          neutral            general vocabulary         neutral   \n",
       "4   slang/informal           general vocabulary  slang/informal   \n",
       "5          neutral             general vocabulary         neutral   \n",
       "6          neutral             general vocabulary         neutral   \n",
       "7          neutral             general vocabulary         neutral   \n",
       "8          neutral             general vocabulary         neutral   \n",
       "9          neutral             general vocabulary         neutral   \n",
       "10         neutral             general vocabulary         neutral   \n",
       "11         neutral            general vocabulary         neutral   \n",
       "12  slang/informal           general vocabulary  slang/informal   \n",
       "13         neutral             general vocabulary         neutral   \n",
       "14         neutral             general vocabulary         neutral   \n",
       "15         neutral             general vocabulary         neutral   \n",
       "\n",
       "   wordphrase_b difficulty                      Answers  \\\n",
       "0                 medium    a_and_b_are_not_related;0   \n",
       "1                 medium  a_is_more_specific_than_b;0   \n",
       "2                  easy    a_and_b_are_not_related;0   \n",
       "3                medium    a_and_b_are_not_related;0   \n",
       "4                 easy    a_and_b_are_not_related;0   \n",
       "5                   easy    a_and_b_are_not_related;0   \n",
       "6                 medium    a_and_b_are_not_related;0   \n",
       "7                   hard  a_is_more_specific_than_b;0   \n",
       "8                 medium    a_and_b_are_not_related;0   \n",
       "9                 medium  a_is_more_specific_than_b;0   \n",
       "10                 easy    a_and_b_are_not_related;0   \n",
       "11               medium    a_and_b_are_not_related;0   \n",
       "12                easy    a_and_b_are_not_related;0   \n",
       "13                  easy    a_and_b_are_not_related;0   \n",
       "14                medium    a_and_b_are_not_related;0   \n",
       "15                  hard  a_is_more_specific_than_b;0   \n",
       "\n",
       "    a_and_b_are_not_related  a_and_b_are_related  \\\n",
       "0                      0.93                 0.07   \n",
       "1                       NaN                 0.27   \n",
       "2                      0.60                 0.40   \n",
       "3                      0.47                 0.47   \n",
       "4                      1.00                  NaN   \n",
       "5                      0.33                 0.53   \n",
       "6                      0.80                 0.20   \n",
       "7                       NaN                 0.07   \n",
       "8                      1.00                  NaN   \n",
       "9                       NaN                 0.50   \n",
       "10                      NaN                 1.00   \n",
       "11                      NaN                  NaN   \n",
       "12                     0.50                  NaN   \n",
       "13                      NaN                 0.50   \n",
       "14                      NaN                 1.00   \n",
       "15                      NaN                  NaN   \n",
       "\n",
       "    a_and_b_have_the_same_meaning  a_is_more_specific_than_b  \\\n",
       "0                             NaN                        NaN   \n",
       "1                             0.2                       0.53   \n",
       "2                             NaN                        NaN   \n",
       "3                             NaN                       0.07   \n",
       "4                             NaN                        NaN   \n",
       "5                             NaN                        NaN   \n",
       "6                             NaN                        NaN   \n",
       "7                             0.2                       0.73   \n",
       "8                             NaN                        NaN   \n",
       "9                             NaN                        NaN   \n",
       "10                            NaN                        NaN   \n",
       "11                            0.5                       0.50   \n",
       "12                            0.5                        NaN   \n",
       "13                            NaN                        NaN   \n",
       "14                            NaN                        NaN   \n",
       "15                            1.0                        NaN   \n",
       "\n",
       "    b_is_more_specific_than_a  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "5                        0.13  \n",
       "6                         NaN  \n",
       "7                         NaN  \n",
       "8                         NaN  \n",
       "9                        0.50  \n",
       "10                        NaN  \n",
       "11                        NaN  \n",
       "12                        NaN  \n",
       "13                       0.50  \n",
       "14                        NaN  \n",
       "15                        NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2_actual_correct_by_question_with_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>question_</th>\n",
       "      <th>a_domain</th>\n",
       "      <th>a_register</th>\n",
       "      <th>wordphrase_a</th>\n",
       "      <th>b_domain</th>\n",
       "      <th>b_register</th>\n",
       "      <th>wordphrase_b</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Count_of_Test_Takers</th>\n",
       "      <th>Total_Test_Takers</th>\n",
       "      <th>Overall_Fail_Rate</th>\n",
       "      <th>Answers</th>\n",
       "      <th>a_and_b_are_not_related</th>\n",
       "      <th>a_and_b_are_related</th>\n",
       "      <th>a_and_b_have_the_same_meaning</th>\n",
       "      <th>a_is_more_specific_than_b</th>\n",
       "      <th>b_is_more_specific_than_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933195</td>\n",
       "      <td>2</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933196</td>\n",
       "      <td>5</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933197</td>\n",
       "      <td>32</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933198</td>\n",
       "      <td>78</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933199</td>\n",
       "      <td>81</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933200</td>\n",
       "      <td>82</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933201</td>\n",
       "      <td>83</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>2919933202</td>\n",
       "      <td>84</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>hard</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933195</td>\n",
       "      <td>2</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933196</td>\n",
       "      <td>5</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933197</td>\n",
       "      <td>32</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933198</td>\n",
       "      <td>78</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933199</td>\n",
       "      <td>81</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>slang/informal</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933200</td>\n",
       "      <td>82</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>easy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933201</td>\n",
       "      <td>83</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a_and_b_are_not_related;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>GT</td>\n",
       "      <td>2919933202</td>\n",
       "      <td>84</td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>general vocabulary</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>hard</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a_is_more_specific_than_b;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language Fluency    _unit_id  question_            a_domain  \\\n",
       "0   Japanese  Fluent  2919933195          2  general vocabulary   \n",
       "1   Japanese  Fluent  2919933196          5  general vocabulary   \n",
       "2   Japanese  Fluent  2919933197         32  general vocabulary   \n",
       "3   Japanese  Fluent  2919933198         78  general vocabulary   \n",
       "4   Japanese  Fluent  2919933199         81  general vocabulary   \n",
       "5   Japanese  Fluent  2919933200         82  general vocabulary   \n",
       "6   Japanese  Fluent  2919933201         83  general vocabulary   \n",
       "7   Japanese  Fluent  2919933202         84  general vocabulary   \n",
       "8   Japanese      GT  2919933195          2  general vocabulary   \n",
       "9   Japanese      GT  2919933196          5  general vocabulary   \n",
       "10  Japanese      GT  2919933197         32  general vocabulary   \n",
       "11  Japanese      GT  2919933198         78  general vocabulary   \n",
       "12  Japanese      GT  2919933199         81  general vocabulary   \n",
       "13  Japanese      GT  2919933200         82  general vocabulary   \n",
       "14  Japanese      GT  2919933201         83  general vocabulary   \n",
       "15  Japanese      GT  2919933202         84  general vocabulary   \n",
       "\n",
       "        a_register wordphrase_a            b_domain      b_register  \\\n",
       "0          neutral             general vocabulary         neutral   \n",
       "1          neutral             general vocabulary         neutral   \n",
       "2          neutral             general vocabulary         neutral   \n",
       "3          neutral            general vocabulary         neutral   \n",
       "4   slang/informal           general vocabulary  slang/informal   \n",
       "5          neutral             general vocabulary         neutral   \n",
       "6          neutral             general vocabulary         neutral   \n",
       "7          neutral             general vocabulary         neutral   \n",
       "8          neutral             general vocabulary         neutral   \n",
       "9          neutral             general vocabulary         neutral   \n",
       "10         neutral             general vocabulary         neutral   \n",
       "11         neutral            general vocabulary         neutral   \n",
       "12  slang/informal           general vocabulary  slang/informal   \n",
       "13         neutral             general vocabulary         neutral   \n",
       "14         neutral             general vocabulary         neutral   \n",
       "15         neutral             general vocabulary         neutral   \n",
       "\n",
       "   wordphrase_b difficulty  Count_of_Test_Takers  Total_Test_Takers  \\\n",
       "0                 medium                   1.0               15.0   \n",
       "1                 medium                   7.0               15.0   \n",
       "2                  easy                   6.0               15.0   \n",
       "3                medium                   8.0               15.0   \n",
       "4                 easy                   NaN                NaN   \n",
       "5                   easy                  10.0               15.0   \n",
       "6                 medium                   3.0               15.0   \n",
       "7                   hard                   4.0               15.0   \n",
       "8                 medium                   NaN                NaN   \n",
       "9                 medium                   2.0                2.0   \n",
       "10                 easy                   2.0                2.0   \n",
       "11               medium                   2.0                2.0   \n",
       "12                easy                   1.0                2.0   \n",
       "13                  easy                   2.0                2.0   \n",
       "14                medium                   2.0                2.0   \n",
       "15                  hard                   2.0                2.0   \n",
       "\n",
       "    Overall_Fail_Rate                      Answers  a_and_b_are_not_related  \\\n",
       "0                0.07    a_and_b_are_not_related;0                     0.93   \n",
       "1                0.47  a_is_more_specific_than_b;0                      NaN   \n",
       "2                0.40    a_and_b_are_not_related;0                     0.60   \n",
       "3                0.53    a_and_b_are_not_related;0                     0.47   \n",
       "4                 NaN    a_and_b_are_not_related;0                     1.00   \n",
       "5                0.67    a_and_b_are_not_related;0                     0.33   \n",
       "6                0.20    a_and_b_are_not_related;0                     0.80   \n",
       "7                0.27  a_is_more_specific_than_b;0                      NaN   \n",
       "8                 NaN    a_and_b_are_not_related;0                     1.00   \n",
       "9                1.00  a_is_more_specific_than_b;0                      NaN   \n",
       "10               1.00    a_and_b_are_not_related;0                      NaN   \n",
       "11               1.00    a_and_b_are_not_related;0                      NaN   \n",
       "12               0.50    a_and_b_are_not_related;0                     0.50   \n",
       "13               1.00    a_and_b_are_not_related;0                      NaN   \n",
       "14               1.00    a_and_b_are_not_related;0                      NaN   \n",
       "15               1.00  a_is_more_specific_than_b;0                      NaN   \n",
       "\n",
       "    a_and_b_are_related  a_and_b_have_the_same_meaning  \\\n",
       "0                  0.07                            NaN   \n",
       "1                  0.27                            0.2   \n",
       "2                  0.40                            NaN   \n",
       "3                  0.47                            NaN   \n",
       "4                   NaN                            NaN   \n",
       "5                  0.53                            NaN   \n",
       "6                  0.20                            NaN   \n",
       "7                  0.07                            0.2   \n",
       "8                   NaN                            NaN   \n",
       "9                  0.50                            NaN   \n",
       "10                 1.00                            NaN   \n",
       "11                  NaN                            0.5   \n",
       "12                  NaN                            0.5   \n",
       "13                 0.50                            NaN   \n",
       "14                 1.00                            NaN   \n",
       "15                  NaN                            1.0   \n",
       "\n",
       "    a_is_more_specific_than_b  b_is_more_specific_than_a  \n",
       "0                         NaN                        NaN  \n",
       "1                        0.53                        NaN  \n",
       "2                         NaN                        NaN  \n",
       "3                        0.07                        NaN  \n",
       "4                         NaN                        NaN  \n",
       "5                         NaN                       0.13  \n",
       "6                         NaN                        NaN  \n",
       "7                        0.73                        NaN  \n",
       "8                         NaN                        NaN  \n",
       "9                         NaN                       0.50  \n",
       "10                        NaN                        NaN  \n",
       "11                       0.50                        NaN  \n",
       "12                        NaN                        NaN  \n",
       "13                        NaN                       0.50  \n",
       "14                        NaN                        NaN  \n",
       "15                        NaN                        NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2_fail_rates = merge_v2_fail_rates(v2_actual_correct_by_question, v2_actual_correct_by_question_with_answer, selector_2)\n",
    "v2_fail_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_report_3(rcR, selector_3):\n",
    "    \n",
    "#     rc_answer = rc_fail_rate(rcR, selector_3)\n",
    "    \n",
    "# #     rc_choices, actual_answer, rater_answer = melt_rc(rcR, selector_3)\n",
    "    \n",
    "# #     rc_answer_actual = melt_rc_answer_actual(rcR, selector_3)\n",
    "    \n",
    "# #     rc_question_skill_pass_rate = rc_q_s_pass_rate(rc_answer, selector_3)\n",
    "    \n",
    "#     return  rc_answer # rc_question_skill_pass_rate\n",
    "\n",
    "\n",
    "def rc_fail_rate(rcR, selector_3):\n",
    "\n",
    "    vR_temp = rcR[selector_3['select1']]\n",
    "     \n",
    "    cond2 = vR_temp['question_no_1'] == vR_temp['Answer_no_1']\n",
    "    cond1 = (vR_temp['question_no_1'].isnull()) | (vR_temp['Answer_no_1'].isnull())\n",
    "    vR_temp['a1'] = np.select([cond1, cond2], [np.nan, 1], 0)\n",
    "    \n",
    "    cond4 = vR_temp['question_no_2'] == vR_temp['Answer_no_2']\n",
    "    cond3 = (vR_temp['question_no_2'].isnull()) | (vR_temp['Answer_no_2'].isnull())\n",
    "    vR_temp['a2'] = np.select([cond3, cond4], [np.nan, 1], 0)\n",
    "    \n",
    "    cond6 = vR_temp['question_no_3'] == vR_temp['Answer_no_3']\n",
    "    cond5 = (vR_temp['question_no_3'].isnull()) | (vR_temp['Answer_no_3'].isnull())\n",
    "    vR_temp['a3'] = np.select([cond5, cond6], [np.nan, 1], 0)\n",
    "    \n",
    "    cond8 = vR_temp['question_no_4'] == vR_temp['Answer_no_4']\n",
    "    cond7 = (vR_temp['question_no_4'].isnull()) | (vR_temp['Answer_no_4'].isnull())\n",
    "    vR_temp['a4'] = np.select([cond7, cond8], [np.nan, 1], 0)\n",
    "    \n",
    "    # Dropping columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_1'], axis =1)  \n",
    "    \n",
    "    # concatenate values from different columns with delimiter ;\n",
    "    vR_temp['Score'] = vR_temp[['a1', 'a2', 'a3', 'a4']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Question'] = ';'.join(['Question 1', 'Question 2', 'Question 3', 'Question 4'])\n",
    "    vR_temp['Difficulty'] = vR_temp[['question_1_difficulty', 'question_2_difficulty', \n",
    "                                     'question_3_difficulty', 'question_4_difficulty']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Google_Translate_Error'] = vR_temp[['question_1_google_translate_error', \n",
    "                                                 'question_2_google_translate_error', \n",
    "                                                 'question_3_google_translate_error', \n",
    "                                                 'question_4_google_translate_error']].astype('str').agg(';'.join, axis=1) \n",
    "    vR_temp['Skill'] = vR_temp[['Question 1 Skill tested', 'Question 2 Skill tested', \n",
    "                                'Question 3 Skill tested', 'Question 4 Skill tested']].astype('str').agg(';'.join, axis=1) \n",
    "    \n",
    "    # Dropping more columns\n",
    "    vR_temp = vR_temp.drop(selector_3['drop_cols_2'], axis =1)  \n",
    "    \n",
    "    # Python explode function to split delimited columns and expand to rows - row_separate in R\n",
    "    vR_temp =  vR_temp.set_index(selector_3['explode']).apply(lambda x: x.str.split(';').explode()).reset_index()\n",
    "    \n",
    "    vR_temp[['Score', 'Question', 'Difficulty', 'Google_Translate_Error', 'Skill']] = vR_temp[['Score', 'Question', 'Difficulty', \n",
    "                                                                                               'Google_Translate_Error', 'Skill']].replace('nan', np.nan)\n",
    "    vR_temp = vR_temp.dropna(subset = ['Score'])  # remove rows with NaN values in Score \n",
    "    vR_temp['Score'] = vR_temp['Score'].astype(float).astype('int') # set Score as integer\n",
    "    \n",
    "    rc_answer = vR_temp\n",
    "    \n",
    "    return rc_answer\n",
    "\n",
    "selector_3 = report_3_selector('Pilot 1E')\n",
    "\n",
    "output = rc_fail_rate(rcR, selector_3)\n",
    "output\n",
    "#output[['question_no_1', 'Answer_no_1', 'question_no_2', 'Answer_no_2', 'question_no_3', 'Answer_no_3', 'question_no_4', 'Answer_no_4', 'a1', 'a2', 'a3', 'a4']].tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  ------------------------REPORT 1 : \"Near Exact Match\" - v1_actual_correct_by_question  ---------------------------------------------------------------\n",
    "\n",
    "def v1_fail_rate(v1R, selector_1):  #Valid for Pilot 3A, 1C\n",
    "    \n",
    "    vR_temp = v1R[selector_1['select1']]\n",
    "    \n",
    "    # first grouping\n",
    "    vR_grouped = vR_temp.groupby(selector_1['groupby1'], dropna =False)['_worker_id'].count().reset_index()\n",
    "    vR_grouped = vR_grouped.rename(columns = {\"_worker_id\" : \"Count_of_Test_Takers\"})\n",
    "    \n",
    "#     # second grouping\n",
    "#     vR_grouped['Total_Test_Takers'] = vR_grouped.groupby(selector_1['groupby2'], dropna =False)['Count_of_Test_Takers'].transform('sum')   \n",
    "#     vR_grouped['Fail_Rate'] = round((vR_grouped['Count_of_Test_Takers'] / vR_grouped['Total_Test_Takers']), 2)\n",
    "    \n",
    "#     # filter Score 0\n",
    "#     vR_grouped = vR_grouped[vR_grouped['Score'] == 0]\n",
    "    \n",
    "#     # sort values by Market and Fail_rate descending \n",
    "#     vR_grouped = vR_grouped.sort_values(selector_1['sort_values'], ascending = selector_1['sort_order'])\n",
    "    \n",
    "#     vR_fail_rates = vR_grouped.reset_index(drop=True) #re-order df index\n",
    "    \n",
    "    return vR_grouped #vR_fail_rates\n",
    "\n",
    "def generate_report_1(v1R, selector_1):\n",
    "    \n",
    "    v1_actual_correct_by_question = v1_fail_rate(v1R, selector_1)\n",
    "    \n",
    "    return v1_actual_correct_by_question\n",
    "\n",
    "selector_1 = report_1_selector('Pilot 1E')\n",
    "output = v1_fail_rate(v1R, selector_1)\n",
    "output.to_excel('TEMP.xlsx', index=False, encoding=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALA",
   "language": "python",
   "name": "ala"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
